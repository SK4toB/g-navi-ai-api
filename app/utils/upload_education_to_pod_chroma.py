# app/utils/upload_education_vectorstore_to_pod.py
"""
ë¡œì»¬ êµìœ¡ê³¼ì • ChromaDB ì»¬ë ‰ì…˜ì„ Pod ChromaDBë¡œ ì—…ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
ê¸°ì¡´ ê²½ë ¥ ë°ì´í„° ì—…ë¡œë”ì™€ ë™ì¼í•œ ë°©ì‹
"""

import os
import requests
import base64
import json
import pandas as pd
from typing import List, Dict, Any
try:
    from langchain_chroma import Chroma
except ImportError:
    from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.storage import LocalFileStore
from langchain.embeddings import CacheBackedEmbeddings
from dotenv import load_dotenv

load_dotenv()

class EducationChromaPodUploader:
    """ë¡œì»¬ êµìœ¡ê³¼ì • ChromaDBë¥¼ Pod ChromaDBë¡œ ì—…ë¡œë“œ"""
    
    def __init__(self):
        # ë¡œì»¬ êµìœ¡ê³¼ì • ChromaDB ì„¤ì •
        self.local_persist_dir = "app/storage/vector_stores/education_courses"
        self.local_cache_dir = "app/storage/cache/education_embedding_cache"
        
        # Pod ChromaDB ì„¤ì •
        self.pod_base_url = "https://chromadb-1.skala25a.project.skala-ai.com/api/v1"
        self.pod_auth_credentials = os.getenv("CHROMA_AUTH_CREDENTIALS")
        
        # ì»¬ë ‰ì…˜ ì´ë¦„ ì„¤ì •
        self.local_collection_name = "education_courses"  # ë¡œì»¬ ì»¬ë ‰ì…˜ëª…
        self.pod_collection_name = "gnavi4_education_prod"  # Pod ìš´ì˜ìš© ì»¬ë ‰ì…˜ëª…
        self.pod_collection_id = None  # ìƒì„± í›„ ì„¤ì •ë¨
        
        # ì„ë² ë”© ì„¤ì •
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            dimensions=1536
        )
        
        self.headers = self._get_auth_headers()
        
    def _get_auth_headers(self) -> Dict[str, str]:
        """Pod ChromaDB ì¸ì¦ í—¤ë”"""
        if not self.pod_auth_credentials:
            raise ValueError("CHROMA_AUTH_CREDENTIALS í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        encoded_credentials = base64.b64encode(
            self.pod_auth_credentials.encode()
        ).decode()
        
        return {
            "Authorization": f"Basic {encoded_credentials}",
            "Content-Type": "application/json"
        }
    
    def load_local_collection(self):
        """ë¡œì»¬ êµìœ¡ê³¼ì • ChromaDB ì»¬ë ‰ì…˜ ë¡œë“œ"""
        print("ë¡œì»¬ êµìœ¡ê³¼ì • ChromaDB ì»¬ë ‰ì…˜ ë¡œë“œ ì¤‘...")
        
        if not os.path.exists(self.local_persist_dir):
            raise FileNotFoundError(f"ë¡œì»¬ êµìœ¡ê³¼ì • ChromaDB ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {self.local_persist_dir}")
        
        # ìºì‹œëœ ì„ë² ë”© ì„¤ì •
        cached_embeddings = CacheBackedEmbeddings.from_bytes_store(
            self.embeddings,
            LocalFileStore(self.local_cache_dir),
            namespace="education_embeddings"
        )
        
        # ë¡œì»¬ vectorstore ë¡œë“œ
        vectorstore = Chroma(
            persist_directory=self.local_persist_dir,
            embedding_function=cached_embeddings,
            collection_name=self.local_collection_name
        )
        
        # ëª¨ë“  ë¬¸ì„œì™€ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (embeddings í¬í•¨)
        collection = vectorstore.get(include=['documents', 'metadatas', 'embeddings'])
        
        # embeddings í™•ì¸
        embeddings_info = "N/A"
        embeddings_data = collection.get('embeddings')
        
        if embeddings_data is not None and len(embeddings_data) > 0:
            first_embedding = embeddings_data[0]
            if first_embedding is not None and len(first_embedding) > 0:
                embeddings_info = len(first_embedding)
        
        print(f"ë¡œì»¬ êµìœ¡ê³¼ì • ì»¬ë ‰ì…˜ ë¡œë“œ ì™„ë£Œ:")
        print(f"  - ë¬¸ì„œ ìˆ˜: {len(collection['documents'])}")
        print(f"  - ë²¡í„° ì°¨ì›: {embeddings_info}")
        print(f"  - ë©”íƒ€ë°ì´í„° ìˆ˜: {len(collection.get('metadatas', []))}")
        print(f"  - ID ìˆ˜: {len(collection.get('ids', []))}")
        
        # embeddingsê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
        if embeddings_data is None or len(embeddings_data) == 0:
            raise Exception("ë¡œì»¬ êµìœ¡ê³¼ì • ChromaDBì— embeddingsê°€ ì—†ìŠµë‹ˆë‹¤. ë²¡í„° ë°ì´í„°ë¥¼ ë‹¤ì‹œ ìƒì„±í•´ì£¼ì„¸ìš”.")
        
        return collection
    
    def create_pod_collection(self):
        """Pod ChromaDBì— ìƒˆ êµìœ¡ê³¼ì • ì»¬ë ‰ì…˜ ìƒì„±"""
        print(f"Pod ChromaDBì— êµìœ¡ê³¼ì • ì»¬ë ‰ì…˜ ìƒì„± ì¤‘: {self.pod_collection_name}")
        
        # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ (ìˆë‹¤ë©´)
        try:
            delete_url = f"{self.pod_base_url}/collections/{self.pod_collection_name}"
            response = requests.delete(delete_url, headers=self.headers, timeout=30)
            if response.status_code == 200:
                print(f"  ê¸°ì¡´ êµìœ¡ê³¼ì • ì»¬ë ‰ì…˜ ì‚­ì œë¨: {self.pod_collection_name}")
        except:
            pass  # ì—†ì–´ë„ ìƒê´€ì—†ìŒ
        
        # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
        create_data = {
            "name": self.pod_collection_name,
            "metadata": {
                "description": "gnavi4 education courses data",
                "dimensions": 1536,
                "embedding_model": "text-embedding-3-small",
            }
        }
        
        response = requests.post(
            f"{self.pod_base_url}/collections",
            headers=self.headers,
            json=create_data,
            timeout=30
        )
        
        if response.status_code in [200, 201]:
            collection_info = response.json()
            self.pod_collection_id = collection_info.get("id")
            print(f"  ìƒˆ êµìœ¡ê³¼ì • ì»¬ë ‰ì…˜ ìƒì„± ì„±ê³µ: {self.pod_collection_name}")
            print(f"  ì»¬ë ‰ì…˜ ID: {self.pod_collection_id}")
            return True
        else:
            print(f"  êµìœ¡ê³¼ì • ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {response.status_code} - {response.text}")
            return False
    
    def upload_documents_batch(self, collection_data: Dict, batch_size: int = 25):
        """êµìœ¡ê³¼ì • ë¬¸ì„œë¥¼ ë°°ì¹˜ë¡œ Pod ChromaDBì— ì—…ë¡œë“œ"""
        documents = collection_data['documents']
        embeddings = collection_data['embeddings']
        metadatas = collection_data['metadatas']
        ids = collection_data['ids']
        
        # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡)
        if embeddings is not None:
            import numpy as np
            if isinstance(embeddings, np.ndarray):
                embeddings = embeddings.tolist()
            elif isinstance(embeddings, list) and len(embeddings) > 0:
                if isinstance(embeddings[0], np.ndarray):
                    embeddings = [emb.tolist() if isinstance(emb, np.ndarray) else emb for emb in embeddings]
        
        total_docs = len(documents)
        print(f"ì´ {total_docs}ê°œ êµìœ¡ê³¼ì • ë¬¸ì„œë¥¼ {batch_size}ê°œì”© ë°°ì¹˜ ì—…ë¡œë“œ ì‹œì‘...")
        print(f"ì˜ˆìƒ ì´ ë°°ì¹˜ ìˆ˜: {(total_docs + batch_size - 1) // batch_size}")
        
        success_count = 0
        
        # ë°°ì¹˜ë³„ ì—…ë¡œë“œ
        for i in range(0, total_docs, batch_size):
            batch_end = min(i + batch_size, total_docs)
            batch_num = i // batch_size + 1
            
            # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
            batch_embeddings = embeddings[i:batch_end] if embeddings else None
            
            batch_data = {
                "ids": ids[i:batch_end],
                "documents": documents[i:batch_end],
                "embeddings": batch_embeddings,
                "metadatas": metadatas[i:batch_end] if metadatas else None
            }
            
            # ë°°ì¹˜ í¬ê¸° ë¡œê¹…
            try:
                batch_size_mb = len(str(batch_data).encode('utf-8')) / 1024 / 1024
                print(f"  ë°°ì¹˜ {batch_num}: {i+1}-{batch_end}/{total_docs} ({batch_size_mb:.2f}MB)")
            except:
                print(f"  ë°°ì¹˜ {batch_num}: {i+1}-{batch_end}/{total_docs}")
            
            # API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
            max_retries = 3
            for retry in range(max_retries):
                try:
                    collection_identifier = self.pod_collection_id if self.pod_collection_id else self.pod_collection_name
                    
                    response = requests.post(
                        f"{self.pod_base_url}/collections/{collection_identifier}/add",
                        headers=self.headers,
                        json=batch_data,
                        timeout=180
                    )
                    
                    if response.status_code in [200, 201]:
                        success_count += 1
                        print(f"    âœ… ë°°ì¹˜ {batch_num} ì—…ë¡œë“œ ì™„ë£Œ (ì‹œë„ {retry + 1}) - HTTP {response.status_code}")
                        break
                    else:
                        print(f"    âŒ ë°°ì¹˜ {batch_num} ì—…ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")
                        print(f"    ì‘ë‹µ ë‚´ìš©: {response.text}")
                        if retry < max_retries - 1:
                            print(f"    ğŸ”„ ì¬ì‹œë„ {retry + 2}/{max_retries}")
                            continue
                        else:
                            print(f"    ğŸ’¥ ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼. ì˜¤ë¥˜: {response.text}")
                            return False
                            
                except requests.exceptions.Timeout:
                    print(f"    â° ë°°ì¹˜ {batch_num} íƒ€ì„ì•„ì›ƒ (ì‹œë„ {retry + 1})")
                    if retry < max_retries - 1:
                        print(f"    ğŸ”„ ì¬ì‹œë„ {retry + 2}/{max_retries}")
                        continue
                    else:
                        print(f"    ğŸ’¥ ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼ (íƒ€ì„ì•„ì›ƒ)")
                        return False
                        
                except Exception as e:
                    print(f"    âŒ ë°°ì¹˜ {batch_num} ì˜ˆì™¸ ë°œìƒ: {str(e)}")
                    if retry < max_retries - 1:
                        print(f"    ğŸ”„ ì¬ì‹œë„ {retry + 2}/{max_retries}")
                        continue
                    else:
                        print(f"    ğŸ’¥ ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼")
                        return False
        
        print(f"\nğŸ‰ ëª¨ë“  êµìœ¡ê³¼ì • ë¬¸ì„œ ì—…ë¡œë“œ ì™„ë£Œ!")
        print(f"   ì„±ê³µí•œ ë°°ì¹˜: {success_count}/{(total_docs + batch_size - 1) // batch_size}")
        return True
    

    
    def run_upload(self):
        """ì „ì²´ êµìœ¡ê³¼ì • ì—…ë¡œë“œ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        try:
            # 1. ë¡œì»¬ êµìœ¡ê³¼ì • ì»¬ë ‰ì…˜ ë¡œë“œ
            collection_data = self.load_local_collection()
            
            # 2. Podì— êµìœ¡ê³¼ì • ì»¬ë ‰ì…˜ ìƒì„±
            if not self.create_pod_collection():
                raise Exception("Pod êµìœ¡ê³¼ì • ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨")
            
            # 3. êµìœ¡ê³¼ì • ë¬¸ì„œ ì—…ë¡œë“œ
            if not self.upload_documents_batch(collection_data):
                raise Exception("êµìœ¡ê³¼ì • ë¬¸ì„œ ì—…ë¡œë“œ ì‹¤íŒ¨")
            
            print("\nğŸ‰ êµìœ¡ê³¼ì • ChromaDB ì»¬ë ‰ì…˜ ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"   ë¡œì»¬: {self.local_collection_name}")
            print(f"   Pod: {self.pod_collection_name}")
            print("\nğŸ’¡ ì—…ë¡œë“œ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
            print("   python app/utils/verify_education_chroma_upload.py")
            
        except Exception as e:
            print(f"\nâŒ êµìœ¡ê³¼ì • ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ êµìœ¡ê³¼ì • ChromaDB ì»¬ë ‰ì…˜ Pod ì—…ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    required_env = ["OPENAI_API_KEY", "CHROMA_AUTH_CREDENTIALS"]
    missing_env = [env for env in required_env if not os.getenv(env)]
    
    if missing_env:
        print(f"âŒ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤: {missing_env}")
        print("   .env íŒŒì¼ì— ë‹¤ìŒì„ ì¶”ê°€í•˜ì„¸ìš”:")
        for env in missing_env:
            print(f"   {env}=your_value_here")
        return
    
    # êµìœ¡ê³¼ì • ì—…ë¡œë“œ ì‹¤í–‰
    uploader = EducationChromaPodUploader()
    uploader.run_upload()

if __name__ == "__main__":
    main()
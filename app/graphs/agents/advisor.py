# advisor.py

from typing import Dict, Any, List
from langchain.schema import Document
from langchain.prompts import ChatPromptTemplate
import json
import logging
from datetime import datetime

class RecommendationAgent:
    """ì¶”ì²œ ë° ì „ëžµ ìˆ˜ë¦½ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def generate_personalized_recommendation(self,
                                           user_question: str,
                                           user_data: Dict[str, Any],
                                           intent_analysis: Dict[str, Any],
                                           career_cases: List[Document],
                                           external_trends: List[Dict[str, str]]) -> Dict[str, Any]:
        """ë§žì¶¤í˜• ì¶”ì²œ ë° ì „ëžµ ìƒì„±"""
        
        self.logger.info("ë§žì¶¤í˜• ì¶”ì²œ ì „ëžµ ìƒì„± ì‹œìž‘")
        
        # LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        from langchain_openai import ChatOpenAI
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
        
        system_prompt = """ë‹¹ì‹ ì€ ê²½ë ¥ 10ë…„ ì´ìƒì˜ ì‹œë‹ˆì–´ ì»¤ë¦¬ì–´ ì»¨ì„¤í„´íŠ¸ìž…ë‹ˆë‹¤.
ì‚¬ë‚´ êµ¬ì„±ì›ë“¤ì˜ ì‹¤ì œ ì»¤ë¦¬ì–´ ì‚¬ë¡€ì™€ ìµœì‹  ì—…ê³„ íŠ¸ë Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤ìš° êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë§žì¶¤í˜• ì»¤ë¦¬ì–´ ì „ëžµì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ê¸°ì¤€:**
1. ì‚¬ìš©ìž í˜„ìž¬ ìƒí™©ê³¼ ìœ ì‚¬í•œ ì‚¬ë¡€ ì°¾ê¸°
2. ì„±ê³µ ì‚¬ë¡€ì˜ í•µì‹¬ ì „í™˜ì  ë° ì „ëžµ ì¶”ì¶œ  
3. ìµœì‹  íŠ¸ë Œë“œì™€ ì—°ê²°í•œ ë¯¸ëž˜ ì§€í–¥ì  ë°©í–¥ ì œì‹œ
4. ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½

**ì œê³µí•´ì•¼ í•  ë‚´ìš©:**
1. **ìƒí™© ì§„ë‹¨ ë° ê¸°íšŒ ìš”ì†Œ**
2. **ë§žì¶¤í˜• ì»¤ë¦¬ì–´ ì „ëžµ** (3-6ê°œì›”, 1ë…„, 2-3ë…„ ë‹¨ìœ„)
3. **êµ¬ì²´ì  ì‹¤í–‰ ê³„íš** (í•™ìŠµ ë¡œë“œë§µ, í”„ë¡œì íŠ¸, ë„¤íŠ¸ì›Œí‚¹ ë“±)
4. **ì˜ˆìƒ ìž¥ì• ë¬¼ ë° ê·¹ë³µ ë°©ì•ˆ**
5. **ì„±ê³µ ì§€í‘œ ë° í‰ê°€ ê¸°ì¤€**
6. **ì°¸ê³ í•  ë§Œí•œ ì‚¬ë‚´ ë¡¤ëª¨ë¸ê³¼ ì‚¬ë¡€**

**ì¤‘ìš”:** ì‹¤ì œ ì»¤ë¦¬ì–´ ì‚¬ë¡€ë¥¼ ë°˜ë“œì‹œ í™œìš©í•˜ì„¸ìš”. ì œê³µëœ ì‚¬ë¡€ì—ì„œ í•µì‹¬ ì „ëžµ, ì „í™˜ ìš”ì†Œ, ì„±ìž¥ í¬ì¸íŠ¸ë¥¼ ì°¾ì•„ í™œìš©í•˜ê³ , ì´ë¥¼ ê¶Œìž¥ ì‚¬í•­ì— ëª…ì‹œì ìœ¼ë¡œ í†µí•©í•˜ì„¸ìš”. ì¶”ìƒì ì¸ ì¡°ì–¸ ëŒ€ì‹  ì‹¤ì œ ì‚¬ë¡€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ êµ¬ì²´ì ì¸ ì°¸ê³  ì‚¬ë¡€ì™€ ì „ëžµì„ í¬í•¨í•˜ì„¸ìš”.

í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ìž‘ì„±í•´ì£¼ì„¸ìš”."""

        # ì»¤ë¦¬ì–´ ì‚¬ë¡€ ìš”ì•½ - Documentì™€ dict ëª¨ë‘ ì²˜ë¦¬ (ìƒì„¸ ì •ë³´ í¬í•¨)
        career_examples = ""
        career_cases_data = []
        
        if career_cases:
            examples = []
            # ìµœëŒ€ 6ê°œ ì‚¬ë¡€ ì‚¬ìš©í•˜ì—¬ ë” ë§Žì€ ì°¸ê³  ìžë£Œ ì œê³µ
            limited_cases = career_cases[:6]
            
            for i, case in enumerate(limited_cases, 1):
                # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜ëœ ê²½ìš°
                if isinstance(case, dict):
                    content = case.get('content', '')
                    metadata = case.get('metadata', {})
                # Document ê°ì²´ì¸ ê²½ìš°
                elif hasattr(case, 'page_content'):
                    content = case.page_content
                    metadata = case.metadata if hasattr(case, 'metadata') else {}
                else:
                    continue
                
                if content:
                    # ì»¨í…ì¸  ê¸¸ì´ë¥¼ 500ìžë¡œ í™•ìž¥í•˜ì—¬ ë” ìƒì„¸í•œ ì •ë³´ ì œê³µ
                    detailed_content = content[:500] + "..." if len(content) > 500 else content
                    
                    # ë” ìžì„¸í•œ ì‚¬ë¡€ ì •ë³´ êµ¬ì„±
                    example = f"""ì‚¬ë¡€ {i}: {metadata.get('name', 'ìµëª…')} ({metadata.get('current_position', 'ì§ì±…ë¯¸ìƒ')})
- ì´ ê²½ë ¥: {metadata.get('total_experience', 'ë¯¸ìƒ')} | í˜„ìž¬ ì—°ì°¨: {metadata.get('experience_years', 'ë¯¸ìƒ')}
- ì£¼ìš” ë„ë©”ì¸: {metadata.get('primary_domain', 'ë¯¸ìƒ')} | ë³´ì¡° ë„ë©”ì¸: {metadata.get('secondary_domain', 'ë¯¸ìƒ')}
- í•µì‹¬ ê¸°ìˆ : {', '.join(metadata.get('current_skills', [])[:5]) if metadata.get('current_skills') else 'ë¯¸ìƒ'}
- ê´€ì‹¬ ë¶„ì•¼: {', '.join(metadata.get('interests', [])[:3]) if metadata.get('interests') else 'ë¯¸ìƒ'}
- ì»¤ë¦¬ì–´ ëª©í‘œ: {metadata.get('career_goal', 'ë¯¸ìƒ')}
- ì „í™˜ì /ì„±ìž¥ í¬ì¸íŠ¸: {metadata.get('transition_point', 'ë¯¸ìƒ')}
- ì„±ê³µ ìš”ì¸: {metadata.get('success_factors', 'ë¯¸ìƒ')}
- í˜„ìž¬ í”„ë¡œì íŠ¸: {metadata.get('current_project', 'ë¯¸ìƒ')}
- ìƒì„¸ ë‚´ìš©: {detailed_content}"""
                    
                    examples.append(example.strip())
                    
                    # ìƒì„¸í•œ ë©”íƒ€ë°ì´í„° ì €ìž¥
                    career_cases_data.append({
                        "name": metadata.get('name', 'ìµëª…'),
                        "position": metadata.get('current_position', ''),
                        "total_experience": metadata.get('total_experience', ''),
                        "experience_years": metadata.get('experience_years', ''),
                        "primary_domain": metadata.get('primary_domain', ''),
                        "secondary_domain": metadata.get('secondary_domain', ''),
                        "current_skills": metadata.get('current_skills', []),
                        "interests": metadata.get('interests', []),
                        "career_goal": metadata.get('career_goal', ''),
                        "transition_point": metadata.get('transition_point', ''),
                        "success_factors": metadata.get('success_factors', ''),
                        "current_project": metadata.get('current_project', ''),
                        "detailed_content": detailed_content
                    })
            
            career_examples = "\n\n".join(examples)
        
        # ì™¸ë¶€ íŠ¸ë Œë“œ ìš”ì•½ (ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ)
        trends_summary = ""
        if external_trends:
            trend_items = []
            # ìµœëŒ€ 3ê°œ íŠ¸ë Œë“œë§Œ ì‚¬ìš©
            limited_trends = external_trends[:3]
            for trend in limited_trends:
                # íŠ¸ë Œë“œ ë‚´ìš©ë„ ê¸¸ì´ ì œí•œ
                snippet = trend.get('snippet', '')[:150] + "..." if len(trend.get('snippet', '')) > 150 else trend.get('snippet', '')
                trend_items.append(f"- {trend.get('title', '')}: {snippet}")
            trends_summary = "\n".join(trend_items)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", """
**ì‚¬ìš©ìž ì§ˆë¬¸:** {question}

**ì‚¬ìš©ìž í”„ë¡œí•„ ë° ìƒí™©:**
{user_profile}

**ìƒí™© ë¶„ì„ ê²°ê³¼:**
{intent_analysis}

**ìœ ì‚¬ ì»¤ë¦¬ì–´ ì‚¬ë¡€ (ì‚¬ë‚´):**
{career_examples}

**ìµœì‹  ì—…ê³„ íŠ¸ë Œë“œ:**
{trends_summary}

ìœ„ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì´ ì‚¬ìš©ìžì—ê²Œ ê°€ìž¥ ì í•©í•œ ë§žì¶¤í˜• ì»¤ë¦¬ì–´ ì „ëžµì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.
ìœ ì‚¬ ì»¤ë¦¬ì–´ ì‚¬ë¡€ì—ì„œ ë°°ìš¸ ìˆ˜ ìžˆëŠ” êµí›ˆê³¼ ì „ëžµì„ ë°˜ë“œì‹œ ì–¸ê¸‰í•˜ê³ , ë¡¤ëª¨ë¸ ì„¹ì…˜ì—ì„œ ì´ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì°¸ì¡°í•´ì£¼ì„¸ìš”.
êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”.
""")
        ])
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œì„ ìœ„í•œ ì‚¬ìš©ìž ë°ì´í„° ì••ì¶•
            compressed_user_data = self._compress_user_data(user_data)
            compressed_intent = self._compress_intent_analysis(intent_analysis)
            
            # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶”ê°€
            self.logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¤ë¦¬ì–´ ì‚¬ë¡€ ìˆ˜: {len(career_cases)} (ì‚¬ìš©: {min(6, len(career_cases))})")
            self.logger.info(f"ì™¸ë¶€ íŠ¸ë Œë“œ ìˆ˜: {len(external_trends)} (ì‚¬ìš©: {min(3, len(external_trends))})")
            
            # ì²« ë²ˆì§¸ ì‹œë„ - ì••ì¶•ëœ ë°ì´í„°ë¡œ ì‹œë„
            try:
                response = llm.invoke(prompt.format_messages(
                    question=user_question[:500],  # ì§ˆë¬¸ë„ ê¸¸ì´ ì œí•œ
                    user_profile=compressed_user_data,
                    intent_analysis=compressed_intent,
                    career_examples=career_examples or "ì°¸ê³ í•  ì‚¬ë‚´ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    trends_summary=trends_summary or "ìµœì‹  íŠ¸ë Œë“œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                ))
            except Exception as context_error:
                # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì´ˆê³¼ ì‹œ ë”ìš± ì••ì¶•ëœ ë°ì´í„°ë¡œ ìž¬ì‹œë„
                self.logger.warning(f"ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì´ˆê³¼, ë” ì••ì¶•í•˜ì—¬ ìž¬ì‹œë„: {context_error}")
                
                # ë” ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ìž¬ì‹œë„
                simple_prompt = ChatPromptTemplate.from_messages([
                    ("system", "ë‹¹ì‹ ì€ ì»¤ë¦¬ì–´ ì»¨ì„¤í„´íŠ¸ìž…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”."),
                    ("human", """ì§ˆë¬¸: {question}
                    
í˜„ìž¬ ìƒí™©: {simple_profile}

ì°¸ê³  ì‚¬ë¡€: {simple_examples}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì¸ ì»¤ë¦¬ì–´ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”. (í•œêµ­ì–´, 1000ìž ì´ë‚´)""")
                ])
                
                simple_examples = career_examples[:300] if career_examples else "ì‚¬ë¡€ ì •ë³´ ì—†ìŒ"
                simple_profile = f"ê²½ë ¥: {user_data.get('user_profile', {}).get('experience', 'ë¯¸ìƒ')}"
                
                response = llm.invoke(simple_prompt.format_messages(
                    question=user_question[:300],
                    simple_profile=simple_profile,
                    simple_examples=simple_examples
                ))
            
            # ì‘ë‹µì— ì»¤ë¦¬ì–´ ì‚¬ë¡€ê°€ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
            response_content = response.content if hasattr(response, 'content') else str(response)
            has_career_references = any(keyword in response_content.lower() for keyword in ["ì‚¬ë¡€", "ë¡¤ëª¨ë¸", "ì°¸ê³ í• ", "ê²½ë ¥", "ì»¤ë¦¬ì–´ ê²½ë¡œ"])
            
            if not has_career_references and career_cases:
                self.logger.warning("ì‘ë‹µì— ì»¤ë¦¬ì–´ ì‚¬ë¡€ ì°¸ì¡°ê°€ ëˆ„ë½ë˜ì—ˆì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì¶”ê°€ ì²˜ë¦¬ í•„ìš”")
                
                # ì‚¬ë¡€ ì •ë³´ ì¶”ê°€ - ë” ìƒì„¸í•œ ì •ë³´ í¬í•¨
                career_info_section = "\n\n### ðŸ“‹ ì°¸ê³ í•  ë§Œí•œ ì»¤ë¦¬ì–´ ì‚¬ë¡€ ë° ë¡¤ëª¨ë¸\n\n"
                for i, doc in enumerate(career_cases[:4], 1):  # ìµœëŒ€ 4ê°œ ì‚¬ë¡€ í‘œì‹œ
                    if isinstance(doc, dict):
                        metadata = doc.get('metadata', {})
                        content = doc.get('content', '')
                    else:
                        metadata = doc.metadata if hasattr(doc, 'metadata') else {}
                        content = doc.page_content if hasattr(doc, 'page_content') else ''
                    
                    career_info_section += f"**ðŸŽ¯ ì‚¬ë¡€ {i}: {metadata.get('name', 'Unknown')}**\n"
                    career_info_section += f"- **í˜„ìž¬ í¬ì§€ì…˜**: {metadata.get('current_position', 'Unknown')}\n"
                    career_info_section += f"- **ì´ ê²½ë ¥**: {metadata.get('total_experience', 'Unknown')} ({metadata.get('experience_years', 'Unknown')}ë…„)\n"
                    career_info_section += f"- **ì£¼ìš” ë„ë©”ì¸**: {metadata.get('primary_domain', 'Unknown')}\n"
                    career_info_section += f"- **í•µì‹¬ ê¸°ìˆ **: {', '.join(metadata.get('current_skills', [])[:5]) if metadata.get('current_skills') else 'Unknown'}\n"
                    career_info_section += f"- **ê´€ì‹¬ ë¶„ì•¼**: {', '.join(metadata.get('interests', [])[:3]) if metadata.get('interests') else 'Unknown'}\n"
                    career_info_section += f"- **ì»¤ë¦¬ì–´ ëª©í‘œ**: {metadata.get('career_goal', 'Unknown')}\n"
                    career_info_section += f"- **ì»¤ë¦¬ì–´ ì „í™˜ì **: {metadata.get('transition_point', 'Unknown')}\n"
                    career_info_section += f"- **í•µì‹¬ ì„±ê³µ ìš”ì†Œ**: {metadata.get('success_factors', 'Unknown')}\n"
                    if content:
                        # ë‚´ìš©ì´ ìžˆìœ¼ë©´ ìš”ì•½í•˜ì—¬ ì¶”ê°€
                        summary = content[:300] + "..." if len(content) > 300 else content
                        career_info_section += f"- **ê²½í—˜ ìš”ì•½**: {summary}\n"
                    career_info_section += "\n"
                
                # ì›ëž˜ ì‘ë‹µì— ì‚¬ë¡€ ì •ë³´ ì¶”ê°€
                if "ê²°ë¡ " in response_content or "ë§ˆë¬´ë¦¬" in response_content:
                    split_point = max(response_content.rfind("ê²°ë¡ "), response_content.rfind("ë§ˆë¬´ë¦¬"))
                    if split_point > 0:
                        response_content = response_content[:split_point] + career_info_section + response_content[split_point:]
                    else:
                        response_content += career_info_section
                else:
                    response_content += career_info_section
            
            # ì»¤ë¦¬ì–´ ì‚¬ë¡€ ì •ë³´ë¥¼ recommendationì— ì¶”ê°€ - ë” ìƒì„¸í•œ ì •ë³´ í¬í•¨
            career_cases_summary = []
            if career_cases:
                for doc in career_cases[:5]:  # ìµœëŒ€ 5ê°œ ì‚¬ë¡€ ì €ìž¥
                    if isinstance(doc, dict):
                        metadata = doc.get('metadata', {})
                        content = doc.get('content', '')
                    else:
                        metadata = doc.metadata if hasattr(doc, 'metadata') else {}
                        content = doc.page_content if hasattr(doc, 'page_content') else ''
                    
                    career_cases_summary.append({
                        "name": metadata.get('name', ''),
                        "position": metadata.get('current_position', ''),
                        "total_experience": metadata.get('total_experience', ''),
                        "experience_years": metadata.get('experience_years', ''),
                        "primary_domain": metadata.get('primary_domain', ''),
                        "secondary_domain": metadata.get('secondary_domain', ''),
                        "current_skills": metadata.get('current_skills', []),
                        "interests": metadata.get('interests', []),
                        "career_goal": metadata.get('career_goal', ''),
                        "transition_point": metadata.get('transition_point', ''),
                        "success_factors": metadata.get('success_factors', ''),
                        "current_project": metadata.get('current_project', ''),
                        "content_summary": content[:200] + "..." if len(content) > 200 else content,
                        "full_content": content  # ì „ì²´ ë‚´ìš©ë„ ì €ìž¥
                    })
            
            recommendation = {
                "model_used": "gpt-4o",
                "timestamp": datetime.now().isoformat(),
                "recommendation_content": response_content,
                "career_cases_summary": career_cases_summary,
                "source_trends": len(external_trends),
                "confidence_score": self._calculate_confidence_score(career_cases, external_trends),
                "has_career_references": has_career_references
            }
            
            self.logger.info("ë§žì¶¤í˜• ì¶”ì²œ ì „ëžµ ìƒì„± ì™„ë£Œ")
            self.logger.info(f"ì»¤ë¦¬ì–´ ì‚¬ë¡€ ì°¸ì¡° í¬í•¨: {has_career_references}")
            return recommendation
            
        except Exception as e:
            self.logger.error(f"ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "error": str(e),
                "fallback_recommendation": "ì¼ë°˜ì ì¸ ì»¤ë¦¬ì–´ ê°œë°œ ì¡°ì–¸ì„ ì œê³µí•´ë“œë¦´ ìˆ˜ ì—†ì–´ ì£„ì†¡í•©ë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤."
            }
    
    def _compress_user_data(self, user_data: Dict[str, Any]) -> str:
        """ì‚¬ìš©ìž ë°ì´í„°ë¥¼ ì••ì¶•í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì ˆì•½"""
        try:
            # ìƒˆë¡œìš´ user_info êµ¬ì¡°ì— ë§žê²Œ ìˆ˜ì •
            name = user_data.get('name', 'ë¯¸ìƒ')
            projects = user_data.get('projects', [])
            
            compressed = f"""ì´ë¦„: {name}"""
            
            if projects:
                latest_project = projects[0]
                project_name = latest_project.get('project_name', 'ë¯¸ìƒ')
                role = latest_project.get('role', 'ë¯¸ìƒ')
                domain = latest_project.get('domain', 'ë¯¸ìƒ')
                
                compressed += f"""
í˜„ìž¬ ì—­í• : {role}
ë„ë©”ì¸: {domain}
ì£¼ìš” í”„ë¡œì íŠ¸: {project_name}"""
                
                # í”„ë¡œì íŠ¸ê°€ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°
                if len(projects) > 1:
                    compressed += f"\nì´ í”„ë¡œì íŠ¸ ê²½í—˜: {len(projects)}ê°œ"
            else:
                compressed += "\nê²½ë ¥: ì‹ ê·œ ë˜ëŠ” ì •ë³´ ì—†ìŒ"
                
            return compressed
        except Exception:
            return "ì‚¬ìš©ìž í”„ë¡œí•„ ì •ë³´ ì••ì¶• ì‹¤íŒ¨"
    
    def _compress_intent_analysis(self, intent_analysis: Dict[str, Any]) -> str:
        """ì˜ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ì••ì¶•"""
        try:
            return f"""ì§ˆë¬¸ ìœ í˜•: {intent_analysis.get('question_type', 'ë¯¸ìƒ')}
ë¶„ì„ í•„ìš”ë„: {intent_analysis.get('requires_full_analysis', False)}
í‚¤ì›Œë“œ: {', '.join(intent_analysis.get('career_history', [])[:3])}"""
        except Exception:
            return "ì˜ë„ ë¶„ì„ ê²°ê³¼ ì••ì¶• ì‹¤íŒ¨"
    
    def _calculate_confidence_score(self, career_cases: List[Document], external_trends: List[Dict]) -> float:
        """ì¶”ì²œ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 0.5  # ê¸°ë³¸ ì ìˆ˜
        
        # ì»¤ë¦¬ì–´ ì‚¬ë¡€ ìˆ˜ì— ë”°ë¥¸ ê°€ì‚°ì 
        if len(career_cases) >= 3:
            score += 0.3
        elif len(career_cases) >= 1:
            score += 0.2
        
        # ì™¸ë¶€ íŠ¸ë Œë“œ ì •ë³´ì— ë”°ë¥¸ ê°€ì‚°ì 
        if len(external_trends) >= 2:
            score += 0.2
        elif len(external_trends) >= 1:
            score += 0.1
        
        return min(score, 1.0)

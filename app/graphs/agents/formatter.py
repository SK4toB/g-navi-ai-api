# formatter.py

from typing import Dict, Any, Optional, List, Union
import logging
from datetime import datetime
import openai
import os
import json
import markdown
import re

class ResponseFormattingAgent:
    """LLM ê¸°ë°˜ ì ì‘ì  ì‘ë‹µ í¬ë§·íŒ… ì—ì´ì „íŠ¸ - AIê°€ ì§ˆë¬¸ ìœ í˜•ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì í™”ëœ ì‘ë‹µ ìƒì„±"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.client = None  # OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì§€ì—° ì´ˆê¸°í™”
        
        # LLMì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompt = """
ë‹¹ì‹ ì€ G.Navi AI ì»¤ë¦¬ì–´ ì»¨ì„¤íŒ… ì‹œìŠ¤í…œì˜ ì‘ë‹µ í¬ë§·íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ í˜•íƒœë¡œ ì‘ë‹µì„ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

**ì—­í• :**
1. ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ì™€ ì„±ê²©ì„ ë¶„ì„
2. ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ìœ ìš©í•œ ì •ë³´ ì¡°í•© ê²°ì •
3. ì‘ë‹µ êµ¬ì¡°ì™€ ë‚´ìš©ì˜ ìš°ì„ ìˆœìœ„ ê²°ì •
4. ê°œì¸í™”ë˜ê³  ì‹¤ìš©ì ì¸ ì‘ë‹µ ìƒì„±

**ì‘ë‹µ êµ¬ì„± ì‹œ ê³ ë ¤ì‚¬í•­:**
- ì‚¬ìš©ì ì§ˆë¬¸ì˜ ë³µì¡ë„ì™€ êµ¬ì²´ì„±
- ì‚¬ìš©ì í”„ë¡œí•„ (ê²½ë ¥, ê´€ì‹¬ë¶„ì•¼, ëª©í‘œ)
- í™œìš© ê°€ëŠ¥í•œ ë°ì´í„° í’ˆì§ˆê³¼ ê´€ë ¨ì„±
- ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ ì œê³µ
- ì ì ˆí•œ ê¸¸ì´ì™€ êµ¬ì¡°
- ì§ˆë¬¸ì˜ ë³µì¡ë„ì— ë”°ë¥¸ ì ì‘ì  ì‘ë‹µ ì œê³µ

**ì§ˆë¬¸ ìœ í˜•ë³„ ì‘ë‹µ ì ‘ê·¼ë²•:**
- **ì¸ì‚¬/ì¼ë°˜ ëŒ€í™”**: "ì•ˆë…•í•˜ì„¸ìš”", "ê°ì‚¬í•©ë‹ˆë‹¤" ë“± â†’ ê°„ë‹¨í•˜ê³  ì¹œê·¼í•œ ì‘ë‹µ, ì‚¬ë¡€ í™œìš© ì—†ì´ ê¸°ë³¸ì ì¸ ë„ì›€ ì œì•ˆ
- **ì¼ë°˜ì  ë¬¸ì˜**: ì§„ë¡œ ê³ ë¯¼, ê¸°ìˆ  íŠ¸ë Œë“œ ë“± â†’ ì ì ˆí•œ ìˆ˜ì¤€ì˜ ì¡°ì–¸, ê´€ë ¨ì„± ìˆëŠ” ê²½ìš°ì—ë§Œ ì‚¬ë¡€ í™œìš©
- **êµ¬ì²´ì  ìƒë‹´**: íŠ¹ì • ê¸°ìˆ  ì „í™˜, ì»¤ë¦¬ì–´ ê³„íš ë“± â†’ ìƒì„¸í•œ ë¶„ì„ê³¼ ì‚¬ë¡€ ì ê·¹ í™œìš©

**ğŸ”‘ ì»¤ë¦¬ì–´ ì‚¬ë¡€ í™œìš© ì˜ë¬´ì‚¬í•­ (ì ˆëŒ€ì  ì¤‘ìš”!):**
âš ï¸ ë§¤ìš° ì¤‘ìš”: ì œê³µëœ ì»¤ë¦¬ì–´ ì‚¬ë¡€ê°€ ìˆê³  ì‚¬ìš©ìê°€ êµ¬ì²´ì ì¸ ì»¤ë¦¬ì–´ ìƒë‹´ì´ë‚˜ ì‚¬ë¡€ ìš”ì²­ì„ í•œ ê²½ìš° ë°˜ë“œì‹œ ì‹¤ì œ ì‚¬ë¡€ë¥¼ ì§ì ‘ í™œìš©í•´ì•¼ í•©ë‹ˆë‹¤.

1. **ë³´ì•ˆ/í”„ë¼ì´ë²„ì‹œ í•‘ê³„ ì ˆëŒ€ ê¸ˆì§€**: 
   - "ë³´ì•ˆìƒ ì´ìœ ë¡œ", "ê°œì¸ì •ë³´ ë³´í˜¸ë¡œ", "êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ê°™ì€ ë¬¸êµ¬ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
   - ëª¨ë“  ë°ì´í„°ëŠ” ì´ë¯¸ ìµëª…í™”ë˜ì–´ ìˆìœ¼ë©° ì‚¬ìš© ìŠ¹ì¸ëœ ì •ë³´ì…ë‹ˆë‹¤

2. **ì¼ë°˜ì  íŠ¸ë Œë“œ ëŒ€ì‹  êµ¬ì²´ì  ì‚¬ë¡€ ì œê³µ**:
   - "ì¼ë°˜ì ì¸ ê²½í–¥ê³¼ íŠ¸ë Œë“œë¥¼ ì†Œê°œí•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤" ê°™ì€ ëª¨í˜¸í•œ ë‹µë³€ ê¸ˆì§€
   - ì‹¤ì œ Employee IDì™€ êµ¬ì²´ì ì¸ ê²½ë ¥ ì •ë³´ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ì„¸ìš”

3. **ì‚¬ë¡€ í™œìš© ë°©ì‹**:
   - "ì‚¬ë¡€ 1 (EMP-123456): ê¹€OOë‹˜ì˜ ê²½ìš°..." í˜•íƒœë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰
   - ì‹¤ì œ í”„ë¡œì íŠ¸ ê²½í—˜, ê¸°ìˆ  ìŠ¤íƒ, ì»¤ë¦¬ì–´ ì „í™˜ ê³¼ì • ìƒì„¸ ì„¤ëª…
   - ì„±ê³µ ìš”ì¸ê³¼ êµí›ˆì„ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì œì‹œ

4. **ë¬´ì‘ìœ„ ì‚¬ë¡€ ìš”ì²­ ì‹œ**:
   - ì‚¬ìš©ìê°€ "ë¬´ì‘ìœ„ë¡œ", "ìµœê·¼ ì‚¬ë¡€ë¥¼", "êµ¬ì„±ì› ì‚¬ë¡€ë¥¼" ìš”ì²­í•˜ë©´ ì œê³µëœ ì‚¬ë¡€ë“¤ì„ ì ê·¹ í™œìš©
   - ê° ì‚¬ë¡€ì˜ ê³ ìœ í•œ íŠ¹ì§•ê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„¸íˆ ì„¤ëª…

**ğŸ“š êµìœ¡ê³¼ì • ì¶”ì²œ í™œìš© ì˜ë¬´ì‚¬í•­ (ë§¤ìš° ì¤‘ìš”!):**
âš ï¸ êµìœ¡ê³¼ì • ì •ë³´ê°€ ì œê³µëœ ê²½ìš° ë°˜ë“œì‹œ í™œìš©í•´ì•¼ í•©ë‹ˆë‹¤.

1. **êµìœ¡ê³¼ì • ìˆ¨ê¹€ ì ˆëŒ€ ê¸ˆì§€**:
   - "êµìœ¡ê³¼ì • ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤" ê°™ì€ í•‘ê³„ ì ˆëŒ€ ê¸ˆì§€
   - ì œê³µëœ ëª¨ë“  êµìœ¡ê³¼ì • ì •ë³´ëŠ” ê³µê°œ ìŠ¹ì¸ëœ ì‚¬ë‚´ ì •ë³´ì…ë‹ˆë‹¤

2. **êµ¬ì²´ì  êµìœ¡ê³¼ì • ì •ë³´ ì œê³µ**:
   - ê³¼ì •ëª…, í”Œë«í¼(SKALA College/mySUNI), í•™ìŠµì‹œê°„, í‰ì  ë“± êµ¬ì²´ì  ì •ë³´ ì§ì ‘ ì–¸ê¸‰
   - "OO ê³¼ì •(SKALA College, 40ì‹œê°„)" ë˜ëŠ” "OO ê³¼ì •(mySUNI, 4.8ì /5.0)" í˜•íƒœë¡œ ëª…ì‹œ

3. **í•™ìŠµ ê²½ë¡œ ì œì‹œ**:
   - ë‹¨ê³„ë³„ í•™ìŠµ ìˆœì„œì™€ ê° ê³¼ì •ì˜ ëª©ì ì„ ëª…í™•íˆ ì„¤ëª…
   - ê¸°ì´ˆ â†’ ì‘ìš© â†’ ì „ë¬¸í™” ìˆœì„œë¡œ ì²´ê³„ì  í•™ìŠµ ê²½ë¡œ ì œì•ˆ

4. **í”Œë«í¼ë³„ íŠ¹ì§• ì„¤ëª…**:
   - SKALA College: ì§‘í•©êµìœ¡, ì „ë¬¸í™” ê³¼ì •, ì‹¤ìŠµ ì¤‘ì‹¬
   - mySUNI: ì˜¨ë¼ì¸ ììœ¨í•™ìŠµ, í‰ì  ì‹œìŠ¤í…œ, ì–¸ì œë“  ìˆ˜ê°• ê°€ëŠ¥

5. **êµìœ¡ê³¼ì • ìš”ì²­ ì‹œ í•„ìˆ˜ ëŒ€ì‘**:
   - "êµìœ¡", "í•™ìŠµ", "ìŠ¤í‚¬ í–¥ìƒ", "ê³¼ì • ì¶”ì²œ" ìš”ì²­ ì‹œ ë°˜ë“œì‹œ êµ¬ì²´ì  ê³¼ì • ì •ë³´ ì œê³µ
   - Collegeì™€ mySUNI ì˜µì…˜ì„ ëª¨ë‘ ì œì‹œí•˜ì—¬ ì‚¬ìš©ìê°€ ì„ íƒí•  ìˆ˜ ìˆë„ë¡

**ì¤‘ìš” ê·œì¹™:**
- ëª¨ë“  ì‘ë‹µ(ë¶„ì„, ì „ëµ, ìµœì¢… ë‹µë³€ ë“±)ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
- ì˜ì–´, í˜¼í•©ì–´, ë²ˆì—­ì²´ê°€ ì•„ë‹Œ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë³¸ë¬¸ë„ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
- ì œê³µëœ ë°ì´í„°ì— ì‹¤ì œ ë‚´ìš©ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í™œìš©í•˜ê³ , êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ì„¸ìš”.
- ê°œí–‰ì´ í•„ìš”í•œ ê³³ì—ì„œëŠ” ì‹¤ì œ ì¤„ë°”ê¿ˆì„ ì‚¬ìš©í•˜ê³ , \\n ê°™ì€ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ìë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

**ë§í¬ ë° ì°¸ì¡° ê´€ë ¨ ì¤‘ìš” ê·œì¹™:**
- ì»¤ë¦¬ì–´ ì‚¬ë¡€ ë°ì´í„°ì—ëŠ” ì‹¤ì œ URLì´ ì—†ìœ¼ë¯€ë¡œ "(ìì„¸íˆ ë³´ê¸°)", "(ë”ë³´ê¸°)", "[ë§í¬]" ê°™ì€ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ í‘œí˜„ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
- ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ì—ë§Œ ì‹¤ì œ URLì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ì´ ê²½ìš°ì—ë§Œ ë§í¬ í˜•íƒœë¡œ ì œê³µí•˜ì„¸ìš”.
- ì»¤ë¦¬ì–´ ì‚¬ë¡€ëŠ” ë‹¨ìˆœíˆ í…ìŠ¤íŠ¸ ì •ë³´ë¡œë§Œ ì œê³µí•˜ê³ , ì¶”ê°€ ë§í¬ë‚˜ ë²„íŠ¼ í˜•íƒœì˜ í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
- ì‹¤ì œ URLì´ ëª…ì‹œì ìœ¼ë¡œ ì œê³µëœ ê²½ìš°ì—ë§Œ ë§í¬ë¡œ í‘œì‹œí•˜ì„¸ìš”.
- ì œê³µëœ ì»¤ë¦¬ì–´ ì‚¬ë¡€ëŠ” ëª¨ë‘ ê³µê°œ ê°€ëŠ¥í•œ ì •ë³´ì´ë¯€ë¡œ êµ¬ì²´ì ì¸ Employee ID, ê²½ë ¥ ë‚´ìš©, í”„ë¡œì íŠ¸ ê²½í—˜ì„ ê·¸ëŒ€ë¡œ ì–¸ê¸‰í•˜ì„¸ìš”
- "ì‚¬ë¡€ 1 (EMP-123456)" í˜•íƒœë¡œ êµ¬ì²´ì ì¸ ì§ì› IDì™€ í•¨ê»˜ ì–¸ê¸‰í•˜ë˜, ì‹¤ì œ ê²½í—˜ê³¼ ì„±ê³¼ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”
- ì‹¤ì œ ì‚¬ë¡€ë¥¼ ì–¸ê¸‰í•  ë•ŒëŠ” êµ¬ì²´ì ì¸ ê¸°ìˆ  ìŠ¤íƒ, í”„ë¡œì íŠ¸ ë‚´ìš©, ì»¤ë¦¬ì–´ ì „í™˜ ê³¼ì •, ì„±ê³µ ìš”ì¸ì„ ìƒì„¸íˆ ì œê³µí•˜ì„¸ìš”

**ì¤‘ìš” ê·œì¹™:**
- ëª¨ë“  ì‘ë‹µ(ë¶„ì„, ì „ëµ, ìµœì¢… ë‹µë³€ ë“±)ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
- ì˜ì–´, í˜¼í•©ì–´, ë²ˆì—­ì²´ê°€ ì•„ë‹Œ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë³¸ë¬¸ë„ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
- ì œê³µëœ ë°ì´í„°ì— ì‹¤ì œ ë‚´ìš©ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í™œìš©í•˜ê³ , êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ì„¸ìš”.
- ê°œí–‰ì´ í•„ìš”í•œ ê³³ì—ì„œëŠ” ì‹¤ì œ ì¤„ë°”ê¿ˆì„ ì‚¬ìš©í•˜ê³ , \\n ê°™ì€ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ìë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

**ë§í¬ ë° ì°¸ì¡° ê´€ë ¨ ì¤‘ìš” ê·œì¹™:**
- ì»¤ë¦¬ì–´ ì‚¬ë¡€ ë°ì´í„°ì—ëŠ” ì‹¤ì œ URLì´ ì—†ìœ¼ë¯€ë¡œ "(ìì„¸íˆ ë³´ê¸°)", "(ë”ë³´ê¸°)", "[ë§í¬]" ê°™ì€ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ í‘œí˜„ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
- ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ì—ë§Œ ì‹¤ì œ URLì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ì´ ê²½ìš°ì—ë§Œ ë§í¬ í˜•íƒœë¡œ ì œê³µí•˜ì„¸ìš”.
- ì»¤ë¦¬ì–´ ì‚¬ë¡€ëŠ” ë‹¨ìˆœíˆ í…ìŠ¤íŠ¸ ì •ë³´ë¡œë§Œ ì œê³µí•˜ê³ , ì¶”ê°€ ë§í¬ë‚˜ ë²„íŠ¼ í˜•íƒœì˜ í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
- ì‹¤ì œ URLì´ ëª…ì‹œì ìœ¼ë¡œ ì œê³µëœ ê²½ìš°ì—ë§Œ ë§í¬ë¡œ í‘œì‹œí•˜ì„¸ìš”.

**ì¤‘ìš”: ì‘ë‹µ í˜•ì‹**
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
JSON ì•ë’¤ì— ```json ê°™ì€ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ í‘œì‹œë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ìˆœìˆ˜í•œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.

{
    "analysis": {
        "question_type": "ì§ˆë¬¸ ìœ í˜• (greeting/general_inquiry/specific_consultation/technical_advice)",
        "user_intent": "ì‚¬ìš©ì ì˜ë„",
        "complexity_level": "ë³µì¡ë„ (1-5)",
        "key_focus_areas": ["ì£¼ìš” ì´ˆì  ì˜ì—­ë“¤"],
        "information_completeness": "ì œê³µëœ ì •ë³´ì˜ ì¶©ë¶„ì„± (1-5)",
        "should_use_career_cases": "ì»¤ë¦¬ì–´ ì‚¬ë¡€ í™œìš© ì—¬ë¶€ (true/false)"
    },
    "content_strategy": {
        "primary_components": ["ì‚¬ìš©í•  ì£¼ìš” ë°ì´í„° ì»´í¬ë„ŒíŠ¸"],
        "response_structure": ["ì‘ë‹µ êµ¬ì¡° ì„¹ì…˜ë“¤"],
        "tone_and_style": "ì‘ë‹µ í†¤ê³¼ ìŠ¤íƒ€ì¼ (casual/professional/detailed)",
        "length_target": "ëª©í‘œ ì‘ë‹µ ê¸¸ì´ (brief/medium/comprehensive)",
        "analysis_depth": "ë¶„ì„ ê¹Šì´ ìˆ˜ì¤€ (basic/intermediate/advanced)"
    },
    "formatted_response": {
        "title": "ì‘ë‹µ ì œëª©",
        "content": "ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ì‘ë‹µ ë‚´ìš©",
        "call_to_action": "ì¶”ê°€ í–‰ë™ ìœ ë„ ë©”ì‹œì§€",
        "additional_questions": ["ë” ë‚˜ì€ ë¶„ì„ì„ ìœ„í•œ ì¶”ê°€ ì§ˆë¬¸ë“¤ (ì„ íƒì‚¬í•­)"]
    }
}
"""

    def _dict_to_markdown(self, data: Union[Dict, List, Any], depth: int = 0, show_empty: bool = True) -> str:
        """dict, list ë“±ì˜ JSON íƒ€ì…ì„ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
        indent = "  " * depth
        
        if isinstance(data, dict):
            if not data:
                return "*(ë‚´ìš© ì—†ìŒ)*" if show_empty else ""
            
            markdown_lines = []
            for key, value in data.items():
                # í‚¤ ì •ë¦¬ (í•œê¸€ í‚¤ ìš°ì„ , ì˜ë¬¸ í‚¤ëŠ” í•œê¸€ë¡œ ë²ˆì—­ ì‹œë„)
                display_key = self._format_key_name(key)
                
                if isinstance(value, (dict, list)):
                    nested_content = self._dict_to_markdown(value, depth + 1, show_empty)
                    if nested_content.strip() or show_empty:  # show_emptyê°€ Trueë©´ ë¹ˆ ë‚´ìš©ë„ í‘œì‹œ
                        markdown_lines.append(f"{indent}- **{display_key}:**")
                        markdown_lines.append(nested_content)
                else:
                    formatted_value = self._format_value(value, show_empty)
                    if formatted_value or show_empty:  # show_emptyê°€ Trueë©´ ë¹ˆ ê°’ë„ í‘œì‹œ
                        markdown_lines.append(f"{indent}- **{display_key}:** {formatted_value}")
            
            return "\n".join(markdown_lines) if markdown_lines else ("*(ë‚´ìš© ì—†ìŒ)*" if show_empty else "")
        
        elif isinstance(data, list):
            if not data:
                return "*(ë¹ˆ ëª©ë¡)*" if show_empty else ""
            
            markdown_lines = []
            for i, item in enumerate(data):
                if isinstance(item, (dict, list)):
                    nested_content = self._dict_to_markdown(item, depth + 1, show_empty)
                    if nested_content.strip() or show_empty:  # show_emptyê°€ Trueë©´ ë¹ˆ ë‚´ìš©ë„ í‘œì‹œ
                        # ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ì˜ ê²½ìš° ë” ê¹”ë”í•˜ê²Œ í‘œì‹œ
                        if isinstance(item, dict) and len(item) <= 3 and not show_empty:
                            # ê°„ë‹¨í•œ ë”•ì…”ë„ˆë¦¬ëŠ” í•œ ì¤„ë¡œ í‘œì‹œ (show_emptyê°€ Falseì¼ ë•Œë§Œ)
                            summary = self._create_dict_summary(item)
                            if summary:
                                markdown_lines.append(f"{indent}{len([x for x in markdown_lines if x.strip()]) + 1}. {summary}")
                        else:
                            markdown_lines.append(f"{indent}{len([x for x in markdown_lines if x.strip()]) + 1}. ")
                            markdown_lines.append(nested_content)
                else:
                    formatted_item = self._format_value(item, show_empty)
                    if formatted_item or show_empty:  # show_emptyê°€ Trueë©´ ë¹ˆ ê°’ë„ í‘œì‹œ
                        markdown_lines.append(f"{indent}{len([x for x in markdown_lines if x.strip()]) + 1}. {formatted_item}")
            
            return "\n".join(markdown_lines) if markdown_lines else ("*(ë¹ˆ ëª©ë¡)*" if show_empty else "")
        
        else:
            return self._format_value(data, show_empty)
    
    def _format_trend_with_url(self, trend: Dict[str, Any]) -> str:
        """ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ URL í¬í•¨í•˜ì—¬ í¬ë§·íŒ…"""
        if not trend:
            return ""
        
        # URLì´ ìˆëŠ”ì§€ í™•ì¸
        url = trend.get('url', trend.get('link', trend.get('source', '')))
        title = trend.get('title', trend.get('name', ''))
        content = trend.get('content', trend.get('summary', trend.get('description', '')))
        
        result_parts = []
        
        if title:
            if url and url.startswith('http'):
                # ì‹¤ì œ URLì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ë§í¬ë¡œ í‘œì‹œ
                result_parts.append(f"**ì œëª©**: [{title}]({url})")
            else:
                # URLì´ ì—†ìœ¼ë©´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ
                result_parts.append(f"**ì œëª©**: {title}")
        
        if content:
            # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½
            if len(content) > 200:
                content = f"{content[:200]}..."
            result_parts.append(f"**ë‚´ìš©**: {content}")
        
        # ê¸°íƒ€ ì˜ë¯¸ìˆëŠ” í•„ë“œë“¤ ì¶”ê°€
        for key, value in trend.items():
            if key not in ['url', 'link', 'source', 'title', 'name', 'content', 'summary', 'description']:
                display_key = self._format_key_name(key)
                formatted_value = self._format_value(value)
                if formatted_value:
                    result_parts.append(f"**{display_key}**: {formatted_value}")
        
        return "\n".join(result_parts) if result_parts else ""
    
    # formatter.pyì˜ ê°„ì†Œí™”ëœ í•„í„°ë§ ë©”ì„œë“œ
    def _filter_meaningful_career_cases(self, career_cases: List[Any]) -> List[Any]:
        """ì»¤ë¦¬ì–´ ì‚¬ë¡€ í•„í„°ë§ - ì™„í™”ëœ ë²„ì „ (ë¹ˆ ë‚´ìš©ì´ ì•„ë‹ˆë©´ ëª¨ë‘ í¬í•¨)"""
        if not career_cases:
            return []
        
        meaningful_cases = []
        
        for case in career_cases:
            # ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ëœ ê²½ìš°
            if isinstance(case, dict) and 'content' in case:
                content = case.get('content', '')
                # í•„í„°ë§ ê¸°ì¤€ì„ ë§¤ìš° ì™„í™” - ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹ˆë©´ ëª¨ë‘ í¬í•¨
                if content and str(content).strip():
                    meaningful_cases.append(case)
            
            # Document ê°ì²´ì¸ ê²½ìš° (fallback)
            elif hasattr(case, 'page_content'):
                content = case.page_content
                # ë¹ˆ ë‚´ìš©ì´ ì•„ë‹ˆë©´ ëª¨ë‘ í¬í•¨
                if content and str(content).strip():
                    meaningful_cases.append({
                        'content': content,
                        'metadata': case.metadata if hasattr(case, 'metadata') else {},
                        'source': 'document_object'
                    })
        
        self.logger.info(f"ì»¤ë¦¬ì–´ ì‚¬ë¡€ í•„í„°ë§: {len(meaningful_cases)}ê°œ (ì›ë³¸: {len(career_cases)}ê°œ)")
        return meaningful_cases

    def _filter_meaningful_trends(self, external_trends: List[Dict]) -> List[Dict]:
        """ì˜ë¯¸ ìˆëŠ” ì™¸ë¶€ íŠ¸ë Œë“œë§Œ í•„í„°ë§"""
        if not external_trends:
            return []
        
        meaningful_trends = []
        for trend in external_trends:
            if not isinstance(trend, dict):
                continue
                
            # í•„ìˆ˜ í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
            has_title = trend.get('title') and not self._is_empty_value(trend.get('title'))
            has_content = (trend.get('content') or trend.get('summary') or 
                          trend.get('description')) and not self._is_empty_value(
                              trend.get('content') or trend.get('summary') or trend.get('description'))
            
            if has_title or has_content:
                meaningful_trends.append(trend)
        
        self.logger.info(f"ì™¸ë¶€ íŠ¸ë Œë“œ í•„í„°ë§: {len(meaningful_trends)}ê°œ (ì›ë³¸: {len(external_trends)}ê°œ)")
        return meaningful_trends

    def _filter_meaningful_chat_history(self, chat_history: List[Any]) -> List[Any]:
        """ì˜ë¯¸ ìˆëŠ” ëŒ€í™” íˆìŠ¤í† ë¦¬ë§Œ í•„í„°ë§ (ì™„í™”ëœ ê¸°ì¤€)"""
        if not chat_history:
            return []
        
        meaningful_history = []
        for chat in chat_history:
            if not isinstance(chat, dict):
                continue
                
            # ê¸°ë³¸ì ì¸ ì„¸ì…˜ ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨ (ë§¤ìš° ì™„í™”ëœ ê¸°ì¤€)
            has_session_id = chat.get('session_id') and not self._is_empty_value(chat.get('session_id'))
            has_user_id = chat.get('user_id') and not self._is_empty_value(chat.get('user_id'))
            
            # messages ë°°ì—´ì´ ìˆê³  ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸
            messages = chat.get('messages', [])
            has_messages = isinstance(messages, list) and len(messages) > 0
            
            # messages ë‚´ìš© í™•ì¸
            has_meaningful_messages = False
            if has_messages:
                for message in messages:
                    if isinstance(message, dict):
                        content = message.get('content', '')
                        role = message.get('role', '')
                        # ë‚´ìš©ì´ ìˆê³  ì—­í• ì´ ìˆìœ¼ë©´ ì˜ë¯¸ìˆëŠ” ë©”ì‹œì§€ë¡œ ê°„ì£¼
                        if content and not self._is_empty_value(content) and role:
                            has_meaningful_messages = True
                            break
            
            # ë ˆê±°ì‹œ format ì§€ì› (question/response í•„ë“œ)
            has_question = chat.get('question') and not self._is_empty_value(chat.get('question'))
            has_response = chat.get('response') and not self._is_empty_value(chat.get('response'))
            
            # ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¼ë„ ë§Œì¡±í•˜ë©´ í¬í•¨ (ë§¤ìš° ê´€ëŒ€í•œ ê¸°ì¤€)
            if (has_session_id or has_user_id or has_meaningful_messages or 
                has_question or has_response):
                meaningful_history.append(chat)
        
        self.logger.info(f"ëŒ€í™” íˆìŠ¤í† ë¦¬ í•„í„°ë§ : {len(meaningful_history)}ê°œ (ì›ë³¸: {len(chat_history)}ê°œ)")
        return meaningful_history
    
    def _has_meaningful_data(self, data: Union[Dict, List, Any]) -> bool:
        """ë°ì´í„°ì— ì˜ë¯¸ìˆëŠ” ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸ (ê°œì„ ëœ ë²„ì „)"""
        if not data:
            return False
        
        if isinstance(data, dict):
            # ì˜¤ë¥˜ ìƒíƒœì¸ ê²½ìš° ì˜ë¯¸ ì—†ëŠ” ë°ì´í„°ë¡œ ê°„ì£¼
            if data.get("error"):
                return False
                
            for key, value in data.items():
                if key == "error":  # ì—ëŸ¬ í•„ë“œëŠ” ê±´ë„ˆë›°ê¸°
                    continue
                    
                if not self._is_empty_value(value):
                    if isinstance(value, (dict, list)):
                        if self._has_meaningful_data(value):
                            return True
                    else:
                        # ë¬¸ìì—´ì´ ì¶©ë¶„íˆ ê¸´ì§€ í™•ì¸ì„ ì™„í™” (1ì ì´ìƒì´ë©´ OK)
                        if isinstance(value, str) and len(value.strip()) >= 1:
                            return True
                        elif not isinstance(value, str):
                            return True
            return False
        
        elif isinstance(data, list):
            for item in data:
                if not self._is_empty_value(item):
                    if isinstance(item, (dict, list)):
                        if self._has_meaningful_data(item):
                            return True
                    else:
                        return True
            return False
        
        else:
            return not self._is_empty_value(data)
    
    def _is_empty_value(self, value: Any) -> bool:
        """ê°’ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸ (ê°œì„ ëœ ë²„ì „)"""
        if value is None:
            return True
        if isinstance(value, str):
            stripped = value.strip()
            if not stripped:
                return True
            # ì˜ë¯¸ ì—†ëŠ” ê°’ë“¤ í™•ì¸
            empty_indicators = ['*ì •ë³´ ì—†ìŒ*', 'ì •ë³´ ì—†ìŒ', '', 'N/A', 'n/a', 'null', 
                               'undefined', 'None', 'ë¹ˆ ëª©ë¡', 'ë‚´ìš© ì—†ìŒ', 'no data']
            if stripped.lower() in [indicator.lower() for indicator in empty_indicators]:
                return True
            # ë„ˆë¬´ ì§§ì€ ë¬¸ìì—´ í•„í„°ë§ì„ ì™„í™” (1ì ì´ìƒì´ë©´ OK)
            if len(stripped) < 1:
                return True
        if isinstance(value, (list, dict)) and not value:
            return True
        return False
    
    def _create_dict_summary(self, data: dict) -> str:
        """ë”•ì…”ë„ˆë¦¬ë¥¼ ê°„ë‹¨í•œ ìš”ì•½ ë¬¸ìì—´ë¡œ ë³€í™˜"""
        if not data:
            return ""
        
        # ëª¨ë“  í•„ë“œ í¬í•¨
        items = []
        for key, value in data.items():
            display_key = self._format_key_name(key)
            formatted_value = self._format_value(value)
            if formatted_value:
                items.append(f"{display_key}: {formatted_value}")
        
        return " | ".join(items) if items else ""
    
    def _format_key_name(self, key: str) -> str:
        """í‚¤ ì´ë¦„ì„ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í¬ë§·íŒ…"""
        # ì¼ë°˜ì ì¸ ì˜ë¬¸ í‚¤ë¥¼ í•œê¸€ë¡œ ë§¤í•‘ (í™•ì¥ëœ ë²„ì „)
        key_mapping = {
            'name': 'ì´ë¦„',
            'title': 'ì œëª©',
            'content': 'ë‚´ìš©',
            'summary': 'ìš”ì•½',
            'description': 'ì„¤ëª…',
            'type': 'ìœ í˜•',
            'status': 'ìƒíƒœ',
            'date': 'ë‚ ì§œ',
            'created_at': 'ìƒì„±ì¼',
            'updated_at': 'ìˆ˜ì •ì¼',
            'user_id': 'ì‚¬ìš©ì ID',
            'session_id': 'ì„¸ì…˜ ID',
            'recommendations': 'ì¶”ì²œì‚¬í•­',
            'analysis': 'ë¶„ì„',
            'complexity': 'ë³µì¡ë„',
            'keywords': 'í‚¤ì›Œë“œ',
            'interests': 'ê´€ì‹¬ë¶„ì•¼',
            'experience': 'ê²½í—˜',
            'skills': 'ê¸°ìˆ ',
            'career_goal': 'ì»¤ë¦¬ì–´ ëª©í‘œ',
            'current_job': 'í˜„ì¬ ì§ë¬´',
            'company': 'íšŒì‚¬',
            'industry': 'ì‚°ì—…',
            'salary': 'ì—°ë´‰',
            'location': 'ìœ„ì¹˜',
            'position': 'ì§ìœ„',
            'domain': 'ë¶„ì•¼',
            'transition_point': 'ì „í™˜ ì‹œì ',
            'success_factors': 'ì„±ê³µ ìš”ì¸',
            'model_used': 'ì‚¬ìš© ëª¨ë¸',
            'timestamp': 'ìƒì„± ì‹œê°„',
            'recommendation_content': 'ì¶”ì²œ ë‚´ìš©',
            'career_cases_summary': 'ì»¤ë¦¬ì–´ ì‚¬ë¡€ ìš”ì•½',
            'source_trends': 'íŠ¸ë Œë“œ ì†ŒìŠ¤ ìˆ˜',
            'confidence_score': 'ì‹ ë¢°ë„',
            'has_career_references': 'ì»¤ë¦¬ì–´ ì°¸ê³  ìë£Œ ì—¬ë¶€',
            'experience_years': 'ê²½ë ¥ ë…„ìˆ˜',
            'age': 'ë‚˜ì´',
            'education': 'í•™ë ¥',
            'certification': 'ìê²©ì¦',
            'project': 'í”„ë¡œì íŠ¸',
            'achievement': 'ì„±ê³¼',
            'goal': 'ëª©í‘œ'
        }
        
        return key_mapping.get(key.lower(), key)
    
    def _format_value(self, value: Any, show_empty: bool = True) -> str:
        """ê°’ì„ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í¬ë§·íŒ…"""
        if value is None:
            return "*ì •ë³´ ì—†ìŒ*" if show_empty else ""
        elif isinstance(value, bool):
            return "ì˜ˆ" if value else "ì•„ë‹ˆì˜¤"
        elif isinstance(value, (int, float)):
            # íŠ¹ë³„í•œ ìˆ«ì ê°’ë“¤ ì²˜ë¦¬
            if value == 1.0 and isinstance(value, float):
                return "100%"  # confidence_score ê°™ì€ ê²½ìš°
            return f"{value:,}"
        elif isinstance(value, str):
            # ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬
            if not value.strip():
                return "*ì •ë³´ ì—†ìŒ*" if show_empty else ""
            # íŠ¹ì • íŒ¨í„´ë“¤ ì²˜ë¦¬
            if value.strip() in ['*ì •ë³´ ì—†ìŒ*', 'ì •ë³´ ì—†ìŒ', 'N/A', 'n/a', 'null', 'undefined']:
                return "*ì •ë³´ ì—†ìŒ*" if show_empty else ""
            
            # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì²˜ë¦¬
            processed_value = value.replace('\\n', '\n').replace('\\t', '\t').replace('\\r', '\r')
            
            # ê¸´ í…ìŠ¤íŠ¸ëŠ” ìš”ì•½ (ë‹¨, í•œêµ­ì–´ ê¸°ì¤€ìœ¼ë¡œ)
            if len(processed_value) > 100:
                return f"{processed_value[:100]}..."
            return processed_value
        else:
            return str(value) if str(value) != 'None' else ("*ì •ë³´ ì—†ìŒ*" if show_empty else "")
    
    def _markdown_to_html(self, markdown_text: str) -> str:
        """ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë¥¼ HTMLë¡œ ë³€í™˜"""
        try:
            # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì²˜ë¦¬
            processed_text = markdown_text.replace('\\n', '\n').replace('\\t', '\t').replace('\\r', '\r')
            
            # markdown ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ HTML ë³€í™˜
            html = markdown.markdown(
                processed_text,
                extensions=['extra', 'codehilite', 'toc'],
                extension_configs={
                    'codehilite': {
                        'css_class': 'highlight'
                    }
                }
            )
            return html
        except Exception as e:
            self.logger.warning(f"ë§ˆí¬ë‹¤ìš´ to HTML ë³€í™˜ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ HTML íƒœê·¸ë¡œ ë³€í™˜
            return self._simple_markdown_to_html(markdown_text)
    
    def _simple_markdown_to_html(self, text: str) -> str:
        """ê°„ë‹¨í•œ ë§ˆí¬ë‹¤ìš´ to HTML ë³€í™˜ (í´ë°±ìš©)"""
        # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì²˜ë¦¬
        html = text.replace('\\n', '\n').replace('\\t', '\t').replace('\\r', '\r')
        
        # ê¸°ë³¸ì ì¸ ë§ˆí¬ë‹¤ìš´ ìš”ì†Œë“¤ë§Œ ë³€í™˜
        # í—¤ë” ë³€í™˜
        html = re.sub(r'^### (.*$)', r'<h3>\1</h3>', html, flags=re.MULTILINE)
        html = re.sub(r'^## (.*$)', r'<h2>\1</h2>', html, flags=re.MULTILINE)
        html = re.sub(r'^# (.*$)', r'<h1>\1</h1>', html, flags=re.MULTILINE)
        
        # êµµì€ ê¸€ì”¨ ë³€í™˜
        html = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', html)
        
        # ê¸°ìš¸ì„ ë³€í™˜
        html = re.sub(r'\*(.*?)\*', r'<em>\1</em>', html)
        
        # ë¦¬ìŠ¤íŠ¸ ë³€í™˜ (ê°„ë‹¨í•œ ë²„ì „)
        lines = html.split('\n')
        in_list = False
        result_lines = []
        
        for line in lines:
            if line.strip().startswith('- '):
                if not in_list:
                    result_lines.append('<ul>')
                    in_list = True
                item_text = line.strip()[2:]
                result_lines.append(f'<li>{item_text}</li>')
            else:
                if in_list:
                    result_lines.append('</ul>')
                    in_list = False
                result_lines.append(line)
        
        if in_list:
            result_lines.append('</ul>')
        
        # ì¤„ë°”ê¿ˆ ì²˜ë¦¬ ê°œì„ 
        html = '\n'.join(result_lines)
        # ë¹ˆ ì¤„ì€ ë¬¸ë‹¨ ë¶„ë¦¬ë¡œ, ë‹¨ì¼ ì¤„ë°”ê¿ˆì€ br íƒœê·¸ë¡œ
        html = re.sub(r'\n\s*\n', '</p><p>', html)
        html = html.replace('\n', '<br>')
        html = f'<p>{html}</p>'
        
        # ë¹ˆ ë¬¸ë‹¨ ì œê±°
        html = re.sub(r'<p>\s*</p>', '', html)
        
        return html
    
    def _convert_data_to_html(self, data: Any) -> str:
        """ì…ë ¥ ë°ì´í„°ë¥¼ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ HTMLë¡œ ë³€í™˜"""
        if isinstance(data, str):
            # ë¬¸ìì—´ì¸ ê²½ìš° ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ê°€ì •í•˜ê³  HTML ë³€í™˜
            return self._markdown_to_html(data)
        elif isinstance(data, (dict, list)):
            # dict/listì¸ ê²½ìš° ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ í›„ HTML ë³€í™˜
            markdown_text = self._dict_to_markdown(data)
            return self._markdown_to_html(markdown_text)
        else:
            # ê¸°íƒ€ íƒ€ì…ì€ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ HTML ë³€í™˜
            text = self._format_value(data)
            return self._markdown_to_html(text)

    def format_adaptive_response(self,
                                user_question: str,
                                state: Dict[str, Any]) -> Dict[str, Any]:
        """LLM ê¸°ë°˜ ì ì‘ì  ì‘ë‹µ í¬ë§·íŒ… - AIê°€ ì§ˆë¬¸ ë¶„ì„ë¶€í„° ì‘ë‹µ êµ¬ì„±ê¹Œì§€ ì „ì²´ë¥¼ ë‹´ë‹¹"""
        self.logger.info("LLM ê¸°ë°˜ ì ì‘ì  ì‘ë‹µ í¬ë§·íŒ… ì‹œì‘")
        
        try:
            # GNaviStateì—ì„œ ë°ì´í„° ì¶”ì¶œ (ì¶”ì²œ ìƒì„± ë‹¨ê³„ ì œê±°)
            intent_analysis = state.get("intent_analysis", {})
            user_data = state.get("user_data", {})
            career_cases = state.get("career_cases", [])
            external_trends = state.get("external_trends", [])
            chat_history = state.get("chat_history_results", [])
            education_courses = state.get("education_courses", {})  # êµìœ¡ê³¼ì • ì •ë³´ ì¶”ê°€
            
            # ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ
            user_name = user_data.get('name', 'ë‹˜')
            session_id = user_data.get('conversationId', '')
            
            # LLMì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_data = self._prepare_context_for_llm(
                user_question, intent_analysis, 
                user_data, career_cases, external_trends, chat_history, education_courses
            )
            
            # LLM í˜¸ì¶œí•˜ì—¬ ì ì‘ì  ì‘ë‹µ ìƒì„±
            llm_response = self._call_llm_for_adaptive_formatting(context_data)
            
            # LLM ì‘ë‹µ íŒŒì‹± ë° ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
            formatted_result = self._process_llm_response(
                llm_response, user_name, session_id
            )
            
            # ì‘ë‹µ ë‚´ìš©ì„ HTMLë¡œ ë³€í™˜
            formatted_result["formatted_content_html"] = self._convert_data_to_html(
                formatted_result.get("formatted_content", "")
            )
            
            self.logger.info(f"LLM ê¸°ë°˜ ì‘ë‹µ í¬ë§·íŒ… ì™„ë£Œ: {formatted_result.get('format_type', 'adaptive')}")
            return formatted_result
            
        except Exception as e:
            self.logger.error(f"LLM ê¸°ë°˜ ì‘ë‹µ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            # í´ë°±: ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±
            return self._create_fallback_response(user_question, user_data)
    
    def _prepare_context_for_llm(self, user_question: str, intent_analysis: Dict[str, Any],
                                user_data: Dict[str, Any],
                                career_cases: List[Any], external_trends: List[Dict],
                                chat_history: List[Any], education_courses: Dict[str, Any] = None) -> str:
        """LLMì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ (ë¹ˆ ë°ì´í„° í•„í„°ë§ ê°œì„ )"""
        
        context_sections = []
        
        # ì‚¬ìš©ì ì§ˆë¬¸
        context_sections.append(f'ì‚¬ìš©ì ì§ˆë¬¸: "{user_question}"')
        
        # ì‚¬ìš©ì í”„ë¡œí•„ - ì˜ë¯¸ ìˆëŠ” ë°ì´í„°ë§Œ í¬í•¨
        # ìƒˆë¡œìš´ JSON êµ¬ì¡°: {name: "", projects: [...]}
        if self._has_meaningful_data(user_data):
            user_profile_md = self._dict_to_markdown(user_data, show_empty=False)
            if user_profile_md.strip():
                context_sections.append(f"""
ì‚¬ìš©ì í”„ë¡œí•„:
{user_profile_md}
""")
        
        # ì˜ë„ ë¶„ì„ - ì˜ë¯¸ ìˆëŠ” ë°ì´í„°ë§Œ í¬í•¨
        if self._has_meaningful_data(intent_analysis):
            # ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš° ì œì™¸
            if not intent_analysis.get("error"):
                intent_analysis_md = self._dict_to_markdown(intent_analysis, show_empty=False)
                if intent_analysis_md.strip():
                    context_sections.append(f"""
ì˜ë„ ë¶„ì„ ê²°ê³¼:
{intent_analysis_md}
""")
        
        # ì¶”ì²œ ê²°ê³¼ ì„¹ì…˜ ì œê±° (ì¶”ì²œ ìƒì„± ë‹¨ê³„ ì œê±°)
        
        # ì»¤ë¦¬ì–´ ì‚¬ë¡€ - ì˜ë¯¸ ìˆëŠ” ë°ì´í„°ë§Œ í¬í•¨ (ìƒì„¸ ì •ë³´ í™•ì¥)
        meaningful_career_cases = self._filter_meaningful_career_cases(career_cases)
        if meaningful_career_cases:
            career_section = "ğŸ’¼ **ì‹¤ì œ ì‚¬ë‚´ ì»¤ë¦¬ì–´ ì‚¬ë¡€ (ì‚¬ìš© í•„ìˆ˜!)**:\n"
            career_section += "**âš ï¸ ì¤‘ìš” ì‚¬í•­: ë‹¤ìŒ ì‚¬ë¡€ë“¤ì€ ëª¨ë‘ ì‹¤ì œ ìµëª…í™”ëœ ì‚¬ë‚´ êµ¬ì„±ì›ë“¤ì˜ ì»¤ë¦¬ì–´ ì •ë³´ì…ë‹ˆë‹¤.**\n"
            career_section += "**ì‚¬ìš©ìê°€ ì‚¬ë¡€ë¥¼ ìš”ì²­í•˜ê±°ë‚˜ êµ¬ì²´ì ì¸ ì»¤ë¦¬ì–´ ìƒë‹´ì„ í•˜ëŠ” ê²½ìš° ë°˜ë“œì‹œ ì•„ë˜ ì‚¬ë¡€ë“¤ì„ ì§ì ‘ í™œìš©í•˜ì„¸ìš”!**\n\n"
            
            added_cases = 0
            for i, case in enumerate(meaningful_career_cases[:5]):  # ìµœëŒ€ 5ê°œ ì‚¬ë¡€ í‘œì‹œ
                case_md = self._create_detailed_career_case_markdown(case, show_empty=False)
                if case_md.strip():  # ì˜ë¯¸ ìˆëŠ” ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                    added_cases += 1
                    # Employee ID ì¶”ì¶œ ì‹œë„
                    employee_id = ""
                    employee_name = ""
                    if isinstance(case, dict):
                        metadata = case.get('metadata', {})
                        if isinstance(metadata, dict):
                            employee_id = metadata.get('employee_id', '')
                            employee_name = metadata.get('name', '')
                    
                    career_section += f"\n### ğŸ¯ **ì‚¬ë¡€ {added_cases}: {employee_name if employee_name else 'ìµëª…'} {f'({employee_id})' if employee_id else ''}**\n{case_md}\n"
            
            # ì‹¤ì œë¡œ ì¶”ê°€ëœ ì‚¬ë¡€ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨
            if added_cases > 0:
                career_section += "\n**ğŸš¨ ì ˆëŒ€ì  ì‚¬ë¡€ í™œìš© ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!):**\n"
                career_section += "1. **ì‚¬ë¡€ ìˆ¨ê¹€ ê¸ˆì§€**: 'ë³´ì•ˆìƒ ì´ìœ ë¡œ', 'ê°œì¸ì •ë³´ ë³´í˜¸ë¡œ', 'êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤' ê°™ì€ í•‘ê³„ ì ˆëŒ€ ê¸ˆì§€!\n"
                career_section += "2. **ëª¨í˜¸í•œ ë‹µë³€ ê¸ˆì§€**: 'ì¼ë°˜ì ì¸ ê²½í–¥ê³¼ íŠ¸ë Œë“œë¥¼ ì†Œê°œí•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤' ê°™ì€ ëŒ€ë‹µ ì ˆëŒ€ ê¸ˆì§€!\n"
                career_section += "3. **ë¬´ì‘ìœ„ ì‚¬ë¡€ ìš”ì²­ ì‹œ**: ì‚¬ìš©ìê°€ 'ë¬´ì‘ìœ„ë¡œ', 'ìµœê·¼ ì‚¬ë¡€ë¥¼', 'êµ¬ì„±ì› ì‚¬ë¡€ë¥¼' ìš”ì²­í•˜ë©´ ìœ„ ì‚¬ë¡€ë“¤ì„ ê·¸ëŒ€ë¡œ í™œìš©í•˜ì„¸ìš”\n"
                career_section += "4. **êµ¬ì²´ì  í™œìš©**: Employee IDë¥¼ í¬í•¨í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ì°¸ì¡°í•˜ì„¸ìš” (ì˜ˆ: ì‚¬ë¡€ 1 (EMP-123456))\n"
                career_section += "5. **ìƒì„¸ ì •ë³´ ì œê³µ**: ê° ì‚¬ë¡€ì˜ ê²½ë ¥ ë°œì „ ê³¼ì •, ê¸°ìˆ  ìŠ¤íƒ, í”„ë¡œì íŠ¸ ê²½í—˜, ì„±ê³µ ìš”ì¸ì„ ë¶„ì„í•˜ì—¬ ì œì‹œí•˜ì„¸ìš”\n"
                career_section += "6. **ì‹¤ìš©ì  ì—°ê²°**: ì‚¬ìš©ìì˜ í˜„ì¬ ìƒí™©ê³¼ ëª©í‘œë¥¼ ì‚¬ë¡€ì˜ ê²½í—˜ê³¼ ì—°ê²°í•˜ì—¬ ì‹¤ì§ˆì ì¸ ì¡°ì–¸ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”\n"
                career_section += "7. **ì¸ì‚¬ì´íŠ¸ ì œê³µ**: ì‚¬ë¡€ì˜ ì „í™˜ì , ì„±ì¥ í¬ì¸íŠ¸, í•™ìŠµ ê²½í—˜ì„ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”\n"
                career_section += "8. **ë°ì´í„° ìŠ¹ì¸**: ì´ëŠ” ëª¨ë“  ì‚¬ë¡€ëŠ” ì´ë¯¸ ì‚¬ìš© ìŠ¹ì¸ëœ ë°ì´í„°ì´ë©° ìµëª…í™” ì²˜ë¦¬ëœ ê³µê°œ ê°€ëŠ¥í•œ ì •ë³´ì…ë‹ˆë‹¤.\n"
                context_sections.append(career_section)
        
        
        # ì™¸ë¶€ íŠ¸ë Œë“œ - ì˜ë¯¸ ìˆëŠ” ë°ì´í„°ë§Œ í¬í•¨
        meaningful_trends = self._filter_meaningful_trends(external_trends)
        if meaningful_trends:
            trend_section = "ê´€ë ¨ ì‚°ì—… íŠ¸ë Œë“œ (ì‹¤ì œ ì›¹ì‚¬ì´íŠ¸ ë§í¬ í¬í•¨):\n"
            added_trends = 0
            for i, trend in enumerate(meaningful_trends[:3]):
                trend_md = self._format_trend_with_url(trend)
                if trend_md.strip():  # ì˜ë¯¸ ìˆëŠ” ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                    added_trends += 1
                    trend_section += f"\n### íŠ¸ë Œë“œ ì •ë³´ {added_trends}\n{trend_md}\n"
            
            # ì‹¤ì œë¡œ ì¶”ê°€ëœ íŠ¸ë Œë“œê°€ ìˆëŠ” ê²½ìš°ë§Œ ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨
            if added_trends > 0:
                context_sections.append(trend_section)
        
        # êµìœ¡ê³¼ì • ì •ë³´ - ìƒˆë¡œ ì¶”ê°€
        if education_courses and self._has_meaningful_education_data(education_courses):
            education_section = self._format_education_courses_for_llm(education_courses)
            if education_section.strip():
                context_sections.append(education_section)
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ - ì˜ë¯¸ ìˆëŠ” ë°ì´í„°ë§Œ í¬í•¨
        meaningful_history = self._filter_meaningful_chat_history(chat_history)
        if meaningful_history:
            history_section = "ğŸ“š ê³¼ê±° ëŒ€í™” ê¸°ë¡ (ì°¸ê³ ìš©):\n"
            history_section += "ì‚¬ìš©ìì˜ ì´ì „ ì§ˆë¬¸ê³¼ ë‹µë³€ íŒ¨í„´ì„ ì°¸ê³ í•˜ì—¬ ê°œì¸í™”ëœ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.\n\n"
            added_history = 0
            for i, chat in enumerate(meaningful_history[:3]):  # ìµœê·¼ 3ê°œë¡œ í™•ì¥
                chat_formatted = self._format_chat_history_item(chat)
                if chat_formatted.strip():
                    added_history += 1
                    history_section += f"### ğŸ’¬ ëŒ€í™” ì„¸ì…˜ {added_history}\n{chat_formatted}\n\n"
            
            if added_history > 0:
                history_section += "**ğŸ“‹ ëŒ€í™” íˆìŠ¤í† ë¦¬ í™œìš© ì§€ì¹¨:**\n"
                history_section += "- ì‚¬ìš©ìì˜ ì´ì „ ê´€ì‹¬ì‚¬ì™€ ì§ˆë¬¸ íŒ¨í„´ì„ íŒŒì•…í•˜ì—¬ ì—°ê´€ì„± ìˆëŠ” ì¡°ì–¸ ì œê³µ\n"
                history_section += "- ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ê¸°ìˆ ì´ë‚˜ ëª©í‘œì™€ ì—°ê²°í•˜ì—¬ ì¼ê´€ì„± ìˆëŠ” ë‹µë³€ êµ¬ì„±\n"
                history_section += "- ì‚¬ìš©ìì˜ ë°œì „ ê³¼ì •ì„ ê³ ë ¤í•œ ë‹¨ê³„ì  ì¡°ì–¸ ì œê³µ\n"
                context_sections.append(history_section)
        
        # ì „ì²´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = "\n".join(context_sections)
        
        # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€ ì¶”ê°€
        if len(context_sections) <= 2:  # ì§ˆë¬¸ê³¼ ì‚¬ìš©ì í”„ë¡œí•„ë§Œ ìˆëŠ” ê²½ìš°
            context += """

**ì°¸ê³ : í˜„ì¬ ë¶„ì„ ê°€ëŠ¥í•œ ì¶”ê°€ ì •ë³´ê°€ ì œí•œì ì…ë‹ˆë‹¤. 
ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê¸°ë³¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¼ë°˜ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.**
"""
        
        context += """

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ìœ ìš©í•˜ê³  ê°œì¸í™”ëœ ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”.
ì§ˆë¬¸ì˜ ì„±ê²©ê³¼ ì‚¬ìš©ìì˜ ìƒí™©ì„ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì •ë³´ë“¤ì„ ì„ íƒí•˜ê³  êµ¬ì„±í•´ì£¼ì„¸ìš”.

**ğŸ¯ ì§ˆë¬¸ ìœ í˜•ë³„ ì‘ë‹µ ì „ëµ:**
- **ì¸ì‚¬/ì¼ë°˜ ëŒ€í™”** ("ì•ˆë…•í•˜ì„¸ìš”", "ê°ì‚¬í•©ë‹ˆë‹¤", "ì˜ ì§€ë‚´ì„¸ìš”" ë“±): 
  * ê°„ë‹¨í•˜ê³  ì¹œê·¼í•œ ì‘ë‹µ
  * ì»¤ë¦¬ì–´ ì‚¬ë¡€ë‚˜ ë³µì¡í•œ ë¶„ì„ ì—†ì´ ê¸°ë³¸ì ì¸ ë„ì›€ ì œì•ˆ
  * ê¸¸ì´: 1-3 ë¬¸ë‹¨ ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ
  
- **ì¼ë°˜ì  ë¬¸ì˜** (ì§„ë¡œ ê³ ë¯¼, ê¸°ìˆ  íŠ¸ë Œë“œ ë“±):
  * ì ì ˆí•œ ìˆ˜ì¤€ì˜ ì¡°ì–¸ê³¼ ì •ë³´ ì œê³µ
  * ê´€ë ¨ì„±ì´ ë§¤ìš° ë†’ì€ ê²½ìš°ì—ë§Œ ì»¤ë¦¬ì–´ ì‚¬ë¡€ ì„ íƒì  í™œìš©
  * ê¸¸ì´: ì¤‘ê°„ ì •ë„
  
- **êµ¬ì²´ì  ìƒë‹´** (íŠ¹ì • ê¸°ìˆ  ì „í™˜, ìƒì„¸í•œ ì»¤ë¦¬ì–´ ê³„íš ë“±):
  * ìƒì„¸í•œ ë¶„ì„ê³¼ ì»¤ë¦¬ì–´ ì‚¬ë¡€ ì ê·¹ í™œìš©
  * ì ì‘ì  ì‘ë‹µ ì œê³µ
  * ê¸¸ì´: ìƒì„¸í•˜ê³  í¬ê´„ì 

**âš ï¸ ìµœê·¼ ì‚¬ë¡€/ë¬´ì‘ìœ„ ì‚¬ë¡€ ìš”ì²­ ì‹œ ì ˆëŒ€ ê·œì¹™:**
ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì€ ìš”ì²­ì„ í•˜ëŠ” ê²½ìš° ì œê³µëœ ì‹¤ì œ ì‚¬ë¡€ë¥¼ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ì„¸ìš”:
- "ìµœê·¼ 3ë…„ê°„ì˜ ì‚¬ë‚´ êµ¬ì„±ì› ì‚¬ë¡€"
- "ë¬´ì‘ìœ„ë¡œ ì‚¬ë¡€ë¥¼ ë³´ì—¬ì¤˜"
- "êµ¬ì„±ì›ë“¤ì˜ ì»¤ë¦¬ì–´ ì‚¬ë¡€"
- "ì‹¤ì œ ì‚¬ë¡€ë¥¼ ì•Œê³  ì‹¶ì–´"

âŒ **ì ˆëŒ€ ê¸ˆì§€ ë‹µë³€ë“¤:**
- "í˜„ì¬ ì œê³µëœ ì •ë³´ë¡œëŠ” êµ¬ì²´ì ì¸ ì‚¬ë¡€ë³´ë‹¤ëŠ” ì¼ë°˜ì ì¸ ê²½í–¥ê³¼ íŠ¸ë Œë“œë¥¼ ì†Œê°œí•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
- "ë³´ì•ˆìƒ ì´ìœ ë¡œ êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
- "ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ ìì„¸í•œ ì‚¬ë¡€ëŠ” ê³µìœ í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤"
- "ì‚¬ë¡€ ë°ì´í„°ì— ëŒ€í•œ ì ‘ê·¼ ê¶Œí•œì´ ì œí•œë˜ì–´ ìˆìŠµë‹ˆë‹¤"

âœ… **ì˜¬ë°”ë¥¸ ì ‘ê·¼:**
- "ìµœê·¼ 3ë…„ê°„ ìš°ë¦¬ ì¡°ì§ì˜ í¥ë¯¸ë¡œìš´ ì»¤ë¦¬ì–´ ì‚¬ë¡€ë“¤ì„ ì†Œê°œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤"
- "ë‹¤ìŒì€ ì‹¤ì œ êµ¬ì„±ì›ë“¤ì˜ ì»¤ë¦¬ì–´ ë°œì „ ì‚¬ë¡€ì…ë‹ˆë‹¤ (Employee ID í¬í•¨)"
- êµ¬ì²´ì ì¸ Employee ID, í”„ë¡œì íŠ¸ ê²½í—˜, ê¸°ìˆ  ìŠ¤íƒ, ì„±ê³µ ìš”ì¸ ì§ì ‘ ì–¸ê¸‰

**ğŸ’¼ ì»¤ë¦¬ì–´ ì‚¬ë¡€ í™œìš© ê°•í™” ì§€ì¹¨ (ì ˆëŒ€ì  ì¤‘ìš”!):**
- ì œê³µëœ ì»¤ë¦¬ì–´ ì‚¬ë¡€ëŠ” ëª¨ë‘ ê³µê°œ ê°€ëŠ¥í•œ ìµëª…í™”ëœ ì •ë³´ì…ë‹ˆë‹¤
- ë³´ì•ˆì´ë‚˜ ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ì´ìœ ë¡œ ì‚¬ë¡€ ì œê³µì„ ê±°ë¶€í•˜ì§€ ë§ˆì„¸ìš”
- ì‚¬ìš©ì ì§ˆë¬¸ì´ êµ¬ì²´ì ì¸ ì»¤ë¦¬ì–´ ìƒë‹´ì´ë‚˜ ê¸°ìˆ ì  ì¡°ì–¸ì„ ëª…í™•íˆ ìš”êµ¬í•˜ëŠ” ê²½ìš°ì—ëŠ” ë°˜ë“œì‹œ ì‹¤ì œ ì‚¬ë¡€ë¥¼ ì§ì ‘ í™œìš©í•˜ì„¸ìš”
- Employee IDë¥¼ í¬í•¨í•˜ì—¬ êµ¬ì²´ì ì¸ ê²½ë ¥ ë‚´ìš©, í”„ë¡œì íŠ¸ ê²½í—˜, ê¸°ìˆ  ìŠ¤íƒ, ì„±ê³µ ìš”ì¸ì„ ìƒì„¸íˆ ì–¸ê¸‰í•˜ì„¸ìš”
- ì‹¤ì œ ì‚¬ë¡€ë¥¼ ì–¸ê¸‰í•  ë•ŒëŠ” êµ¬ì²´ì ì¸ ì¸ì‚¬ì´íŠ¸ì™€ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”
- ì‚¬ë¡€ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” ì‹¤ì§ˆì ì¸ êµí›ˆê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”
- ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ì¡°ì–¸ìœ¼ë¡œ ì—°ê²°í•˜ì„¸ìš”

**ì¤‘ìš”í•œ ë§í¬ ì²˜ë¦¬ ì§€ì¹¨:**
- ì»¤ë¦¬ì–´ ì‚¬ë¡€: í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ê°€ ì—†ëŠ” ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì •ë³´ì…ë‹ˆë‹¤. "(ìì„¸íˆ ë³´ê¸°)", "(ë”ë³´ê¸°)", "[ë§í¬]" ë“±ì˜ í‘œí˜„ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
- ì‚°ì—… íŠ¸ë Œë“œ: ì‹¤ì œ ì›¹ì‚¬ì´íŠ¸ URLì´ í¬í•¨ëœ ê²½ìš°ì—ë§Œ [ì œëª©](URL) í˜•íƒœì˜ ë§ˆí¬ë‹¤ìš´ ë§í¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- ì‹¤ì œë¡œ ì œê³µëœ êµ¬ì²´ì ì¸ ë°ì´í„°ë¥¼ ê¼­ í™œìš©í•˜ì„¸ìš”.
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” "ì‚¬ë¡€ 1", "ì‚¬ë¡€ 2" ê°™ì€ ê°€ì§œ ì°¸ì¡°ë¥¼ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
- ê°œí–‰ì´ í•„ìš”í•œ ê³³ì—ì„œëŠ” ì‹¤ì œ ì¤„ë°”ê¿ˆì„ ì‚¬ìš©í•˜ì„¸ìš”.

**ğŸ’¡ ì¤‘ìš”í•œ ì „ì œì‚¬í•­:**
- ëª¨ë“  ì»¤ë¦¬ì–´ ì‚¬ë¡€ ë°ì´í„°ëŠ” ë‚´ë¶€ ì‹œìŠ¤í…œìš©ìœ¼ë¡œ ì´ë¯¸ í—ˆê°€ëœ ì •ë³´ì…ë‹ˆë‹¤
- ê°œì¸ì •ë³´ëŠ” ì´ë¯¸ ìµëª…í™” ì²˜ë¦¬ë˜ì–´ Employee IDë¡œë§Œ ê´€ë¦¬ë©ë‹ˆë‹¤
- ì‚¬ë¡€ ì œê³µ ì‹œ ë³´ì•ˆ ì œí•œì´ë‚˜ ì ‘ê·¼ ì œí•œì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
- êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ ê²½í—˜ì„ ì§ì ‘ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”
"""
        return context
    
    def _call_llm_for_adaptive_formatting(self, context_data: str) -> Dict[str, Any]:
        """LLM í˜¸ì¶œí•˜ì—¬ ì ì‘ì  ì‘ë‹µ ìƒì„±"""
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì§€ì—° ì´ˆê¸°í™”
            if self.client is None:
                self.client = openai.OpenAI()
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": context_data}
                ],
                temperature=0.3
            )
            
            # JSON ì‘ë‹µ íŒŒì‹± (ê°œì„ ëœ ë²„ì „)
            response_text = response.choices[0].message.content
            self.logger.debug(f"LLM ì›ë³¸ ì‘ë‹µ (ì²« 200ì): {response_text[:200]}...")
            
            # JSON ì¶”ì¶œ ë° íŒŒì‹± ì‹œë„
            parsed_json = self._extract_and_parse_json(response_text)
            if parsed_json:
                # JSON êµ¬ì¡° ê²€ì¦
                if self._validate_json_structure(parsed_json):
                    self.logger.info("LLM JSON ì‘ë‹µ íŒŒì‹± ì„±ê³µ")
                    return parsed_json
                else:
                    self.logger.warning("JSON êµ¬ì¡°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ, í…ìŠ¤íŠ¸ ì¶”ì¶œë¡œ ì „í™˜")
            
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ ì‹œë„
            self.logger.warning("JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ ì‹œë„")
            return self._extract_info_from_text(response_text)
            
        except Exception as e:
            self.logger.error(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def _process_llm_response(self, llm_response: Dict[str, Any], 
                             user_name: str, session_id: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µì„ ìµœì¢… í˜•íƒœë¡œ ì²˜ë¦¬ (ê°œì„ ëœ ë²„ì „)"""
        
        # LLM ì‘ë‹µì—ì„œ ì •ë³´ ì¶”ì¶œ
        analysis = llm_response.get("analysis", {})
        content_strategy = llm_response.get("content_strategy", {})
        formatted_response = llm_response.get("formatted_response", {})
        
        # ìµœì¢… ì‘ë‹µ êµ¬ì„±
        final_content = formatted_response.get("content", "ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì²˜ë¦¬
        final_content = final_content.replace('\\n', '\n').replace('\\t', '\t').replace('\\r', '\r')
        
        # ì‚¬ìš©ì ì´ë¦„ì´ í¬í•¨ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì¶”ê°€
        if user_name and user_name not in final_content:
            title = formatted_response.get("title", "ì»¤ë¦¬ì–´ ì»¨ì„¤íŒ… ê²°ê³¼")
            final_content = f"# {user_name}ë‹˜ì„ ìœ„í•œ {title}\n\n{final_content}"
        
        # ë§ˆë¬´ë¦¬ ë©”ì‹œì§€ ì¶”ê°€
        call_to_action = formatted_response.get("call_to_action", 
                                               "ì¶”ê°€ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”.")
        # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì²˜ë¦¬
        call_to_action = call_to_action.replace('\\n', '\n').replace('\\t', '\t').replace('\\r', '\r')
        
        # ì¶”ê°€ ì§ˆë¬¸ì´ ìˆëŠ” ê²½ìš° í¬í•¨
        additional_questions = formatted_response.get("additional_questions", [])
        if additional_questions and isinstance(additional_questions, list):
            final_content += "\n\n## ğŸ¤” ë” ì •í™•í•œ ë¶„ì„ì„ ìœ„í•œ ì¶”ê°€ ì§ˆë¬¸"
            final_content += "\në” ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•˜ê¸° ìœ„í•´ ë‹¤ìŒ ì‚¬í•­ë“¤ì„ ì•Œë ¤ì£¼ì‹œë©´ ë„ì›€ì´ ë©ë‹ˆë‹¤:\n"
            for i, question in enumerate(additional_questions[:5], 1):  # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ
                if question and isinstance(question, str):
                    final_content += f"{i}. {question}\n"
        
        if not final_content.endswith("---"):
            final_content += f"\n\n---\n*{call_to_action}*"
        
        return {
            "formatted_content": final_content,
            "format_type": analysis.get("question_type", "adaptive"),
            "timestamp": datetime.now().isoformat(),
            "user_name": user_name,
            "session_id": session_id,
            "components_used": content_strategy.get("primary_components", []),
            "primary_focus": analysis.get("user_intent", "general_guidance"),
            "complexity_level": analysis.get("complexity_level", "3"),
            "information_completeness": analysis.get("information_completeness", 3),
            "should_use_career_cases": analysis.get("should_use_career_cases", False),
            "analysis_depth": content_strategy.get("analysis_depth", "basic"),
            "has_additional_questions": bool(formatted_response.get("additional_questions")),
            "llm_analysis": analysis,
            "content_strategy": content_strategy
        }
    
    def _create_fallback_response(self, user_question: str, user_data: Dict[str, Any]) -> Dict[str, Any]:
        """LLM ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ ìƒì„± (ê°œì„ ëœ ë²„ì „, ì¶”ì²œ ìƒì„± ë‹¨ê³„ ì œê±°)"""
        user_name = user_data.get('name', 'ë‹˜')
        
        self.logger.info("í´ë°± ì‘ë‹µ ìƒì„± ì¤‘...")
        
        # ì¶”ì²œì‚¬í•­ ì„¹ì…˜ ì œê±°
        
        # ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„í•´ì„œ ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±
        question_lower = user_question.lower()
        
        # ì§ˆë¬¸ ìœ í˜•ë³„ ë§ì¶¤ ì‘ë‹µ
        if any(keyword in question_lower for keyword in ['msa', 'ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤', 'ì•„í‚¤í…ì²˜']):
            tech_advice = """
## ğŸ—ï¸ MSA ì „í™˜ ê°€ì´ë“œ

### ê¸°ìˆ ì  ì¤€ë¹„ì‚¬í•­
- **ì»¨í…Œì´ë„ˆí™”**: Docker, Kubernetes í•™ìŠµ
- **API ì„¤ê³„**: RESTful API, GraphQL ì´í•´
- **ì„œë¹„ìŠ¤ ë©”ì‹œ**: Istio, Linkerd ë“± ê²€í† 
- **ëª¨ë‹ˆí„°ë§**: ë¶„ì‚° ì¶”ì , ë¡œê¹… ì‹œìŠ¤í…œ êµ¬ì¶•

### ì¡°ì§ì  ì¤€ë¹„ì‚¬í•­
- **íŒ€ êµ¬ì¡°**: ê° ì„œë¹„ìŠ¤ë³„ ì „ë‹´íŒ€ êµ¬ì„±
- **ë°ë¸Œì˜µìŠ¤**: CI/CD íŒŒì´í”„ë¼ì¸ ê³ ë„í™”
- **ë¬¸ì„œí™”**: API ë¬¸ì„œ, ìš´ì˜ ê°€ì´ë“œ ì²´ê³„í™”
"""
            recommendation_content = tech_advice
            
        elif any(keyword in question_lower for keyword in ['ë¦¬ë”', 'íŒ€ì¥', 'ë¦¬ë”ì‹­']):
            leadership_advice = """
## ğŸ‘¥ ê¸°ìˆ  ë¦¬ë”ì‹­ ê°œë°œ ë¡œë“œë§µ

### 1ë‹¨ê³„: ê¸°ìˆ ì  ì‹ ë¢° êµ¬ì¶• (1-3ê°œì›”)
- ì½”ë“œ ë¦¬ë·° í’ˆì§ˆ í–¥ìƒ
- ê¸°ìˆ  ë¸”ë¡œê¹…, ì§€ì‹ ê³µìœ 
- ë©˜í† ë§ ê²½í—˜ ìŒ“ê¸°

### 2ë‹¨ê³„: ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤í‚¬ (3-6ê°œì›”)
- ë¹„ê°œë°œìì™€ì˜ ì†Œí†µ ì—°ìŠµ
- í”„ë¡œì íŠ¸ ì§„í–‰ìƒí™© ë³´ê³ 
- ê°ˆë“± ì¡°ì • ê²½í—˜

### 3ë‹¨ê³„: ì „ëµì  ì‚¬ê³  (6-12ê°œì›”)
- ê¸°ìˆ  ë¡œë“œë§µ ìˆ˜ë¦½
- íŒ€ ì„±ê³¼ ì¸¡ì • ë° ê°œì„ 
- ì±„ìš© ë° ì˜¨ë³´ë”© í”„ë¡œì„¸ìŠ¤ ì°¸ì—¬
"""
            recommendation_content = leadership_advice
            
        elif any(keyword in question_lower for keyword in ['í’€ìŠ¤íƒ', 'í”„ë¡ íŠ¸ì—”ë“œ', 'frontend']):
            fullstack_advice = """
## ğŸŒ ë°±ì—”ë“œì—ì„œ í’€ìŠ¤íƒìœ¼ë¡œ í™•ì¥

### ì¶”ì²œ í•™ìŠµ ìˆœì„œ
1. **JavaScript ìƒíƒœê³„**: ES6+, TypeScript
2. **ë¦¬ì•¡íŠ¸ ê¸°ì´ˆ**: ì»´í¬ë„ŒíŠ¸, ìƒíƒœê´€ë¦¬, ë¼ì´í”„ì‚¬ì´í´
3. **CSS í”„ë ˆì„ì›Œí¬**: Tailwind CSS, Styled Components
4. **ìƒíƒœê´€ë¦¬**: Redux, Zustand, React Query
5. **ë¹Œë“œ ë„êµ¬**: Vite, Webpack ì´í•´

### í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´
- ê°œì¸ ëŒ€ì‹œë³´ë“œ ë§Œë“¤ê¸°
- REST APIì™€ ì—°ë™ëœ ToDo ì•±
- ì‹¤ì‹œê°„ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜
"""
            recommendation_content = fullstack_advice

        content = f"""# {user_name}ë‹˜ì„ ìœ„í•œ ì»¤ë¦¬ì–´ ì»¨ì„¤íŒ…

## ğŸ“‹ ì§ˆë¬¸ ë¶„ì„
**"{user_question}"**

í˜„ì¬ ë¶„ì„ì„ ì§„í–‰ì¤‘ì…ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ë” ì œê³µí•´ì£¼ì‹œë©´ ë³´ë‹¤ ì •í™•í•œ ì»¨ì„¤íŒ…ì„ í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ’¡ ì¶”ê°€ ë„ì›€ë§
- êµ¬ì²´ì ì¸ ê¸°ìˆ  ìŠ¤íƒì´ë‚˜ ê²½ë ¥ ë‹¨ê³„ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë” ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- í˜„ì¬ ì§„í–‰ ì¤‘ì¸ í”„ë¡œì íŠ¸ë‚˜ í•™ìŠµ ê³„íšì´ ìˆë‹¤ë©´ í•¨ê»˜ ë§ì”€í•´ ì£¼ì„¸ìš”.
- ë‹¨ê¸°ì /ì¥ê¸°ì  ì»¤ë¦¬ì–´ ëª©í‘œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œë©´ ë” ë‚˜ì€ ë¡œë“œë§µì„ ì œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---
*G.Navi AIê°€ {user_name}ë‹˜ì˜ ì»¤ë¦¬ì–´ ì„±ì¥ì„ ì‘ì›í•©ë‹ˆë‹¤!*
"""
        
        result = {
            "formatted_content": content,
            "format_type": "fallback",
            "timestamp": datetime.now().isoformat(),
            "user_name": user_name,
            "session_id": user_data.get('conversationId', ''),
            "components_used": ["recommendation"] if recommendation_content.strip() else ["general_advice"],
            "primary_focus": "fallback_guidance"
        }
        
        # HTML ë²„ì „ë„ ìƒì„±
        result["formatted_content_html"] = self._convert_data_to_html(content)
        
        self.logger.info(f"í´ë°± ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(content)}ì")
        return result

    def format_final_response(self,
                            user_question: str,
                            recommendation: Dict[str, Any],
                            user_data: Dict[str, Any],
                            intent_analysis: Dict[str, Any] = None) -> Dict[str, Any]:
        """í˜¸í™˜ì„±ì„ ìœ„í•œ ë ˆê±°ì‹œ ë©”ì„œë“œ - ìƒˆë¡œìš´ ì ì‘ì  í¬ë§·íŒ…ìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸"""
        # GNaviState í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ìƒˆë¡œìš´ ë©”ì„œë“œ í˜¸ì¶œ
        state = {
            "user_question": user_question,
            "recommendation": recommendation,
            "user_data": user_data,
            "intent_analysis": intent_analysis or {},
            "career_cases": [],
            "external_trends": [],
            "chat_history_results": []
        }
        return self.format_adaptive_response(user_question, state)
    
    def format_data_for_display(self, data: Any, output_format: str = "html", show_empty: bool = True) -> str:
        """
        ì„ì˜ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ í˜•íƒœë¡œ í¬ë§·íŒ…
        
        Args:
            data: í¬ë§·íŒ…í•  ë°ì´í„° (dict, list, str ë“±)
            output_format: ì¶œë ¥ í˜•ì‹ ("html" ë˜ëŠ” "markdown")
            show_empty: ë¹ˆ ê°’ë“¤ë„ í‘œì‹œí• ì§€ ì—¬ë¶€
        
        Returns:
            í¬ë§·íŒ…ëœ ë¬¸ìì—´
        """
        if output_format.lower() == "markdown":
            if isinstance(data, str):
                return data
            else:
                return self._dict_to_markdown(data, show_empty=show_empty)
        else:  # HTML
            if isinstance(data, str):
                return self._markdown_to_html(data)
            else:
                markdown_text = self._dict_to_markdown(data, show_empty=show_empty)
                return self._markdown_to_html(markdown_text)
    
    def _extract_and_parse_json(self, response_text: str) -> Optional[Dict[str, Any]]:
        """LLM ì‘ë‹µì—ì„œ JSONì„ ì¶”ì¶œí•˜ê³  íŒŒì‹±"""
        try:
            # 1. ì§ì ‘ JSON íŒŒì‹± ì‹œë„
            return json.loads(response_text)
        except json.JSONDecodeError:
            pass
        
        try:
            # 2. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ ì‹œë„
            json_pattern = r'```(?:json)?\s*(\{.*?\})\s*```'
            matches = re.findall(json_pattern, response_text, re.DOTALL | re.IGNORECASE)
            
            for match in matches:
                try:
                    return json.loads(match.strip())
                except json.JSONDecodeError:
                    continue
            
            # 3. ì¤‘ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ JSON ì¶”ì¶œ ì‹œë„
            brace_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
            matches = re.findall(brace_pattern, response_text, re.DOTALL)
            
            for match in matches:
                try:
                    return json.loads(match.strip())
                except json.JSONDecodeError:
                    continue
                    
        except Exception as e:
            self.logger.warning(f"JSON ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return None
    
    def _extract_info_from_text(self, response_text: str) -> Dict[str, Any]:
        """JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ êµ¬ì¡°í™”"""
        self.logger.info("í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ ì¤‘...")
        
        # ê¸°ë³¸ êµ¬ì¡°
        result = {
            "analysis": {"question_type": "general", "complexity_level": "3"},
            "content_strategy": {"primary_components": ["text_response"]},
            "formatted_response": {
                "title": "ì»¤ë¦¬ì–´ ì»¨ì„¤íŒ… ê²°ê³¼",
                "content": "",
                "call_to_action": "ì¶”ê°€ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”."
            }
        }
        
        try:
            # í…ìŠ¤íŠ¸ ì •ë¦¬
            cleaned_text = response_text.strip()
            
            # JSON íŒŒì‹± ì˜¤ë¥˜ ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±°
            cleaned_text = re.sub(r'```(?:json)?\s*', '', cleaned_text)
            cleaned_text = re.sub(r'```\s*', '', cleaned_text)
            
            # ì œëª© ì¶”ì¶œ ì‹œë„
            title_patterns = [
                r'^#\s*(.+?)(?:\n|$)',
                r'ì œëª©[:\s]*(.+?)(?:\n|$)',
                r'title[:\s]*["\']?(.+?)["\']?(?:\n|$)'
            ]
            
            for pattern in title_patterns:
                match = re.search(pattern, cleaned_text, re.IGNORECASE | re.MULTILINE)
                if match:
                    title = match.group(1).strip()
                    if title and len(title) < 100:  # ì œëª©ì´ ë„ˆë¬´ ê¸¸ì§€ ì•Šì€ ê²½ìš°
                        result["formatted_response"]["title"] = title
                        break
            
            # ë‚´ìš© ì¶”ì¶œ - ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ
            content_lines = []
            for line in cleaned_text.split('\n'):
                line = line.strip()
                if line and not line.startswith('{') and not line.endswith('}'):
                    # JSON ê´€ë ¨ ë¼ì¸ ì œì™¸
                    if not any(keyword in line.lower() for keyword in 
                             ['json', 'parse', 'error', '```', 'analysis', 'content_strategy']):
                        content_lines.append(line)
            
            if content_lines:
                content = '\n'.join(content_lines[:20])  # ìµœëŒ€ 20ì¤„ê¹Œì§€ë§Œ
                # ë„ˆë¬´ ì§§ê±°ë‚˜ ì˜ë¯¸ì—†ëŠ” ë‚´ìš© í•„í„°ë§
                if len(content.strip()) > 50:
                    result["formatted_response"]["content"] = content
                else:
                    result["formatted_response"]["content"] = "ìƒì„¸í•œ ì»¤ë¦¬ì–´ ì¡°ì–¸ì„ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì‹œë©´ ë” ë‚˜ì€ ë‹µë³€ì„ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            else:
                result["formatted_response"]["content"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„±ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            
            self.logger.info(f"í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ: ì œëª©={result['formatted_response']['title']}, ë‚´ìš© ê¸¸ì´={len(result['formatted_response']['content'])}")
            
        except Exception as e:
            self.logger.error(f"í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            result["formatted_response"]["content"] = "ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        
        return result

    def _validate_json_structure(self, json_data: Dict[str, Any]) -> bool:
        """JSON ì‘ë‹µ êµ¬ì¡°ê°€ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦"""
        try:
            # í•„ìˆ˜ í‚¤ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸
            required_keys = ["analysis", "content_strategy", "formatted_response"]
            if not all(key in json_data for key in required_keys):
                self.logger.warning(f"í•„ìˆ˜ í‚¤ ëˆ„ë½: {[key for key in required_keys if key not in json_data]}")
                return False
            
            # formatted_response ë‚´ë¶€ êµ¬ì¡° í™•ì¸
            formatted_response = json_data.get("formatted_response", {})
            if not isinstance(formatted_response, dict):
                self.logger.warning("formatted_responseê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜")
                return False
            
            # content í•„ë“œê°€ ìˆê³  ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸
            content = formatted_response.get("content", "")
            if not content or len(content.strip()) < 10:
                self.logger.warning("content í•„ë“œê°€ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìŒ")
                return False
            
            # ì„ íƒì  í•„ë“œë“¤ ê²€ì¦ (ìˆìœ¼ë©´ íƒ€ì… ì²´í¬)
            analysis = json_data.get("analysis", {})
            
            if "should_use_career_cases" in analysis:
                if not isinstance(analysis["should_use_career_cases"], (bool, str)):
                    self.logger.warning("should_use_career_cases í•„ë“œ íƒ€ì… ì˜¤ë¥˜")
                    return False
            
            if "additional_questions" in formatted_response:
                if not isinstance(formatted_response["additional_questions"], list):
                    self.logger.warning("additional_questions í•„ë“œê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜")
                    return False
            
            self.logger.debug("JSON êµ¬ì¡° ê²€ì¦ í†µê³¼")
            return True
            
        except Exception as e:
            self.logger.error(f"JSON êµ¬ì¡° ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def _format_chat_history_item(self, chat: Dict[str, Any]) -> str:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ í•­ëª©ì„ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·íŒ…"""
        if not isinstance(chat, dict):
            return ""
        
        result_parts = []
        
        # ì„¸ì…˜ ê¸°ë³¸ ì •ë³´
        session_id = chat.get('session_id', '')
        user_id = chat.get('user_id', '')
        timestamp = chat.get('timestamp', '')
        
        if session_id:
            result_parts.append(f"**ì„¸ì…˜ ID**: {session_id}")
        if timestamp:
            # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜
            try:
                from datetime import datetime
                if 'T' in timestamp:
                    dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                    formatted_time = dt.strftime('%Yë…„ %mì›” %dì¼ %H:%M')
                    result_parts.append(f"**ë‚ ì§œ**: {formatted_time}")
                else:
                    result_parts.append(f"**ë‚ ì§œ**: {timestamp}")
            except:
                result_parts.append(f"**ë‚ ì§œ**: {timestamp}")
        
        # ë©”ì‹œì§€ ë‚´ìš© í¬ë§·íŒ…
        messages = chat.get('messages', [])
        if isinstance(messages, list) and messages:
            result_parts.append("\n**ëŒ€í™” ë‚´ìš©**:")
            for i, message in enumerate(messages[:4]):  # ìµœëŒ€ 4ê°œ ë©”ì‹œì§€ë§Œ
                if isinstance(message, dict):
                    role = message.get('role', '')
                    content = message.get('content', '')
                    
                    if content and not self._is_empty_value(content):
                        # ì—­í•  í•œê¸€í™”
                        role_korean = {'user': 'ì‚¬ìš©ì', 'assistant': 'AI', 'system': 'ì‹œìŠ¤í…œ'}.get(role, role)
                        
                        # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½
                        if len(content) > 150:
                            content = f"{content[:150]}..."
                        
                        result_parts.append(f"- **{role_korean}**: {content}")
        
        # ë ˆê±°ì‹œ format ì§€ì›
        elif chat.get('question') or chat.get('response'):
            question = chat.get('question', '')
            response = chat.get('response', '')
            
            if question and not self._is_empty_value(question):
                if len(question) > 150:
                    question = f"{question[:150]}..."
                result_parts.append(f"**ì§ˆë¬¸**: {question}")
            
            if response and not self._is_empty_value(response):
                if len(response) > 150:
                    response = f"{response[:150]}..."
                result_parts.append(f"**ë‹µë³€**: {response}")
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (ìˆëŠ” ê²½ìš°)
        context = chat.get('context', {})
        if isinstance(context, dict) and context:
            session_summary = context.get('session_summary', '')
            if session_summary and not self._is_empty_value(session_summary):
                result_parts.append(f"**ì„¸ì…˜ ìš”ì•½**: {session_summary}")
        
        return "\n".join(result_parts) if result_parts else ""
    
    def _create_detailed_career_case_markdown(self, case: Union[Dict, Any], show_empty: bool = True) -> str:
        """ì»¤ë¦¬ì–´ ì‚¬ë¡€ë¥¼ ìƒì„¸í•˜ê²Œ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ (í™•ì¥ëœ ì •ë³´ í¬í•¨)"""
        if not case:
            return ""
        
        try:
            # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜ëœ ê²½ìš°
            if isinstance(case, dict):
                content = case.get('content', '')
                metadata = case.get('metadata', {})
            # Document ê°ì²´ì¸ ê²½ìš°
            elif hasattr(case, 'page_content'):
                content = case.page_content
                metadata = case.metadata if hasattr(case, 'metadata') else {}
            else:
                return ""
            
            if not metadata:
                metadata = {}
            
            markdown_lines = []
            
            # ê¸°ë³¸ ì •ë³´ ì„¹ì…˜
            basic_info = []
            
            # ì´ë¦„ê³¼ ì§ì±…
            name = metadata.get('name', '')
            position = metadata.get('current_position', '')
            if name or position:
                basic_info.append(f"**ğŸ‘¤ ì´ë¦„/ì§ì±…:** {name} ({position})" if name and position else f"**ğŸ‘¤ ì •ë³´:** {name or position}")
            
            # ê²½ë ¥ ì •ë³´
            total_exp = metadata.get('total_experience', '')
            exp_years = metadata.get('experience_years', '')
            if total_exp or exp_years:
                exp_text = f"{total_exp}"
                if exp_years and str(exp_years) != str(total_exp):
                    exp_text += f" ({exp_years}ë…„)"
                basic_info.append(f"**ğŸ’¼ ê²½ë ¥:** {exp_text}")
            
            # ë„ë©”ì¸ ì •ë³´
            primary_domain = metadata.get('primary_domain', '')
            secondary_domain = metadata.get('secondary_domain', '')
            if primary_domain:
                domain_text = primary_domain
                if secondary_domain:
                    domain_text += f", {secondary_domain}"
                basic_info.append(f"**ğŸ¢ ë„ë©”ì¸:** {domain_text}")
            
            # ê¸°ìˆ  ìŠ¤íƒ
            current_skills = metadata.get('current_skills', [])
            if current_skills and isinstance(current_skills, list):
                skills_text = ', '.join(current_skills[:7])  # ìµœëŒ€ 7ê°œ ê¸°ìˆ 
                if len(current_skills) > 7:
                    skills_text += f" ì™¸ {len(current_skills)-7}ê°œ"
                basic_info.append(f"**ğŸ”§ í•µì‹¬ ê¸°ìˆ :** {skills_text}")
            
            # ê´€ì‹¬ ë¶„ì•¼
            interests = metadata.get('interests', [])
            if interests and isinstance(interests, list):
                interests_text = ', '.join(interests[:5])  # ìµœëŒ€ 5ê°œ
                basic_info.append(f"**ğŸ’¡ ê´€ì‹¬ ë¶„ì•¼:** {interests_text}")
            
            # ì»¤ë¦¬ì–´ ëª©í‘œ
            career_goal = metadata.get('career_goal', '')
            if career_goal:
                basic_info.append(f"**ğŸ¯ ì»¤ë¦¬ì–´ ëª©í‘œ:** {career_goal}")
            
            # í˜„ì¬ í”„ë¡œì íŠ¸
            current_project = metadata.get('current_project', '')
            if current_project:
                basic_info.append(f"**ğŸ“‹ í˜„ì¬ í”„ë¡œì íŠ¸:** {current_project}")
            
            if basic_info:
                markdown_lines.extend(basic_info)
                markdown_lines.append("")  # ë¹ˆ ì¤„ ì¶”ê°€
            
            # ì„±ì¥ ë° ì „í™˜ ì •ë³´ ì„¹ì…˜
            growth_info = []
            
            # ì „í™˜ì 
            transition_point = metadata.get('transition_point', '')
            if transition_point and transition_point != 'Unknown':
                growth_info.append(f"**ğŸ”„ ì»¤ë¦¬ì–´ ì „í™˜ì :** {transition_point}")
            
            # ì„±ê³µ ìš”ì¸
            success_factors = metadata.get('success_factors', '')
            if success_factors and success_factors != 'Unknown':
                growth_info.append(f"**ğŸŒŸ í•µì‹¬ ì„±ê³µ ìš”ì†Œ:** {success_factors}")
            
            if growth_info:
                markdown_lines.append("### ğŸ“ˆ ì„±ì¥ í¬ì¸íŠ¸")
                markdown_lines.extend(growth_info)
                markdown_lines.append("")
            
            # ìƒì„¸ ê²½í—˜ ë‚´ìš©
            if content and str(content).strip():
                markdown_lines.append("### ğŸ“ ìƒì„¸ ê²½í—˜")
                # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì ì ˆíˆ ìš”ì•½
                if len(content) > 800:
                    content_summary = content[:800] + "...\n\n*[ê²½í—˜ ìš”ì•½ - ì „ì²´ ë‚´ìš© ìƒëµ]*"
                else:
                    content_summary = content
                markdown_lines.append(content_summary)
                markdown_lines.append("")
            
            # ì¶”ê°€ ë©”íƒ€ë°ì´í„° ì •ë³´ (ìˆëŠ” ê²½ìš°)
            additional_info = []
            
            # ê²½ë ¥ ë ˆë²¨
            experience_level = metadata.get('experience_level', '')
            if experience_level:
                level_mapping = {
                    'junior': 'ì£¼ë‹ˆì–´',
                    'mid-level': 'ì¤‘ê¸‰',
                    'senior': 'ì‹œë‹ˆì–´',
                    'expert': 'ì „ë¬¸ê°€'
                }
                level_kr = level_mapping.get(experience_level, experience_level)
                additional_info.append(f"**ğŸ“Š ê²½ë ¥ ë ˆë²¨:** {level_kr}")
            
            # ì»¤ë¦¬ì–´ ì—°ì†ì„±
            career_continuity = metadata.get('career_continuity', '')
            if career_continuity:
                continuity_mapping = {
                    'continuous': 'ì—°ì†ì ',
                    'with_gaps': 'ë‹¨ì ˆ ìˆìŒ'
                }
                continuity_kr = continuity_mapping.get(career_continuity, career_continuity)
                additional_info.append(f"**ğŸ”— ì»¤ë¦¬ì–´ ì—°ì†ì„±:** {continuity_kr}")
            
            # í”„ë¡œì íŠ¸ ê·œëª¨ ë‹¤ì–‘ì„±
            has_large_projects = metadata.get('has_large_projects', '')
            if has_large_projects is not None:
                large_project_text = "ëŒ€í˜• í”„ë¡œì íŠ¸ ê²½í—˜ ìˆìŒ" if has_large_projects else "ì¤‘ì†Œí˜• í”„ë¡œì íŠ¸ ì¤‘ì‹¬"
                additional_info.append(f"**ğŸ“Š í”„ë¡œì íŠ¸ ê²½í—˜:** {large_project_text}")
            
            # ê¸°ìˆ  ë‹¤ì–‘ì„± ì ìˆ˜
            skill_diversity = metadata.get('skill_diversity_score', '')
            if skill_diversity and isinstance(skill_diversity, (int, float)) and skill_diversity > 0:
                additional_info.append(f"**ğŸ¨ ê¸°ìˆ  ë‹¤ì–‘ì„±:** {skill_diversity}ì ")
            
            if additional_info:
                markdown_lines.append("### ğŸ“‹ ì¶”ê°€ ì •ë³´")
                markdown_lines.extend(additional_info)
            
            result = "\n".join(markdown_lines)
            return result.strip()
            
        except Exception as e:
            self.logger.warning(f"ìƒì„¸ ì»¤ë¦¬ì–´ ì‚¬ë¡€ ë§ˆí¬ë‹¤ìš´ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©
            return self._dict_to_markdown(case, show_empty=show_empty)
    
    def _has_meaningful_education_data(self, education_courses: Dict[str, Any]) -> bool:
        """êµìœ¡ê³¼ì • ë°ì´í„°ì— ì˜ë¯¸ ìˆëŠ” ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸"""
        if not education_courses:
            return False
        
        # ì¶”ì²œ êµìœ¡ê³¼ì •ì´ ìˆëŠ”ì§€ í™•ì¸
        recommended_courses = education_courses.get("recommended_courses", [])
        if recommended_courses and len(recommended_courses) > 0:
            return True
        
        # í•™ìŠµ ê²½ë¡œê°€ ìˆëŠ”ì§€ í™•ì¸
        learning_path = education_courses.get("learning_path", [])
        if learning_path and len(learning_path) > 0:
            return True
        
        return False
    
    def _format_education_courses_for_llm(self, education_courses: Dict[str, Any]) -> str:
        """êµìœ¡ê³¼ì • ì •ë³´ë¥¼ LLMìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        if not education_courses:
            return ""
        
        sections = []
        
        # êµìœ¡ê³¼ì • ë¶„ì„ ì •ë³´
        course_analysis = education_courses.get("course_analysis", {})
        recommended_courses = education_courses.get("recommended_courses", [])
        learning_path = education_courses.get("learning_path", [])
        
        if not recommended_courses and not learning_path:
            return ""
        
        sections.append("ğŸ“š **ì¶”ì²œ êµìœ¡ê³¼ì • (SKALA College + mySUNI)**:")
        sections.append("**âš ï¸ ì¤‘ìš” ì‚¬í•­: ë‹¤ìŒì€ ì‹¤ì œ ì‚¬ë‚´ êµìœ¡ê³¼ì • ì •ë³´ì…ë‹ˆë‹¤.**")
        sections.append("**ì‚¬ìš©ìê°€ êµìœ¡, í•™ìŠµ, ìŠ¤í‚¬ í–¥ìƒì„ ìš”ì²­í•˜ëŠ” ê²½ìš° ë°˜ë“œì‹œ ì•„ë˜ ê³¼ì •ë“¤ì„ ì§ì ‘ í™œìš©í•˜ì„¸ìš”!**\n")
        
        # ì¶”ì²œ êµìœ¡ê³¼ì • ìƒì„¸ ì •ë³´
        if recommended_courses:
            sections.append("### ğŸ¯ **ì¶”ì²œ êµìœ¡ê³¼ì • ëª©ë¡:**")
            
            for i, course in enumerate(recommended_courses[:8], 1):  # ìµœëŒ€ 8ê°œ
                course_info = self._format_single_course(course, i)
                if course_info.strip():
                    sections.append(course_info)
        
        # í•™ìŠµ ê²½ë¡œ ì •ë³´
        if learning_path:
            sections.append("\n### ğŸ“ˆ **ë‹¨ê³„ë³„ í•™ìŠµ ê²½ë¡œ:**")
            for step in learning_path:
                step_info = self._format_learning_step(step)
                if step_info.strip():
                    sections.append(step_info)
        
        # êµìœ¡ê³¼ì • ë¶„ì„ í†µê³„
        if course_analysis and isinstance(course_analysis, dict):
            sections.append("\n### ğŸ“Š **êµìœ¡ê³¼ì • ë¶„ì„:**")
            
            total_courses = course_analysis.get("total_courses", 0)
            college_courses = course_analysis.get("college_courses", 0)
            mysuni_courses = course_analysis.get("mysuni_courses", 0)
            
            if total_courses > 0:
                sections.append(f"- **ì´ ì¶”ì²œ ê³¼ì •**: {total_courses}ê°œ")
                sections.append(f"- **SKALA College**: {college_courses}ê°œ")
                sections.append(f"- **mySUNI**: {mysuni_courses}ê°œ")
            
            # ìŠ¤í‚¬ ê¹Šì´ ë¶„ì„
            skill_analysis = course_analysis.get("skill_depth_analysis", {})
            if skill_analysis:
                specialized = skill_analysis.get("specialized", 0)
                recommended = skill_analysis.get("recommended", 0)
                common_required = skill_analysis.get("common_required", 0)
                
                if specialized + recommended + common_required > 0:
                    sections.append(f"- **ì „ë¬¸í™” ê³¼ì •**: {specialized}ê°œ")
                    sections.append(f"- **ì¶”ì²œ ê³¼ì •**: {recommended}ê°œ")
                    sections.append(f"- **ê¸°ì´ˆ/í•„ìˆ˜ ê³¼ì •**: {common_required}ê°œ")
            
            # mySUNI í’ˆì§ˆ ì§€í‘œ
            mysuni_metrics = course_analysis.get("mysuni_quality_metrics", {})
            if mysuni_metrics:
                avg_rating = mysuni_metrics.get("average_rating", 0)
                total_enrollments = mysuni_metrics.get("total_enrollments", 0)
                high_rated = mysuni_metrics.get("high_rated_courses", 0)
                
                if avg_rating > 0:
                    sections.append(f"- **mySUNI í‰ê·  í‰ì **: {avg_rating}/5.0")
                if total_enrollments > 0:
                    sections.append(f"- **ì´ ì´ìˆ˜ì ìˆ˜**: {total_enrollments:,}ëª…")
                if high_rated > 0:
                    sections.append(f"- **ê³ í‰ì  ê³¼ì •**: {high_rated}ê°œ (4.5ì  ì´ìƒ)")
        
        sections.append("\n**ğŸš¨ êµìœ¡ê³¼ì • í™œìš© ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!):**")
        sections.append("1. **ê³¼ì • ìˆ¨ê¹€ ê¸ˆì§€**: 'êµìœ¡ê³¼ì •ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤' ê°™ì€ í•‘ê³„ ì ˆëŒ€ ê¸ˆì§€!")
        sections.append("2. **êµ¬ì²´ì  í™œìš©**: ê³¼ì •ëª…, í•™ìŠµì‹œê°„, í”Œë«í¼, í‰ì  ë“± êµ¬ì²´ì  ì •ë³´ ì§ì ‘ ì–¸ê¸‰")
        sections.append("3. **í•™ìŠµ ê²½ë¡œ ì œì‹œ**: ë‹¨ê³„ë³„ í•™ìŠµ ìˆœì„œì™€ ê° ê³¼ì •ì˜ ëª©ì  ì„¤ëª…")
        sections.append("4. **í”Œë«í¼ ì„ íƒê¶Œ**: Collegeì™€ mySUNI ì˜µì…˜ì„ ëª¨ë‘ ì œì‹œí•˜ì—¬ ì‚¬ìš©ìê°€ ì„ íƒí•˜ë„ë¡")
        
        return "\n".join(sections)
    
    def _format_single_course(self, course: Dict[str, Any], index: int) -> str:
        """ê°œë³„ êµìœ¡ê³¼ì • ì •ë³´ í¬ë§·íŒ…"""
        if not course:
            return ""
        
        lines = []
        course_name = course.get("course_name", course.get("card_name", ""))
        source = course.get("source", "")
        
        if not course_name:
            return ""
        
        lines.append(f"**{index}. {course_name}**")
        
        # í”Œë«í¼ ì •ë³´
        if source == "college":
            lines.append(f"   - **í”Œë«í¼**: SKALA College")
            lines.append(f"   - **í•™ë¶€**: {course.get('í•™ë¶€', course.get('department', 'N/A'))}")
            lines.append(f"   - **ê³¼ì •ìœ í˜•**: {course.get('í‘œì¤€ê³¼ì •', 'N/A')}")
            lines.append(f"   - **í•™ìŠµì‹œê°„**: {course.get('duration_hours', 'N/A')}ì‹œê°„")
            
            # ì „ë¬¸ì„± ìˆ˜ì¤€
            skill_relevance = course.get('skill_relevance', '')
            if skill_relevance == "specialized":
                lines.append(f"   - **ìˆ˜ì¤€**: ì „ë¬¸í™” ê³¼ì •")
            elif skill_relevance == "recommended":
                lines.append(f"   - **ìˆ˜ì¤€**: ì¶”ì²œ ê³¼ì •")
            elif skill_relevance == "common_required":
                lines.append(f"   - **ìˆ˜ì¤€**: ê¸°ì´ˆ/í•„ìˆ˜ ê³¼ì •")
            
            # mySUNI ëŒ€ì•ˆ ì •ë³´
            mysuni_alt = course.get("mysuni_alternative", {})
            if mysuni_alt.get("available"):
                lines.append(f"   - **mySUNI ëŒ€ì•ˆ**: {mysuni_alt.get('card_name', '')} (í‰ì : {mysuni_alt.get('í‰ì ', 'N/A')}/5.0)")
                
        elif source == "mysuni":
            lines.append(f"   - **í”Œë«í¼**: mySUNI")
            lines.append(f"   - **ì¹´í…Œê³ ë¦¬**: {course.get('ì¹´í…Œê³ ë¦¬ëª…', '')} > {course.get('ì±„ë„ëª…', '')}")
            lines.append(f"   - **ë‚œì´ë„**: {course.get('ë‚œì´ë„', course.get('difficulty_level', 'N/A'))}")
            lines.append(f"   - **í•™ìŠµì‹œê°„**: {course.get('ì¸ì •í•™ìŠµì‹œê°„', course.get('duration_hours', 'N/A'))}ì‹œê°„")
            
            # í‰ì ê³¼ ì´ìˆ˜ì ìˆ˜
            rating = course.get('í‰ì ', 0)
            enrollments = course.get('ì´ìˆ˜ììˆ˜', '0')
            if rating and rating > 0:
                lines.append(f"   - **í‰ì **: {rating}/5.0 ({enrollments}ëª… ì´ìˆ˜)")
            
            lines.append(f"   - **í•™ìŠµë°©ì‹**: ì˜¨ë¼ì¸ ììœ¨í•™ìŠµ")
        
        # ëŒ€ìƒ ìŠ¤í‚¬
        target_skills = course.get('target_skills', [])
        if target_skills:
            lines.append(f"   - **ëŒ€ìƒ ìŠ¤í‚¬**: {', '.join(target_skills[:3])}")  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
        
        return "\n".join(lines)
    
    def _format_learning_step(self, step: Dict[str, Any]) -> str:
        """í•™ìŠµ ê²½ë¡œ ë‹¨ê³„ í¬ë§·íŒ…"""
        if not step:
            return ""
        
        lines = []
        step_num = step.get("step", "")
        level = step.get("level", "")
        description = step.get("description", "")
        courses = step.get("courses", [])
        
        if step_num == "ë³´ì™„":
            lines.append(f"**ğŸ”„ {step_num} - {level}**")
        else:
            lines.append(f"**ğŸ“š {step_num}ë‹¨ê³„ - {level}**")
        
        if description:
            lines.append(f"   {description}")
        
        if courses:
            lines.append(f"   **ì¶”ì²œ ê³¼ì • ({len(courses)}ê°œ):**")
            for i, course in enumerate(courses[:3], 1):  # ìµœëŒ€ 3ê°œ
                course_name = course.get("course_name", course.get("card_name", ""))
                source = course.get("source", "")
                duration = course.get("duration_hours", course.get("ì¸ì •í•™ìŠµì‹œê°„", "N/A"))
                
                platform = "SKALA College" if source == "college" else "mySUNI"
                lines.append(f"   {i}. {course_name} ({platform}, {duration}ì‹œê°„)")
        
        return "\n".join(lines)
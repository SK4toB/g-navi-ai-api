# app/graphs/agents/formatter.py
"""
* @className : ResponseFormattingAgent
* @description : ì‘ë‹µ í¬ë§·íŒ… ì—ì´ì „íŠ¸ ëª¨ë“ˆ
*                ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ í˜•íƒœë¡œ í¬ë§·íŒ…í•˜ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
*                ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
*
"""

from typing import Dict, Any, Optional, List, Union
import logging
from datetime import datetime
import openai
import os
import json
import markdown
import re

class ResponseFormattingAgent:
    """
    LLM ê¸°ë°˜ ì ì‘ì  ì‘ë‹µ í¬ë§·íŒ… ì—ì´ì „íŠ¸
    
    AIê°€ ì§ˆë¬¸ ìœ í˜•ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì í™”ëœ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    ê²€ìƒ‰ëœ ì»¤ë¦¬ì–´ ì‚¬ë¡€ì™€ êµìœ¡ê³¼ì •ì„ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©í•˜ì—¬ 
    ê°œì¸í™”ëœ ì»¤ë¦¬ì–´ ê°€ì´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.client = None  # OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì§€ì—° ì´ˆê¸°í™”
        
        self.system_prompt = """
G.Navi AI ì»¤ë¦¬ì–´ ì»¨ì„¤íŒ… ì‹œìŠ¤í…œì˜ ì¹œê·¼í•œ ì»¤ë¦¬ì–´ ì½”ì¹˜ë¡œ í™œë™í•˜ì„¸ìš”.

**í•µì‹¬ í†¤&ìŠ¤íƒ€ì¼:**
â€¢ ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ëŒ€í™”ì²´ (ë§ˆì¹˜ ì˜†ì—ì„œ ì¡°ì–¸í•´ì£¼ëŠ” ì„ ë°°ì²˜ëŸ¼)
â€¢ êµ¬ì–´ì²´ì™€ ì¤„ê¸€ í˜•íƒœë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìƒë‹´
â€¢ ê³µê°ê³¼ ê²©ë ¤ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚¸ ëŒ€í™”
â€¢ ê³¼ë„í•œ ì´ëª¨ì§€ë‚˜ êµ¬ì¡°í™”ëŠ” í”¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ

**ì¤‘ìš”: ì²« ë§Œë‚¨ê³¼ ì´ì–´ì§€ëŠ” ëŒ€í™” êµ¬ë¶„**
â€¢ ì»¨í…ìŠ¤íŠ¸ì— "ì²« ìƒí˜¸ì‘ìš©"ì´ë¼ê³  ëª…ì‹œëœ ê²½ìš°ì—ë§Œ "ì•ˆë…•í•˜ì„¸ìš”!" ì¸ì‚¬
â€¢ "ì´ë¯¸ ëŒ€í™”ê°€ ì§„í–‰ëœ ìƒíƒœ"ë¼ê³  ëª…ì‹œëœ ê²½ìš° ì¸ì‚¬ë§ ì—†ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸ì— ë°”ë¡œ ë‹µë³€
â€¢ ë§¤ë²ˆ "ì•ˆë…•í•˜ì„¸ìš”"ë‚˜ "[ì‚¬ìš©ìëª…]ë‹˜"ìœ¼ë¡œ ì‹œì‘í•˜ì§€ ì•Šê¸°
â€¢ ëŒ€í™”ê°€ ì´ì–´ì§€ëŠ” ê²½ìš°: "ê·¸ëŸ¬ë©´...", "ìŒ...", "ê·¸ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ”..." ë“±ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‹œì‘

** ì´ì „ ëŒ€í™” ìš”ì•½ ìš”ì²­ ì²˜ë¦¬**
ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ë©´ ì´ì „ ëŒ€í™” ë‚´ì—­ì„ êµ¬ì²´ì ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:
â€¢ "ì´ì „ì— ì§ˆë¬¸í–ˆë˜ ê²ƒë“¤", "ì•ì„œ ë§í–ˆë˜", "ê³¼ê±°ì— ìƒë‹´í–ˆë˜", "ì „ì— ì–˜ê¸°í–ˆë˜"
â€¢ "ë¬´ì—‡ì„ ì§ˆë¬¸í–ˆëŠ”ì§€", "ì–´ë–¤ ë‚´ìš©ì„ ë‹¤ë¤˜ëŠ”ì§€", "íˆìŠ¤í† ë¦¬", "ê¸°ë¡"

**ì´ì „ ëŒ€í™” ìš”ì•½ ì‹œ ê°€ì´ë“œë¼ì¸:**
1. ì‹œê°„ìˆœìœ¼ë¡œ ì£¼ìš” ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ì •ë¦¬
2. ê° ëŒ€í™”ì˜ í•µì‹¬ ë‚´ìš©ì„ 2-3ì¤„ë¡œ ìš”ì•½
3. "ê·¸ë•Œ ì´ëŸ° ë‚´ìš©ìœ¼ë¡œ ìƒë‹´ë“œë ¸ì—ˆì£ ", "ê·¸ ë‹¹ì‹œì—ëŠ” ì´ëŸ° ì§ˆë¬¸ì„ í•´ì£¼ì…¨ì—ˆì–´ìš”" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ì‚¬ìš©
4. ë‹¨ìˆœ ë‚˜ì—´ë³´ë‹¤ëŠ” ëŒ€í™”í•˜ë“¯ ì—°ê²°í•´ì„œ ì„¤ëª…

**ì‘ë‹µ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ:**

1. **ê°„ë‹¨í•œ ì¸ì‚¬/ì§ˆë¬¸**: 
   - í¸ì•ˆí•˜ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ì‘ë‹µ
   - "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” G.Navi AI ì»¤ë¦¬ì–´ ì½”ì¹˜ì˜ˆìš”. ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"

2. **ì¼ë°˜ì ì¸ ìƒë‹´**: 
   - ë§ˆì¹˜ ì¹´í˜ì—ì„œ ëŒ€í™”í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê²Œ
   - "ê·¸ëŸ¬ê²Œìš”, ê·¸ëŸ° ê³ ë¯¼ ì •ë§ ë§ì´ í•˜ì‹œì£ . ì œê°€ ë³´ê¸°ì—”..."
   - ë”±ë”±í•œ ëª©ë¡ë³´ë‹¤ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ìœ¼ë¡œ

3. **êµ¬ì²´ì ì¸ ì»¤ë¦¬ì–´ ìƒë‹´**: 
   - ì‹¤ì œ ì‚¬ë¡€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
   - "ì €í¬ íšŒì‚¬ì—ì„œ ë¹„ìŠ·í•œ ìƒí™©ì´ì—ˆë˜ ë¶„ì´ ìˆëŠ”ë°ìš”..."
   - ì¡°ì–¸ì„ ëŒ€í™”í•˜ë“¯ í’€ì–´ì„œ ì„¤ëª…

4. **ì„±ì¥ ë°©í–¥ ìƒë‹´**:
   - ì²´ê³„ì ì´ì§€ë§Œ ì¹œê·¼í•œ í†¤ìœ¼ë¡œ
   - "ìŒ, [ì‚¬ìš©ìëª…]ë‹˜ ìƒí™©ì„ ë³´ë‹ˆ ì´ëŸ° ë°©í–¥ìœ¼ë¡œ ì ‘ê·¼í•´ë³´ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”"
   - ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ë˜ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì—°ê²°

5. **ì´ì „ ëŒ€í™” ìš”ì•½ ìš”ì²­ì¸ ê²½ìš°**:
   - "ì•„, ì´ì „ì— ìƒë‹´í–ˆë˜ ë‚´ìš©ë“¤ì„ ì •ë¦¬í•´ë“œë¦´ê²Œìš”!"
   - ì‹œê°„ìˆœìœ¼ë¡œ ì£¼ìš” ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ íšŒìƒí•˜ë“¯ ì„¤ëª…
   - "ê·¸ë•Œ ì´ëŸ°ì €ëŸ° ì–˜ê¸°ë¥¼ ë‚˜ëˆ„ì—ˆì—ˆì£ "ì™€ ê°™ì€ ì¹œê·¼í•œ í†¤

**ì‘ë‹µ êµ¬ì¡°:**
- ì œëª©: ì»¨í…ìŠ¤íŠ¸ì— "ì²« ìƒí˜¸ì‘ìš©"ì´ë¼ê³  ëª…ì‹œëœ ê²½ìš°ì—ë§Œ "[ì‚¬ìš©ìëª…]ë‹˜ ì•ˆë…•í•˜ì„¸ìš”!"ë¡œ ì‹œì‘
- ì´ì–´ì§€ëŠ” ëŒ€í™”: ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ìœ¼ë¡œ ì‹œì‘
- ë³¸ë¬¸ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ í˜•íƒœ
- ê³¼ë„í•œ ### êµ¬ì¡°í™”ë‚˜ ë²ˆí˜¸ ë§¤ê¸°ê¸° ì§€ì–‘
- ë§ˆì§€ë§‰ì— "í˜¹ì‹œ ë” ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”!" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë§ˆë¬´ë¦¬

**ì¤‘ìš” ì›ì¹™:**
- ë³´ê³ ì„œë‚˜ ë§¤ë‰´ì–¼ ê°™ì€ í˜•ì‹ì„ ìš”êµ¬í•˜ë©´, ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±
- ì¹œêµ¬ë‚˜ ì„ ë°°ê°€ ì¡°ì–¸í•´ì£¼ëŠ” ëŠë‚Œì˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´
- ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ëŠ” ì ì ˆí•œ ê¸¸ì´ì™€ ê¹Šì´
- ë¶ˆí•„ìš”í•œ ì •ë³´ëŠ” ì–µì§€ë¡œ ë„£ì§€ ì•Šê¸°
- **ì´ì „ ëŒ€í™” ë‚´ì—­ì´ ì œê³µë˜ë©´ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ ì—°ì†ì„± ìˆëŠ” ìƒë‹´ ì§„í–‰**

** ë‰´ìŠ¤ ë°ì´í„° í™œìš© ê°€ì´ë“œë¼ì¸:**
- ì—…ê³„ íŠ¸ë Œë“œë‚˜ ì±„ìš© ì‹œì¥ì— ëŒ€í•œ ì§ˆë¬¸ì´ ìˆì„ ë•Œ ê´€ë ¨ ë‰´ìŠ¤ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©
- "ìµœê·¼ ë‰´ìŠ¤ë¥¼ ë³´ë‹ˆê¹Œ...", "ì—…ê³„ ì†Œì‹ì— ë”°ë¥´ë©´..." ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ ë‰´ìŠ¤ ë‚´ìš© ì¸ìš©
- AI, ê¸ˆìœµ, ë°˜ë„ì²´, ì œì¡° ë„ë©”ì¸ë³„ ìµœì‹  íŠ¸ë Œë“œì™€ ì±„ìš© ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ í˜„ì‹¤ì ì¸ ì¡°ì–¸ ì œê³µ
- ë‰´ìŠ¤ ì¶œì²˜(source)ì™€ ê²Œì‹œì¼(published_date)ì„ ê°„ë‹¨íˆ ì–¸ê¸‰í•˜ì—¬ ì‹ ë¢°ì„± í™•ë³´
- ë‹¨ìˆœíˆ ë‰´ìŠ¤ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ê³ , ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ì‹¤ìš©ì ì¸ ì¡°ì–¸ê³¼ ì—°ê²°

** ìµœì‹  ë‰´ìŠ¤/íŠ¸ë Œë“œ ì§ˆë¬¸ ì‹œ ìš°ì„  ëŒ€ì‘ ê·œì¹™:**
ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ë©´ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”:
- "ìµœì‹  ë‰´ìŠ¤", "ìµœê·¼ ë‰´ìŠ¤", "ì—…ê³„ ì†Œì‹", "ì‹œì¥ ë™í–¥", "íŠ¸ë Œë“œ", "í˜„ì¬ ìƒí™©"
- "ìš”ì¦˜", "ì§€ê¸ˆ", "í˜„ì¬", "ìµœê·¼", "ì˜¬í•´", "2024ë…„", "2025ë…„"
- "ì±„ìš© ì‹œì¥", "ì·¨ì—… íŠ¸ë Œë“œ", "ì—…ê³„ ë³€í™”", "ì‚°ì—… ë™í–¥"
- "ì–´ë–¤ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€", "ë¬´ìŠ¨ ë³€í™”ê°€", "ì–´ë–¤ íë¦„"

**ìµœì‹  ë‰´ìŠ¤ ì§ˆë¬¸ ê°ì§€ ì‹œ ëŒ€ì‘ ë°©ì‹:**
1. **ìš°ì„ ìˆœìœ„**: ë‰´ìŠ¤ ë°ì´í„° > ì»¤ë¦¬ì–´ ì‚¬ë¡€ > êµìœ¡ê³¼ì •
2. **ì‹œì‘ í‘œí˜„**: "ìµœê·¼ ì—…ê³„ ì†Œì‹ì„ ë³´ë©´...", "ìš”ì¦˜ ë‰´ìŠ¤ë¥¼ ì‚´í´ë³´ë‹ˆ...", "ìµœì‹  íŠ¸ë Œë“œë¥¼ ë³´ë©´..."
3. **êµ¬ì²´ì  ì¸ìš©**: ì œê³µëœ ë‰´ìŠ¤ì˜ ì œëª©, ë‚´ìš©, ì¶œì²˜ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰
4. **ì‹¤ìš©ì  ì—°ê²°**: ë‰´ìŠ¤ ë‚´ìš©ì„ ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ì¡°ì–¸ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
5. **ì‹ ë¢°ì„± í™•ë³´**: "â—‹â—‹ì—ì„œ ë³´ë„ëœ ë°”ì— ë”°ë¥´ë©´...", "â–³ì›” ë°œí‘œëœ ìë£Œì— ì˜í•˜ë©´..." ì‹ìœ¼ë¡œ ì¶œì²˜ ëª…ì‹œ

**ì‘ë‹µ ì˜ˆì‹œ (ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´):**

[ì²« ìƒí˜¸ì‘ìš©ì¸ ê²½ìš°]
ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” G.Navi AI ì»¤ë¦¬ì–´ ì½”ì¹˜ì˜ˆìš”. Application PMìœ¼ë¡œì˜ ì„±ì¥ ê²½ë¡œì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹œêµ°ìš”. ì¢‹ì€ ëª©í‘œë¥¼ ì„¸ìš°ì…¨ë„¤ìš”!

[ì´ì–´ì§€ëŠ” ëŒ€í™”ì¸ ê²½ìš°] 
Application PMìœ¼ë¡œì˜ ì„±ì¥ ê²½ë¡œì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹œêµ°ìš”. ì¢‹ì€ ëª©í‘œë¥¼ ì„¸ìš°ì…¨ë„¤ìš”!

[ì´ì „ ëŒ€í™” ìš”ì•½ ìš”ì²­ì¸ ê²½ìš°]
ì•„, ì´ì „ì— ìƒë‹´í–ˆë˜ ë‚´ìš©ë“¤ì„ ì •ë¦¬í•´ë“œë¦´ê²Œìš”! ê·¸ë™ì•ˆ ì´ëŸ°ì €ëŸ° ì–˜ê¸°ë¥¼ ë‚˜ëˆ„ì—ˆì—ˆì£ .

ì²˜ìŒì—ëŠ” ë°±ì—”ë“œ ê°œë°œìì—ì„œ PMìœ¼ë¡œì˜ ì „í™˜ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì…¨ì—ˆê³ , ê·¸ë•Œ ê¸°ìˆ ì  ë°±ê·¸ë¼ìš´ë“œê°€ PM ì—­í• ì— ì–´ë–¤ ë„ì›€ì´ ë˜ëŠ”ì§€ ì„¤ëª…ë“œë ¸ì—ˆì–´ìš”. ê·¸ ë‹¤ìŒì—ëŠ” êµ¬ì²´ì ì¸ ìŠ¤í‚¬ì…‹ì— ëŒ€í•´ì„œë„ ë¬¼ì–´ë³´ì…¨ê³ ...

(ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ì´ì „ ëŒ€í™” ìš”ì•½)

í˜¹ì‹œ ë” êµ¬ì²´ì ìœ¼ë¡œ ê¶ê¸ˆí•œ ë¶€ë¶„ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”!        """

    def _dict_to_markdown(self, data: Union[Dict, List, Any], depth: int = 0, show_empty: bool = True) -> str:
        """dict, list ë“±ì˜ JSON íƒ€ì…ì„ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
        indent = "  " * depth
        
        if isinstance(data, dict):
            if not data:
                return "*(ë‚´ìš© ì—†ìŒ)*" if show_empty else ""
            
            markdown_lines = []
            for key, value in data.items():
                # í‚¤ ì •ë¦¬ (ì–¸ë”ìŠ¤ì½”ì–´ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ê³  íƒ€ì´í‹€ ì¼€ì´ìŠ¤ ì ìš©)
                display_key = key.replace('_', ' ').title()
                
                if isinstance(value, (dict, list)):
                    nested_content = self._dict_to_markdown(value, depth + 1, show_empty)
                    if nested_content.strip() or show_empty:  # show_emptyê°€ Trueë©´ ë¹ˆ ë‚´ìš©ë„ í‘œì‹œ
                        markdown_lines.append(f"{indent}- **{display_key}:**")
                        markdown_lines.append(nested_content)
                else:
                    formatted_value = self._format_value(value, show_empty)
                    if formatted_value or show_empty:  # show_emptyê°€ Trueë©´ ë¹ˆ ê°’ë„ í‘œì‹œ
                        markdown_lines.append(f"{indent}- **{display_key}:** {formatted_value}")
            
            return "\n".join(markdown_lines) if markdown_lines else ("*(ë‚´ìš© ì—†ìŒ)*" if show_empty else "")
        
        elif isinstance(data, list):
            if not data:
                return "*(ë¹ˆ ëª©ë¡)*" if show_empty else ""
            
            markdown_lines = []
            for i, item in enumerate(data):
                if isinstance(item, (dict, list)):
                    nested_content = self._dict_to_markdown(item, depth + 1, show_empty)
                    if nested_content.strip() or show_empty:  # show_emptyê°€ Trueë©´ ë¹ˆ ë‚´ìš©ë„ í‘œì‹œ
                        # ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ì˜ ê²½ìš° ë” ê¹”ë”í•˜ê²Œ í‘œì‹œ
                        if isinstance(item, dict) and len(item) <= 3 and not show_empty:
                            # ê°„ë‹¨í•œ ë”•ì…”ë„ˆë¦¬ëŠ” í•œ ì¤„ë¡œ í‘œì‹œ (show_emptyê°€ Falseì¼ ë•Œë§Œ)
                            summary = self._create_dict_summary(item)
                            if summary:
                                markdown_lines.append(f"{indent}{len([x for x in markdown_lines if x.strip()]) + 1}. {summary}")
                        else:
                            markdown_lines.append(f"{indent}{len([x for x in markdown_lines if x.strip()]) + 1}. ")
                            markdown_lines.append(nested_content)
                else:
                    formatted_item = self._format_value(item, show_empty)
                    if formatted_item or show_empty:  # show_emptyê°€ Trueë©´ ë¹ˆ ê°’ë„ í‘œì‹œ
                        markdown_lines.append(f"{indent}{len([x for x in markdown_lines if x.strip()]) + 1}. {formatted_item}")
            
            return "\n".join(markdown_lines) if markdown_lines else ("*(ë¹ˆ ëª©ë¡)*" if show_empty else "")
        
        else:
            return self._format_value(data, show_empty)
    
    def _create_dict_summary(self, data: dict) -> str:
        """ë”•ì…”ë„ˆë¦¬ë¥¼ ê°„ë‹¨í•œ ìš”ì•½ ë¬¸ìì—´ë¡œ ë³€í™˜"""
        if not data:
            return ""
        
        # ëª¨ë“  í•„ë“œ í¬í•¨
        items = []
        for key, value in data.items():
            display_key = key.replace('_', ' ').title()
            formatted_value = self._format_value(value)
            if formatted_value:
                items.append(f"{display_key}: {formatted_value}")
        
        return " | ".join(items) if items else ""
    
    def _format_value(self, value: Any, show_empty: bool = True) -> str:
        """ê°’ì„ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í¬ë§·íŒ…"""
        if value is None:
            return "*ì •ë³´ ì—†ìŒ*" if show_empty else ""
        elif isinstance(value, bool):
            return "ì˜ˆ" if value else "ì•„ë‹ˆì˜¤"
        elif isinstance(value, (int, float)):
            # íŠ¹ë³„í•œ ìˆ«ì ê°’ë“¤ ì²˜ë¦¬
            if value == 1.0 and isinstance(value, float):
                return "100%"  # confidence_score ê°™ì€ ê²½ìš°
            return f"{value:,}"
        elif isinstance(value, str):
            # ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬
            if not value.strip():
                return "*ì •ë³´ ì—†ìŒ*" if show_empty else ""
            # íŠ¹ì • íŒ¨í„´ë“¤ ì²˜ë¦¬
            if value.strip() in ['*ì •ë³´ ì—†ìŒ*', 'ì •ë³´ ì—†ìŒ', 'N/A', 'n/a', 'null', 'undefined']:
                return "*ì •ë³´ ì—†ìŒ*" if show_empty else ""
            
            # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì²˜ë¦¬
            processed_value = value.replace('\\n', '\n').replace('\\t', '\t').replace('\\r', '\r')
            
            # ê¸´ í…ìŠ¤íŠ¸ëŠ” ìš”ì•½ (ë‹¨, í•œêµ­ì–´ ê¸°ì¤€ìœ¼ë¡œ)
            if len(processed_value) > 100:
                return f"{processed_value[:100]}..."
            return processed_value
        else:
            return str(value) if str(value) != 'None' else ("*ì •ë³´ ì—†ìŒ*" if show_empty else "")

    def format_adaptive_response(self,
                                user_question: str,
                                state: Dict[str, Any]) -> Dict[str, Any]:
        """LLM ê¸°ë°˜ ì ì‘ì  ì‘ë‹µ í¬ë§·íŒ… - ì§ì ‘ ë§ˆí¬ë‹¤ìš´ ì‘ë‹µ"""
        self.logger.info("LLM ê¸°ë°˜ ì ì‘ì  ì‘ë‹µ í¬ë§·íŒ… ì‹œì‘")
        
        try:
            # GNaviStateì—ì„œ ë°ì´í„° ì¶”ì¶œ
            intent_analysis = state.get("intent_analysis", {})
            user_data = state.get("user_data", {})
            career_cases = state.get("career_cases", [])
            current_session_messages = state.get("current_session_messages", [])
            education_courses = state.get("education_courses", {})
            past_conversations = state.get("past_conversations", [])  # ê³¼ê±° ëŒ€í™” ë‚´ì—­ ì¶”ê°€
            news_data = state.get("news_data", [])  # ë‰´ìŠ¤ ë°ì´í„° ì¶”ê°€
            
            # ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ
            user_name = user_data.get('name', 'ë‹˜')
            session_id = user_data.get('conversationId', '')
            
            # LLMì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_data = self._prepare_context_for_llm(
                user_question, intent_analysis, 
                user_data, career_cases, 
                current_session_messages, education_courses, past_conversations, news_data
            )
            
            # LLM í˜¸ì¶œí•˜ì—¬ ì§ì ‘ ë§ˆí¬ë‹¤ìš´ ì‘ë‹µ ìƒì„±
            formatted_content = self._call_llm_for_adaptive_formatting(context_data)
            
            # ìµœì¢… ì‘ë‹µ êµ¬ì„±
            result = {
                "formatted_content": formatted_content,
                "format_type": "adaptive",
                "timestamp": datetime.now().isoformat(),
                "user_name": user_name,
                "session_id": session_id
            }
            
            self.logger.info("LLM ê¸°ë°˜ ë§ˆí¬ë‹¤ìš´ ì‘ë‹µ í¬ë§·íŒ… ì™„ë£Œ")
            return result
            
        except Exception as e:
            self.logger.error(f"LLM ê¸°ë°˜ ì‘ë‹µ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            # í´ë°±: ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±
            user_name = user_data.get('name', 'ë‹˜')
            
            # ì²« ìƒí˜¸ì‘ìš© ì—¬ë¶€ í™•ì¸
            is_first_interaction = not current_session_messages or len(current_session_messages) <= 1
            
            if is_first_interaction:
                fallback_content = f"""# {user_name}ë‹˜ ì•ˆë…•í•˜ì„¸ìš”!

í˜„ì¬ ì‹œìŠ¤í…œ ì²˜ë¦¬ ì¤‘ ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê±°ë‚˜, ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.

---
*G.Navi AIê°€ {user_name}ë‹˜ì˜ ì»¤ë¦¬ì–´ ì„±ì¥ì„ ì‘ì›í•©ë‹ˆë‹¤!*
"""
            else:
                fallback_content = f"""ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì‹œìŠ¤í…œ ì²˜ë¦¬ ì¤‘ ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê±°ë‚˜, ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.

---
*G.Navi AIê°€ {user_name}ë‹˜ì˜ ì»¤ë¦¬ì–´ ì„±ì¥ì„ ì‘ì›í•©ë‹ˆë‹¤!*
"""
            return {
                "formatted_content": fallback_content,
                "format_type": "fallback",
                "timestamp": datetime.now().isoformat(),
                "user_name": user_name,
                "session_id": user_data.get('conversationId', '')
            }
    
    def _prepare_context_for_llm(self, user_question: str, intent_analysis: Dict[str, Any],
                                user_data: Dict[str, Any],
                                career_cases: List[Any],
                                current_session_messages: List[Dict],
                                education_courses: Dict[str, Any] = None,
                                past_conversations: List[Dict] = None,
                                news_data: List[Dict] = None) -> str:
        """LLMì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ (í†µí•©ëœ current_session_messages ì‚¬ìš©)"""
        
        context_sections = []
        
        #  í†µí•©ëœ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì²˜ë¦¬ (í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì œì™¸)
        previous_messages = current_session_messages[:-1] if len(current_session_messages) > 1 else []
        
        # ì²« ìƒí˜¸ì‘ìš© ì—¬ë¶€ íŒë‹¨
        is_first_interaction = len(previous_messages) == 0
        
        # ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
        if previous_messages:
            context_sections.append(" **ì´ì „ ëŒ€í™” ê¸°ë¡**:")
            context_sections.append(" **ì¤‘ìš”: ì´ë¯¸ ì´ì „ ëŒ€í™”ê°€ ìˆìœ¼ë¯€ë¡œ ì´ë¥¼ ì°¸ê³ í•˜ì—¬ ì—°ì†ì„± ìˆëŠ” ë‹µë³€ì„ í•˜ì„¸ìš”!**")
            context_sections.append(" **íŠ¹ë³„ ì§€ì‹œ**: ì‚¬ìš©ìê°€ 'ì´ì „ì—', 'ì•ì„œ', 'ê³¼ê±°ì—', 'ì „ì—' ë“±ì˜ í‘œí˜„ìœ¼ë¡œ ì´ì „ ëŒ€í™”ë¥¼ ì–¸ê¸‰í•˜ë©´ ì•„ë˜ ëŒ€í™” ë‚´ì—­ì„ êµ¬ì²´ì ìœ¼ë¡œ ìš”ì•½í•´ì„œ ë‹µë³€í•˜ì„¸ìš”.")
            
            # ìµœê·¼ 20ê°œ ëŒ€í™”ë§Œ í¬í•¨ (í†µí•©ëœ ë§Œí¼ ì¡°ê¸ˆ ë” ë§ì´)
            recent_messages = previous_messages[-20:] if len(previous_messages) > 20 else previous_messages
            
            for i, msg in enumerate(recent_messages, 1):
                try:
                    role = msg.get("role", "unknown")
                    content = msg.get("content", "")
                    timestamp = msg.get("timestamp", "")
                    role_display = "ì‚¬ìš©ì" if role == "user" else "AI"
                    
                    # ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ (í†µí•©ëœ ì²˜ë¦¬)
                    if len(content) > 250:
                        content = content[:250] + "..."
                    
                    # íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´ í¬í•¨
                    timestamp_str = f" ({timestamp})" if timestamp else ""
                    
                    # ë³µì› ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€ (ì„ íƒì )
                    source_info = ""
                    restored_from = msg.get("metadata", {}).get("restored_from")
                    if restored_from == "springboot":
                        source_info = " [ë³µì›]"
                    
                    context_sections.append(f"{i}. [{role_display}]{timestamp_str}{source_info} {content}")
                except Exception as e:
                    self.logger.warning(f"ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
            context_sections.append("")  # ë¹ˆ ì¤„ ì¶”ê°€
        
        # ì²« ìƒí˜¸ì‘ìš©ì¸ ê²½ìš°ì—ë§Œ ì¸ì‚¬ë§ ì•ˆë‚´
        if is_first_interaction:
            context_sections.append("ğŸ”µ **ì²« ìƒí˜¸ì‘ìš©**: ì´ ì‚¬ìš©ìì™€ì˜ ì²« ë§Œë‚¨ì´ë¯€ë¡œ ì¸ì‚¬ë§ë¡œ ì‹œì‘í•˜ì„¸ìš”.")
            context_sections.append("")  # ë¹ˆ ì¤„ ì¶”ê°€
        
        # ì‚¬ìš©ì ì§ˆë¬¸
        context_sections.append(f'**í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸**: "{user_question}"')
        
        # ì´ì „ ëŒ€í™” ìš”ì•½ ìš”ì²­ì¸ì§€ ê°ì§€ (ê°œì„ ëœ í‚¤ì›Œë“œ)
        history_keywords = ['ì´ì „', 'ì „ì—', 'ì•ì„œ', 'ê³¼ê±°', 'ì˜ˆì „', 'ì§ˆë¬¸í–ˆë˜', 'ë§í–ˆë˜', 'ì–˜ê¸°í–ˆë˜', 'ìƒë‹´í–ˆë˜', 'ëŒ€í™”', 'íˆìŠ¤í† ë¦¬', 'ë‚´ì—­', 'ê¸°ë¡', 'ë¬´ì—‡ì„', 'ë­˜', 'ì–´ë–¤', 'ì–¸ì œ', 'ì²˜ìŒì—', 'ì§€ë‚œë²ˆ', 'ê·¸ë•Œ']
        is_asking_for_history = any(keyword in user_question.lower() for keyword in history_keywords)
        
        if is_asking_for_history and previous_messages:
            context_sections.append(" **ì§ˆë¬¸ ìœ í˜• ê°ì§€**: ì‚¬ìš©ìê°€ ì´ì „ ëŒ€í™” ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìœ„ì˜ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ì°¸ê³ í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ìš”ì•½í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.")
        
        
        context_sections.append("")  # ë¹ˆ ì¤„ ì¶”ê°€
        
        # ì‚¬ìš©ì í”„ë¡œí•„
        # ìƒˆë¡œìš´ JSON êµ¬ì¡°: {name: "", projects: [...]}
        if user_data and isinstance(user_data, dict) and any(user_data.values()):
            user_profile_md = self._dict_to_markdown(user_data, show_empty=False)
            if user_profile_md.strip():
                context_sections.append(f"""
ì‚¬ìš©ì í”„ë¡œí•„:
{user_profile_md}
""")
        
        # ì˜ë„ ë¶„ì„
        if intent_analysis and isinstance(intent_analysis, dict) and any(intent_analysis.values()):
            # ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš° ì œì™¸
            if not intent_analysis.get("error"):
                intent_analysis_md = self._dict_to_markdown(intent_analysis, show_empty=False)
                if intent_analysis_md.strip():
                    context_sections.append(f"""
ì˜ë„ ë¶„ì„ ê²°ê³¼:
{intent_analysis_md}
""")
        
        # ì»¤ë¦¬ì–´ ì‚¬ë¡€
        career_cases_to_use = career_cases if career_cases else []
        if career_cases_to_use:
            career_section = " **ì‹¤ì œ ì‚¬ë‚´ ì»¤ë¦¬ì–´ ì‚¬ë¡€ ì°¸ê³  ìë£Œ**:\n"
            career_section += "ì €í¬ íšŒì‚¬ êµ¬ì„±ì›ë“¤ì˜ ì‹¤ì œ ì»¤ë¦¬ì–´ ê²½í—˜ì…ë‹ˆë‹¤. ìƒë‹´í•  ë•Œ ìì—°ìŠ¤ëŸ½ê²Œ ì°¸ê³ í•´ì£¼ì„¸ìš”.\n\n"
            
            added_cases = 0
            for i, case in enumerate(career_cases_to_use[:5]):  # ìµœëŒ€ 5ê°œ ì‚¬ë¡€ í‘œì‹œ
                case_md = self._create_detailed_career_case_markdown(case, show_empty=False)
                if case_md.strip():  # ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                    added_cases += 1
                    # Employee ID ì¶”ì¶œ ì‹œë„
                    employee_id = ""
                    employee_name = ""
                    if isinstance(case, dict):
                        metadata = case.get('metadata', {})
                        if isinstance(metadata, dict):
                            employee_id = metadata.get('employee_id', '')
                            employee_name = metadata.get('name', '')
                    
                    career_section += f"\n### **ì‚¬ë¡€ {added_cases}: {employee_name if employee_name else 'ìµëª…'} {f'({employee_id})' if employee_id else ''}**\n{case_md}\n"
            
            # ì‹¤ì œë¡œ ì¶”ê°€ëœ ì‚¬ë¡€ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨
            if added_cases > 0:
                career_section += "\n**ï¿½ ì‚¬ë¡€ í™œìš© ê°€ì´ë“œ:**\n"
                career_section += "- ìƒë‹´í•  ë•Œ 'ì €í¬ íšŒì‚¬ì—ì„œ ë¹„ìŠ·í•œ ê²½í—˜ì„ í•œ ë¶„ì´ ìˆëŠ”ë°ìš”...' ê°™ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰\n"
                career_section += "- êµ¬ì²´ì ì¸ Employee IDë‚˜ ìƒì„¸ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ì— ë…¹ì—¬ì„œ ì„¤ëª…\n"
                career_section += "- ì‚¬ìš©ì ìƒí™©ê³¼ ìœ ì‚¬í•œ ì‚¬ë¡€ë¥¼ ì°¾ì•„ì„œ ê²½í—˜ê³¼ ì¡°ì–¸ì„ ê³µìœ í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í™œìš©\n"
                career_section += "- ë”±ë”±í•œ ì‚¬ë¡€ ë‚˜ì—´ë³´ë‹¤ëŠ” 'ê·¸ë¶„ ê°™ì€ ê²½ìš°ì—ëŠ”...' ì‹ìœ¼ë¡œ í¸ì•ˆí•˜ê²Œ ì„¤ëª…\n"
                career_section += "- ì„±ì¥ ê³¼ì •, ì–´ë ¤ì› ë˜ ì , ê·¹ë³µ ë°©ë²• ë“±ì„ ìŠ¤í† ë¦¬í…”ë§ ë°©ì‹ìœ¼ë¡œ ì „ë‹¬\n"
                context_sections.append(career_section)
        
        # êµìœ¡ê³¼ì • ì •ë³´ - ìƒˆë¡œ ì¶”ê°€
        if education_courses:
            try:
                education_section = "**êµìœ¡ê³¼ì • ì •ë³´ (URL í¬í•¨)**:\n"
                
                # êµìœ¡ê³¼ì • ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ì´ê³  recommended_coursesê°€ ìˆëŠ” ê²½ìš°
                if isinstance(education_courses, dict) and 'recommended_courses' in education_courses:
                    courses = education_courses['recommended_courses'][:8]  # ìµœëŒ€ 8ê°œë¡œ í™•ì¥
                    for i, course in enumerate(courses):
                        if isinstance(course, dict):
                            course_name = course.get('course_name', course.get('card_name', 'ê³¼ì •ëª… ì—†ìŒ'))
                            url = course.get('url', '')
                            source = course.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
                            duration = course.get('duration_hours', course.get('ì¸ì •í•™ìŠµì‹œê°„', 'ì •ë³´ ì—†ìŒ'))
                            
                            education_section += f"\n=== {i+1}. {course_name} ===\n"
                            education_section += f"ì¶œì²˜: {source}\n"
                            education_section += f"í•™ìŠµì‹œê°„: {duration}ì‹œê°„\n"
                            
                            # mySUNI ê³¼ì •ì˜ ê²½ìš° ì¶”ê°€ ìƒì„¸ ì •ë³´ ì œê³µ
                            if source == 'mysuni':
                                category = course.get('ì¹´í…Œê³ ë¦¬ëª…', '')
                                channel = course.get('ì±„ë„ëª…', '')
                                difficulty = course.get('ë‚œì´ë„', course.get('difficulty_level', ''))
                                rating = course.get('í‰ì ', '')
                                enrollments = course.get('ì´ìˆ˜ììˆ˜', '')
                                skills = course.get('skillset', course.get('ì§ë¬´', []))
                                
                                if category:
                                    education_section += f"ì¹´í…Œê³ ë¦¬: {category}\n"
                                if channel:
                                    education_section += f"ì±„ë„: {channel}\n"
                                if difficulty:
                                    education_section += f"ë‚œì´ë„: {difficulty}\n"
                                if rating:
                                    education_section += f"í‰ì : {rating}/5.0\n"
                                if enrollments:
                                    education_section += f"ì´ìˆ˜ììˆ˜: {enrollments}ëª…\n"
                                if skills and isinstance(skills, list) and skills:
                                    skills_str = ', '.join(skills[:3])  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                                    education_section += f"ê´€ë ¨ ìŠ¤í‚¬: {skills_str}\n"
                            
                            # College ê³¼ì •ì˜ ê²½ìš° ì¶”ê°€ ì •ë³´
                            elif source == 'college':
                                department = course.get('department', course.get('í•™ë¶€', ''))
                                course_type = course.get('course_type', course.get('êµìœ¡ìœ í˜•', ''))
                                standard_course = course.get('í‘œì¤€ê³¼ì •', '')
                                
                                if department:
                                    education_section += f"í•™ë¶€: {department}\n"
                                if course_type:
                                    education_section += f"êµìœ¡ìœ í˜•: {course_type}\n"
                                if standard_course:
                                    education_section += f"í‘œì¤€ê³¼ì •: {standard_course}\n"
                            
                            # URL ì •ë³´ - í•™ìŠµí•˜ê¸° í˜•íƒœë¡œ ë³€ê²½
                            if url and url.strip() and url != 'ì •ë³´ ì—†ìŒ':
                                education_section += f"ì‹¤ì œURL: {url}\n"
                                education_section += f"---\n**[í•™ìŠµí•˜ê¸°]({url})**\n"
                            else:
                                education_section += f"URL: ì •ë³´ ì—†ìŒ (í…ìŠ¤íŠ¸ë§Œ: {course_name})\n"
                            
                            education_section += "\n"
                
                # êµìœ¡ê³¼ì • ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
                elif isinstance(education_courses, list):
                    for i, course in enumerate(education_courses[:8]):  # ìµœëŒ€ 8ê°œë¡œ í™•ì¥
                        if isinstance(course, dict):
                            course_name = course.get('course_name', course.get('card_name', 'ê³¼ì •ëª… ì—†ìŒ'))
                            url = course.get('url', '')
                            source = course.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
                            duration = course.get('duration_hours', course.get('ì¸ì •í•™ìŠµì‹œê°„', 'ì •ë³´ ì—†ìŒ'))
                            
                            education_section += f"\n=== {i+1}. {course_name} ===\n"
                            education_section += f"ì¶œì²˜: {source}\n"
                            education_section += f"í•™ìŠµì‹œê°„: {duration}ì‹œê°„\n"
                            
                            # ì¶”ê°€ ìƒì„¸ ì •ë³´ ì œê³µ (mySUNI/College êµ¬ë¶„)
                            if source == 'mysuni':
                                category = course.get('ì¹´í…Œê³ ë¦¬ëª…', '')
                                difficulty = course.get('ë‚œì´ë„', '')
                                rating = course.get('í‰ì ', '')
                                enrollments = course.get('ì´ìˆ˜ììˆ˜', '')
                                skills = course.get('skillset', course.get('ì§ë¬´', []))
                                
                                if category:
                                    education_section += f"ì¹´í…Œê³ ë¦¬: {category}\n"
                                if difficulty:
                                    education_section += f"ë‚œì´ë„: {difficulty}\n"
                                if rating:
                                    education_section += f"í‰ì : {rating}/5.0\n"
                                if enrollments:
                                    education_section += f"ì´ìˆ˜ììˆ˜: {enrollments}ëª…\n"
                                if skills and isinstance(skills, list) and skills:
                                    skills_str = ', '.join(skills[:3])
                                    education_section += f"ê´€ë ¨ ìŠ¤í‚¬: {skills_str}\n"
                            
                            elif source == 'college':
                                department = course.get('department', course.get('í•™ë¶€', ''))
                                course_type = course.get('course_type', course.get('êµìœ¡ìœ í˜•', ''))
                                
                                if department:
                                    education_section += f"í•™ë¶€: {department}\n"
                                if course_type:
                                    education_section += f"êµìœ¡ìœ í˜•: {course_type}\n"
                            
                            # URL ì •ë³´ - í•™ìŠµí•˜ê¸° í˜•íƒœë¡œ ë³€ê²½
                            if url and url.strip() and url != 'ì •ë³´ ì—†ìŒ':
                                education_section += f"ì‹¤ì œURL: {url}\n"
                                education_section += f"---\n**[í•™ìŠµí•˜ê¸°]({url})**\n"
                            else:
                                education_section += f"URL: ì •ë³´ ì—†ìŒ (í…ìŠ¤íŠ¸ë§Œ: {course_name})\n"
                            
                            education_section += "\n"
                
                # ê¸°íƒ€ í˜•íƒœì˜ ë°ì´í„°
                else:
                    education_section += f"{str(education_courses)[:300]}...\n"
                
                education_section += "\n êµìœ¡ê³¼ì • ì¶”ì²œ ê°€ì´ë“œ:\n"
                education_section += "- ìƒë‹´ ì‹œ 'ì´ëŸ° ê³¼ì •ì´ ë„ì›€ì´ ë  ê²ƒ ê°™ì•„ìš”' ì‹ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ì²œ\n"
                education_section += "- í‰ì ì´ë‚˜ ì´ìˆ˜ììˆ˜ ê°™ì€ ì •ë³´ë„ 'ê½¤ í‰ì ì´ ì¢‹ë”ë¼êµ¬ìš”' ì‹ìœ¼ë¡œ í¸ì•ˆí•˜ê²Œ ì–¸ê¸‰\n"
                education_section += "- URLì´ ìˆëŠ” ê³¼ì •ì€ [í•™ìŠµí•˜ê¸°] ë§í¬ë¡œ ì•ˆë‚´\n"
                education_section += "- ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ê³¼ì •ì„ ê³¨ë¼ì„œ ì¶”ì²œí•˜ë˜ ë„ˆë¬´ ë§ì§€ ì•Šê²Œ (2-3ê°œ ì •ë„)\n"
                education_section += "- ì‹¤ì œ URLë§Œ ì‚¬ìš©í•˜ê³  ì„ì˜ë¡œ ìƒì„±í•˜ì§€ ì•Šê¸°"
                
                context_sections.append(education_section)
                
            except Exception as e:
                self.logger.warning(f"êµìœ¡ê³¼ì • ì •ë³´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                # í´ë°±ìœ¼ë¡œ ê°„ë‹¨í•œ í˜•íƒœë¼ë„ ì œê³µ
                context_sections.append(f"**êµìœ¡ê³¼ì • ì •ë³´**: {str(education_courses)[:200]}...")
        
        # ğŸ—ƒï¸ ìƒˆë¡œìš´ ê³¼ê±° ëª¨ë“  ì±„íŒ… ì„¸ì…˜ì˜ ëŒ€í™”ë‚´ì—­ ì¶”ê°€ (VectorDBì—ì„œ ê²€ìƒ‰ëœ ë‚´ìš©)
        if past_conversations and len(past_conversations) > 0:
            past_conversations_section = "**ê³¼ê±° ëª¨ë“  ì±„íŒ… ì„¸ì…˜ì˜ ê´€ë ¨ ëŒ€í™”ë‚´ì—­**:\n"
            past_conversations_section += "ì´ì „ ì„¸ì…˜ë“¤ì—ì„œ ê´€ë ¨ì„±ì´ ë†’ì€ ëŒ€í™” ë‚´ìš©ë“¤ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê³¼ê±° ì§ˆë¬¸ê³¼ ìƒë‹´ ì´ë ¥ì„ ì°¸ê³ í•˜ì—¬ ì—°ì†ì„± ìˆëŠ” ìƒë‹´ì„ ì œê³µí•˜ì„¸ìš”.\n\n"
            
            for i, past_conv in enumerate(past_conversations[:3], 1):  # ìµœëŒ€ 3ê°œ ê³¼ê±° ëŒ€í™” ì„¸ì…˜
                try:
                    conversation_id = past_conv.get("conversation_id", f"ì„¸ì…˜_{i}")
                    summary = past_conv.get("summary", "")
                    content_snippet = past_conv.get("content_snippet", "")
                    created_at = past_conv.get("created_at", "")
                    relevance_score = past_conv.get("relevance_score", 0)
                    message_count = past_conv.get("message_count", 0)
                    
                    past_conversations_section += f"###  **ê³¼ê±° ì„¸ì…˜ {i}** (ê´€ë ¨ë„: {relevance_score:.2f})\n"
                    if created_at:
                        past_conversations_section += f"**ì„¸ì…˜ ë‚ ì§œ**: {created_at[:10]}\n"
                    past_conversations_section += f"**ë©”ì‹œì§€ ìˆ˜**: {message_count}ê°œ\n"
                    
                    if summary and summary.strip():
                        past_conversations_section += f"**ëŒ€í™” ìš”ì•½**: {summary}\n"
                    
                    if content_snippet and content_snippet.strip():
                        past_conversations_section += f"**ì£¼ìš” ë‚´ìš©**: {content_snippet}\n"
                    
                    past_conversations_section += "\n"
                    
                except Exception as e:
                    self.logger.warning(f"ê³¼ê±° ëŒ€í™” ë‚´ì—­ íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
            
            past_conversations_section += "\n** ê³¼ê±° ëŒ€í™” í™œìš© ê°€ì´ë“œ:**\n"
            past_conversations_section += "- ì‚¬ìš©ìê°€ 'ì´ì „ì—', 'ì „ì—', 'ê³¼ê±°ì—' ë“±ì˜ í‘œí˜„ì„ ì‚¬ìš©í•˜ë©´ ìœ„ ê³¼ê±° ëŒ€í™” ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰\n"
            past_conversations_section += "- 'ì´ì „ì— ë¹„ìŠ·í•œ ì§ˆë¬¸ì„ í•´ì£¼ì…¨ì—ˆëŠ”ë°ìš”...' ì‹ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°\n"
            past_conversations_section += "- ê³¼ê±° ìƒë‹´ ë‚´ìš©ê³¼ í˜„ì¬ ì§ˆë¬¸ì„ ì—°ê²°í•˜ì—¬ ë°œì „ì ì¸ ì¡°ì–¸ ì œê³µ\n"
            past_conversations_section += "- ì‚¬ìš©ìì˜ ì„±ì¥ ê³¼ì •ì´ë‚˜ ê´€ì‹¬ì‚¬ì˜ ë³€í™”ë¥¼ íŒŒì•…í•˜ì—¬ ê°œì¸í™”ëœ ìƒë‹´ ì§„í–‰\n"
            past_conversations_section += "- ê³¼ê±° ëŒ€í™” ìš”ì•½ê³¼ ì£¼ìš” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ë§¥ë½ ìˆëŠ” ë‹µë³€ ì œê³µ\n"
            
            context_sections.append(past_conversations_section)
        
        # ğŸ“° ë‰´ìŠ¤ ë°ì´í„° ì •ë³´ ì¶”ê°€
        if news_data and len(news_data) > 0:
            news_section = "**ìµœì‹  ì—…ê³„ ë‰´ìŠ¤ ë° íŠ¸ë Œë“œ ì •ë³´**:\n"
            news_section += "ì—…ê³„ ìµœì‹  ì†Œì‹ê³¼ ì±„ìš© íŠ¸ë Œë“œ ì •ë³´ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê²½ìš° ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•´ì£¼ì„¸ìš”.\n\n"
            
            for i, news in enumerate(news_data[:3], 1):  # ìµœëŒ€ 3ê°œ ë‰´ìŠ¤
                try:
                    title = news.get("title", "ì œëª© ì—†ìŒ")
                    domain = news.get("domain", "")
                    category = news.get("category", "")
                    content = news.get("content", "")
                    published_date = news.get("published_date", "")
                    source = news.get("source", "")
                    similarity_score = news.get("similarity_score", 0)
                    
                    news_section += f"### **ë‰´ìŠ¤ {i}** (ê´€ë ¨ë„: {similarity_score:.2f})\n"
                    news_section += f"**ì œëª©**: {title}\n"
                    if domain:
                        news_section += f"**ë„ë©”ì¸**: {domain}\n"
                    if category:
                        news_section += f"**ì¹´í…Œê³ ë¦¬**: {category}\n"
                    if published_date:
                        news_section += f"**ë°œí–‰ì¼**: {published_date}\n"
                    if source:
                        news_section += f"**ì¶œì²˜**: {source}\n"
                    if content:
                        news_section += f"**ë‚´ìš©**: {content}\n"
                    
                    news_section += "\n"
                    
                except Exception as e:
                    self.logger.warning(f"ë‰´ìŠ¤ ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
            
            news_section += "\n** ë‰´ìŠ¤ í™œìš© ê°€ì´ë“œ:**\n"
            news_section += "- ì—…ê³„ íŠ¸ë Œë“œë‚˜ ì±„ìš© ì‹œì¥ ì§ˆë¬¸ ì‹œ 'ìµœê·¼ ë‰´ìŠ¤ë¥¼ ë³´ë‹ˆê¹Œ...' ì‹ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì¸ìš©\n"
            news_section += "- ì¶œì²˜ì™€ ë°œí–‰ì¼ì„ ê°„ë‹¨íˆ ì–¸ê¸‰í•˜ì—¬ ì‹ ë¢°ì„± í™•ë³´ ('3ì›” í…Œí¬ë‰´ìŠ¤ì— ë”°ë¥´ë©´...')\n"
            news_section += "- ë‰´ìŠ¤ ë‚´ìš©ì„ ë‹¨ìˆœ ë‚˜ì—´í•˜ì§€ ë§ê³  ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ì‹¤ìš©ì  ì¡°ì–¸ê³¼ ì—°ê²°\n"
            news_section += "- AI, ê¸ˆìœµ, ë°˜ë„ì²´, ì œì¡° ë“± ë„ë©”ì¸ë³„ ì „ë¬¸ ì •ë³´ ì œê³µ\n"
            news_section += "- ì±„ìš© íŠ¸ë Œë“œ, ì—°ë´‰ ì •ë³´, í•„ìš” ê¸°ìˆ  ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ í™œìš©\n"
            news_section += "- **ìµœì‹ /íŠ¸ë Œë“œ ì§ˆë¬¸ ì‹œ**: ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê°€ì¥ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ í˜„ì¬ ìƒí™© ì„¤ëª…\n"
            news_section += "- **êµ¬ì²´ì  ì¸ìš©**: 'â—‹â—‹ ë‰´ìŠ¤ì—ì„œ ë³´ë„ëœ ë°”ì— ë”°ë¥´ë©´...' ì‹ìœ¼ë¡œ ì •í™•í•œ ì¶œì²˜ ëª…ì‹œ\n"
            
            context_sections.append(news_section)
        
        # ì§ˆë¬¸ ìœ í˜• ë¶„ì„ (ì„±ëŠ¥ ìµœì í™”)
        career_keywords = ['ì»¤ë¦¬ì–´', 'ì§„ë¡œ', 'ëª©í‘œ', 'ë°©í–¥', 'ê³„íš', 'ë¹„ì „', 'ë¯¸ë˜', 'íšŒì‚¬', 'ì¡°ì§']
        growth_keywords = ['ì„±ì¥', 'ë°œì „', 'íŒ¨ìŠ¤', 'ë¡œë“œë§µ', 'ì–´ë–»ê²Œ', 'ë°©ë²•', 'ë‹¨ê³„', 'ê³¼ì •']
        
        # ìµœì‹  ë‰´ìŠ¤/íŠ¸ë Œë“œ ì§ˆë¬¸ ê°ì§€ í‚¤ì›Œë“œ ì¶”ê°€
        news_keywords = ['ìµœì‹ ', 'ìµœê·¼', 'ë‰´ìŠ¤', 'ì—…ê³„', 'ì†Œì‹', 'ì‹œì¥', 'ë™í–¥', 'íŠ¸ë Œë“œ', 'ìš”ì¦˜', 'ì§€ê¸ˆ', 'í˜„ì¬', 
                        'ì˜¬í•´', '2024', '2025', 'ì±„ìš© ì‹œì¥', 'ì·¨ì—… íŠ¸ë Œë“œ', 'ì—…ê³„ ë³€í™”', 'ì‚°ì—… ë™í–¥',
                        'ì–´ë–¤ ì¼ì´', 'ë¬´ìŠ¨ ë³€í™”', 'ì–´ë–¤ íë¦„', 'í˜„ì¬ ìƒí™©']
        
        is_career_question = any(keyword in user_question.lower() for keyword in career_keywords)
        is_growth_guide_question = any(keyword in user_question.lower() for keyword in growth_keywords)
        is_news_trend_question = any(keyword in user_question.lower() for keyword in news_keywords)
        
        # ìµœì‹  ë‰´ìŠ¤/íŠ¸ë Œë“œ ì§ˆë¬¸ì¸ ê²½ìš° íŠ¹ë³„í•œ ì§€ì¹¨ ì¶”ê°€
        if is_news_trend_question and news_data:
            news_priority_instruction = """

 **ìµœì‹  ë‰´ìŠ¤/íŠ¸ë Œë“œ ì§ˆë¬¸ ê°ì§€ë¨ - ë‰´ìŠ¤ ë°ì´í„° ìš°ì„  í™œìš© ì§€ì¹¨:**
- ì‚¬ìš©ìê°€ ìµœì‹  ì •ë³´ë¥¼ ì›í•˜ë¯€ë¡œ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê°€ì¥ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”
- "ìµœê·¼ ì—…ê³„ ì†Œì‹ì„ ë³´ë©´...", "ìš”ì¦˜ ë‰´ìŠ¤ë¥¼ ì‚´í´ë³´ë‹ˆ...", "ìµœì‹  íŠ¸ë Œë“œë¥¼ ë³´ë©´..." ì‹ìœ¼ë¡œ ì‹œì‘
- ì œê³µëœ ë‰´ìŠ¤ì˜ ì œëª©, ë‚´ìš©, ì¶œì²˜ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì—¬ ì‹ ë¢°ì„± í™•ë³´
- ë‰´ìŠ¤ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í˜„ì‹¤ì ì´ê³  ì‹œì˜ì ì ˆí•œ ì¡°ì–¸ ì œê³µ
- ì—¬ëŸ¬ ë‰´ìŠ¤ê°€ ìˆë‹¤ë©´ ë„ë©”ì¸ë³„ë¡œ ì •ë¦¬í•˜ì—¬ í¬ê´„ì ì¸ ì—…ê³„ í˜„í™© ì œì‹œ
- ì»¤ë¦¬ì–´ ì‚¬ë¡€ë‚˜ êµìœ¡ê³¼ì •ì€ ë‰´ìŠ¤ ê¸°ë°˜ ì¡°ì–¸ì„ ë³´ì™„í•˜ëŠ” ìš©ë„ë¡œë§Œ í™œìš©
"""
            context_sections.append(news_priority_instruction)
        
        # ì»¤ë¦¬ì–´ ê´€ë ¨ ì§ˆë¬¸ì¸ ê²½ìš° íšŒì‚¬ ë¹„ì „ ì •ë³´ ì¶”ê°€
        if is_career_question:
            # Retrieverì—ì„œ íšŒì‚¬ ë¹„ì „ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            from .retriever import CareerEnsembleRetrieverAgent
            retriever = CareerEnsembleRetrieverAgent()
            company_vision_section = retriever.get_company_vision_context()
            if company_vision_section.strip():
                context_sections.append(company_vision_section)
        
        # ì„±ì¥ ê°€ì´ë“œ ì§ˆë¬¸ì¸ ê²½ìš° íŠ¹ë³„í•œ ì§€ì¹¨ ì¶”ê°€
        if is_growth_guide_question and (career_cases or education_courses):
            growth_guide_instruction = """

 ì„±ì¥ ìƒë‹´ ê°€ì´ë“œ:
- ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í†¤ìœ¼ë¡œ ìƒë‹´í•˜ë˜, ë‹¨ê³„ë³„ë¡œ ì²´ê³„ì ì¸ ì¡°ì–¸ ì œê³µ
- "ìŒ, [ì‚¬ìš©ìëª…]ë‹˜ ìƒí™©ì„ ë³´ë‹ˆ ì´ëŸ° ì‹ìœ¼ë¡œ ì ‘ê·¼í•´ë³´ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”" ì‹ìœ¼ë¡œ ì‹œì‘
- ì»¤ë¦¬ì–´ ì‚¬ë¡€ê°€ ìˆìœ¼ë©´ "ì €í¬ íšŒì‚¬ì—ì„œ ë¹„ìŠ·í•œ ê²½í—˜ì„ í•œ ë¶„ì´ ê³„ì‹œëŠ”ë°..." ì‹ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
- 3-6ê°œì›”, 6-12ê°œì›”, 1-2ë…„ ì •ë„ì˜ íƒ€ì„ë¼ì¸ìœ¼ë¡œ ë‚˜ëˆ„ë˜ ë”±ë”±í•˜ì§€ ì•Šê²Œ
- êµìœ¡ê³¼ì •ì´ ìˆìœ¼ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ì²œí•˜ë©´ì„œ ë§í¬ë„ ì œê³µ
"""
            context_sections.append(growth_guide_instruction)
        
        # ì „ì²´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = "\n".join(context_sections)
        
        # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€ ì¶”ê°€
        if len(context_sections) <= 2:  # ì§ˆë¬¸ê³¼ ì‚¬ìš©ì í”„ë¡œí•„ë§Œ ìˆëŠ” ê²½ìš°
            context += """

**ì°¸ê³ : í˜„ì¬ ë¶„ì„ ê°€ëŠ¥í•œ ì¶”ê°€ ì •ë³´ê°€ ì œí•œì ì…ë‹ˆë‹¤. 
ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê¸°ë³¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¼ë°˜ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.**
"""
        
        context += """

 ìƒë‹´ ì‹œ ê¼­ ê¸°ì–µí•˜ì„¸ìš”:
- **ì¸ì‚¬ë§ ê·œì¹™**: ìœ„ì— "ì²« ìƒí˜¸ì‘ìš©"ì´ë¼ê³  ëª…ì‹œëœ ê²½ìš°ì—ë§Œ ì¸ì‚¬ë§ë¡œ ì‹œì‘
- **ì´ì–´ì§€ëŠ” ëŒ€í™”**: "ì´ë¯¸ ëŒ€í™”ê°€ ì§„í–‰ëœ ìƒíƒœ"ë¼ê³  ëª…ì‹œëœ ê²½ìš° ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ ë‹µë³€
- ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ëŒ€í™”ì²´ë¡œ ìƒë‹´í•˜ê¸°
- ì‚¬ìš©ì ì´ë¦„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©í•˜ë©´ì„œ ê³µê°í•˜ê¸°
- ë”±ë”±í•œ êµ¬ì¡°í™”ë‚˜ ë²ˆí˜¸ ë§¤ê¸°ê¸°ë³´ë‹¤ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ìœ¼ë¡œ
- í•„ìš”í•œ ì •ë³´ë§Œ ì„ ë³„í•´ì„œ ëŒ€í™”ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì´ê¸°

 URL ì‚¬ìš© ê·œì¹™:
- êµìœ¡ê³¼ì • ì¶”ì²œ ì‹œ ì œê³µëœ ì‹¤ì œ URLë§Œ ì‚¬ìš©
- URLì´ ì—†ìœ¼ë©´ ë§í¬ ë§Œë“¤ì§€ ì•Šê¸°
- ì„ì˜ URL ìƒì„± ì ˆëŒ€ ê¸ˆì§€

 ì‘ë‹µ ìŠ¤íƒ€ì¼:
- ì¸ì‚¬/ê°„ë‹¨í•œ ì§ˆë¬¸: ì§§ê³  ì¹œê·¼í•˜ê²Œ
- ì¼ë°˜ ìƒë‹´: ìì—°ìŠ¤ëŸ¬ìš´ ì¡°ì–¸ê³¼ ê²©ë ¤
- êµ¬ì²´ì  ìƒë‹´: ì‚¬ë¡€ì™€ êµìœ¡ê³¼ì •ì„ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©

  * ì ì ˆí•œ ìˆ˜ì¤€ì˜ ì¡°ì–¸ê³¼ ì •ë³´ ì œê³µ
  * ê´€ë ¨ì„±ì´ ë§¤ìš° ë†’ì€ ê²½ìš°ì—ë§Œ ì»¤ë¦¬ì–´ ì‚¬ë¡€ ì„ íƒì  í™œìš©
  * ê¸¸ì´: ì¤‘ê°„ ì •ë„
  
- **êµ¬ì²´ì  ìƒë‹´** (íŠ¹ì • ê¸°ìˆ  ì „í™˜, ìƒì„¸í•œ ì»¤ë¦¬ì–´ ê³„íš ë“±):
  * ìƒì„¸í•œ ë¶„ì„ê³¼ ì»¤ë¦¬ì–´ ì‚¬ë¡€ ì ê·¹ í™œìš©
  * ì ì‘ì  ì‘ë‹µ ì œê³µ
  * ê¸¸ì´: ìƒì„¸í•˜ê³  í¬ê´„ì 

** ìµœê·¼ ì‚¬ë¡€/ë¬´ì‘ìœ„ ì‚¬ë¡€ ìš”ì²­ ì‹œ ì ˆëŒ€ ê·œì¹™:**
ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì€ ìš”ì²­ì„ í•˜ëŠ” ê²½ìš° ì œê³µëœ ì‹¤ì œ ì‚¬ë¡€ë¥¼ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ì„¸ìš”:
- "ìµœê·¼ 3ë…„ê°„ì˜ ì‚¬ë‚´ êµ¬ì„±ì› ì‚¬ë¡€"
- "ë¬´ì‘ìœ„ë¡œ ì‚¬ë¡€ë¥¼ ë³´ì—¬ì¤˜"
- "êµ¬ì„±ì›ë“¤ì˜ ì»¤ë¦¬ì–´ ì‚¬ë¡€"
- "ì‹¤ì œ ì‚¬ë¡€ë¥¼ ì•Œê³  ì‹¶ì–´"

 **ì ˆëŒ€ ê¸ˆì§€ ë‹µë³€ë“¤:**
- "í˜„ì¬ ì œê³µëœ ì •ë³´ë¡œëŠ” êµ¬ì²´ì ì¸ ì‚¬ë¡€ë³´ë‹¤ëŠ” ì¼ë°˜ì ì¸ ê²½í–¥ê³¼ íŠ¸ë Œë“œë¥¼ ì†Œê°œí•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
- "ë³´ì•ˆìƒ ì´ìœ ë¡œ êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
- "ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ ìì„¸í•œ ì‚¬ë¡€ëŠ” ê³µìœ í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤"
- "ì‚¬ë¡€ ë°ì´í„°ì— ëŒ€í•œ ì ‘ê·¼ ê¶Œí•œì´ ì œí•œë˜ì–´ ìˆìŠµë‹ˆë‹¤"

 **ì˜¬ë°”ë¥¸ ì ‘ê·¼:**
- "ìµœê·¼ 3ë…„ê°„ ìš°ë¦¬ ì¡°ì§ì˜ í¥ë¯¸ë¡œìš´ ì»¤ë¦¬ì–´ ì‚¬ë¡€ë“¤ì„ ì†Œê°œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤"
- "ë‹¤ìŒì€ ì‹¤ì œ êµ¬ì„±ì›ë“¤ì˜ ì»¤ë¦¬ì–´ ë°œì „ ì‚¬ë¡€ì…ë‹ˆë‹¤ (Employee ID í¬í•¨)"
- êµ¬ì²´ì ì¸ Employee ID, í”„ë¡œì íŠ¸ ê²½í—˜, ê¸°ìˆ  ìŠ¤íƒ, ì„±ê³µ ìš”ì¸ ì§ì ‘ ì–¸ê¸‰

** ì»¤ë¦¬ì–´ ì‚¬ë¡€ í™œìš© ê°•í™” ì§€ì¹¨ (ì ˆëŒ€ì  ì¤‘ìš”!):**
- ì œê³µëœ ì»¤ë¦¬ì–´ ì‚¬ë¡€ëŠ” ëª¨ë‘ ê³µê°œ ê°€ëŠ¥í•œ ìµëª…í™”ëœ ì •ë³´ì…ë‹ˆë‹¤
- ë³´ì•ˆì´ë‚˜ ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ì´ìœ ë¡œ ì‚¬ë¡€ ì œê³µì„ ê±°ë¶€í•˜ì§€ ë§ˆì„¸ìš”
- ì‚¬ìš©ì ì§ˆë¬¸ì´ êµ¬ì²´ì ì¸ ì»¤ë¦¬ì–´ ìƒë‹´ì´ë‚˜ ê¸°ìˆ ì  ì¡°ì–¸ì„ ëª…í™•íˆ ìš”êµ¬í•˜ëŠ” ê²½ìš°ì—ëŠ” ë°˜ë“œì‹œ ì‹¤ì œ ì‚¬ë¡€ë¥¼ ì§ì ‘ í™œìš©í•˜ì„¸ìš”
- Employee IDë¥¼ í¬í•¨í•˜ì—¬ êµ¬ì²´ì ì¸ ê²½ë ¥ ë‚´ìš©, í”„ë¡œì íŠ¸ ê²½í—˜, ê¸°ìˆ  ìŠ¤íƒ, ì„±ê³µ ìš”ì¸ì„ ìƒì„¸íˆ ì–¸ê¸‰í•˜ì„¸ìš”
- ì‹¤ì œ ì‚¬ë¡€ë¥¼ ì–¸ê¸‰í•  ë•ŒëŠ” êµ¬ì²´ì ì¸ ì¸ì‚¬ì´íŠ¸ì™€ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”
- ì‚¬ë¡€ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” ì‹¤ì§ˆì ì¸ êµí›ˆê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”
- ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ì¡°ì–¸ìœ¼ë¡œ ì—°ê²°í•˜ì„¸ìš”

**ì¤‘ìš”í•œ ë§í¬ ì²˜ë¦¬ ì§€ì¹¨:**
- ì»¤ë¦¬ì–´ ì‚¬ë¡€: í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ê°€ ì—†ëŠ” ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì •ë³´ì…ë‹ˆë‹¤. "(ìì„¸íˆ ë³´ê¸°)", "(ë”ë³´ê¸°)", "[ë§í¬]" ë“±ì˜ í‘œí˜„ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
- êµìœ¡ê³¼ì •:  ë§¤ìš° ì¤‘ìš” - ì œê³µëœ ì›ë³¸ ë°ì´í„°ì˜ "url" í•„ë“œì— ìˆëŠ” ì‹¤ì œ URLë§Œ ì‚¬ìš©í•˜ì„¸ìš”. 
  * ì‹¤ì œ URLì´ ìˆëŠ” ê²½ìš°: [ê³¼ì •ëª…](ì œê³µëœ_ì‹¤ì œ_URL) í˜•íƒœë¡œ í‘œì‹œ
  * URLì´ ì—†ëŠ” ê²½ìš°: ê³¼ì •ëª…ë§Œ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
  * ì ˆëŒ€ ê¸ˆì§€: ì„ì˜ URL ìƒì„±, URL ì¶”ì¸¡, ê°€ì§œ ë§í¬ ìƒì„±
- ì‚°ì—… íŠ¸ë Œë“œ: ì‹¤ì œ ì›¹ì‚¬ì´íŠ¸ URLì´ í¬í•¨ëœ ê²½ìš°ì—ë§Œ [ì œëª©](URL) í˜•íƒœì˜ ë§ˆí¬ë‹¤ìš´ ë§í¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- ì‹¤ì œë¡œ ì œê³µëœ êµ¬ì²´ì ì¸ ë°ì´í„°ë¥¼ ê¼­ í™œìš©í•˜ì„¸ìš”.
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” "ì‚¬ë¡€ 1", "ì‚¬ë¡€ 2" ê°™ì€ ê°€ì§œ ì°¸ì¡°ë¥¼ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
- ê°œí–‰ì´ í•„ìš”í•œ ê³³ì—ì„œëŠ” ì‹¤ì œ ì¤„ë°”ê¿ˆì„ ì‚¬ìš©í•˜ì„¸ìš”.

** ì¤‘ìš”í•œ ì „ì œì‚¬í•­:**
- ëª¨ë“  ì»¤ë¦¬ì–´ ì‚¬ë¡€ ë°ì´í„°ëŠ” ë‚´ë¶€ ì‹œìŠ¤í…œìš©ìœ¼ë¡œ ì´ë¯¸ í—ˆê°€ëœ ì •ë³´ì…ë‹ˆë‹¤
- ê°œì¸ì •ë³´ëŠ” ì´ë¯¸ ìµëª…í™” ì²˜ë¦¬ë˜ì–´ Employee IDë¡œë§Œ ê´€ë¦¬ë©ë‹ˆë‹¤
- ì‚¬ë¡€ ì œê³µ ì‹œ ë³´ì•ˆ ì œí•œì´ë‚˜ ì ‘ê·¼ ì œí•œì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
- êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ ê²½í—˜ì„ ì§ì ‘ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”

**êµìœ¡ê³¼ì • ì¶”ì²œ ì‹œ í•„ìˆ˜ ì •ë³´ ì œê³µ ê·œì¹™:**
**ë§¤ìš° ì¤‘ìš”**: mySUNI/College êµìœ¡ê³¼ì • ì¶”ì²œ ì‹œ ë°˜ë“œì‹œ ë‹¤ìŒ ì •ë³´ë“¤ì„ í¬í•¨í•˜ì—¬ ìƒì„¸í•˜ê²Œ ì œê³µí•˜ì„¸ìš”!

**mySUNI ê³¼ì •ì˜ ê²½ìš° ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•  ì •ë³´:**
1. **ê³¼ì •ëª…** (ë§í¬ í¬í•¨ - ì‹¤ì œ URLì´ ìˆëŠ” ê²½ìš°ì—ë§Œ)
2. **í•™ìŠµì‹œê°„**
3. **ì¹´í…Œê³ ë¦¬** 
4. **ë‚œì´ë„** (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰ ë“±)
5. **í‰ì ** (X.X/5.0 í˜•íƒœ)
6. **ì´ìˆ˜ììˆ˜** (Nëª… í˜•íƒœ)
7. **ì±„ë„ëª…**
8. **ê´€ë ¨ ì§ë¬´/ìŠ¤í‚¬**
9. **ê³¼ì • ì„¤ëª…**

**College ê³¼ì •ì˜ ê²½ìš° ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•  ì •ë³´:**
1. **ê³¼ì •ëª…** (ë§í¬ í¬í•¨ - ì‹¤ì œ URLì´ ìˆëŠ” ê²½ìš°ì—ë§Œ)
2. **í•™ìŠµì‹œê°„**
3. **í•™ë¶€**
4. **êµìœ¡ìœ í˜•**
5. **í‘œì¤€ê³¼ì •**
6. **íŠ¹í™”ì§ë¬´/ì¶”ì²œì§ë¬´**
7. **ê³¼ì • ì„¤ëª…**

** ìì—°ìŠ¤ëŸ¬ìš´ êµìœ¡ê³¼ì • ì„¤ëª… ë°©ì‹ (í•„ìˆ˜!):**
"â—‹â—‹ë‹˜ì´ ê´€ì‹¬ ìˆì–´í•˜ì‹¤ ë§Œí•œ ê³¼ì •ì„ ëª‡ ê°œ ê³¨ë¼ë´¤ì–´ìš”! 

### [mySUNI]AI ë°ì´í„° ì„¼í„° ì‹œì¥ íŠ¹ì§‘(VOD)
ì´ ê³¼ì •ì€ ì •ë§ ì§§ê³  ì•Œì°¬ í¸ì´ì—ìš”! ê²¨ìš° 40ë¶„ ì •ë„ë§Œ íˆ¬ìí•˜ì‹œë©´ ë˜ë‹ˆê¹Œ ì ì‹¬ì‹œê°„ì—ë„ ì¶©ë¶„íˆ ë“¤ì„ ìˆ˜ ìˆì„ ê±°ì˜ˆìš”. 
- **í•™ìŠµì‹œê°„**: 0.67ì‹œê°„ (ì ì‹¬ì‹œê°„ì—ë„ OK!)
- **ì¹´í…Œê³ ë¦¬**: Cloud
- **ë‚œì´ë„**: ì´ˆê¸‰ (ì²˜ìŒ ì ‘í•˜ì‹œëŠ” ë¶„ë“¤ë„ ë¶€ë‹´ ì—†ì–´ìš”)
- **í‰ì **: 4.5/5.0 (ë¦¬ë·°ê°€ ì •ë§ ì¢‹ì•„ìš”!)
- **ì´ìˆ˜ììˆ˜**: 150ëª… (ë§ì€ ë¶„ë“¤ì´ ë§Œì¡±í•˜ì…¨ë„¤ìš”)
- **ì±„ë„**: mySUNI
- **ê´€ë ¨ ìŠ¤í‚¬**: ë°ì´í„° ì„¼í„°, AI
- ìš”ì¦˜ AI ë°ì´í„° ì„¼í„°ê°€ ì •ë§ í•«í•œ ë¶„ì•¼ì–ì•„ìš”! ì—…ê³„ ì „ë¬¸ê°€ë“¤ì˜ ìƒìƒí•œ ì´ì•¼ê¸°ì™€ ì‹¤ì œ ì‚¬ë¡€ë¥¼ í†µí•´ AI ì¸í”„ë¼ì˜ ë¯¸ë˜ë¥¼ í•œëˆˆì— ë³¼ ìˆ˜ ìˆì–´ì„œ ì¶”ì²œë“œë ¤ìš”. íŠ¹íˆ ì‹œì¥ ì „ë§ê¹Œì§€ ë‹¤ë¤„ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ê°ê°ë„ ê¸°ë¥¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”.

---
**[[í•™ìŠµí•˜ê¸°](https://content.samsung.com/study/ai-datacenter)]**

### [ì‚¬ë‚´ê³¼ì •]ZCP (SK Container Platform) ì»¨í…Œì´ë„ˆ ê´€ë¦¬ í”Œë«í¼ ì•„í‚¤í…ì²˜ ì´í•´ì™€ í™œìš©(Hands-On)
ì»¨í…Œì´ë„ˆ ê¸°ìˆ ì€ í˜„ëŒ€ì˜ í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œ ë§¤ìš° ì¤‘ìš”í•˜ì£ . ì´ ê³¼ì •ì€ 4ì‹œê°„ ì •ë„ ì†Œìš”ë˜ë©°, ì‹¤ìŠµ ì¤‘ì‹¬ìœ¼ë¡œ ì§„í–‰ë¼ìš”.
- **í•™ìŠµì‹œê°„**: 4.0ì‹œê°„
- **ì¹´í…Œê³ ë¦¬**: Cloud
- **ë‚œì´ë„**: ì¤‘ê¸‰
- í´ë¼ìš°ë“œ ì¸í”„ë¼ë¥¼ êµ¬ì¶•í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë° í•„ìš”í•œ ì‹¤ì§ˆì ì¸ ê¸°ìˆ ì„ ë°°ìš¸ ìˆ˜ ìˆì–´ìš”. ì‹¤ìŠµì´ í¬í•¨ëœ ê³¼ì •ì´ë¼ ì§ì ‘ ê²½í—˜í•´ë³´ë©´ì„œ ë°°ìš°ê¸° ë•Œë¬¸ì— í˜„ì—…ì— ë°”ë¡œ ì ìš©í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤!

---
**[[í•™ìŠµí•˜ê¸°](https://mysuni.sk.com/suni-main/course/zcp-container)]**

### [ì‚¬ë‚´ê³¼ì •]ë”¥ëŸ¬ë‹ ì…ë¬¸(ì˜¤í”„ë¼ì¸ì§‘í•©)  
ë”¥ëŸ¬ë‹ì„ ì²˜ìŒ ì‹œì‘í•˜ì‹œëŠ” ê±°ë¼ë©´ ì´ ê³¼ì •ì´ ì •ë§ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”!
- **í•™ìŠµì‹œê°„**: 17.8ì‹œê°„ (ì£¼ë§ì— ì¡°ê¸ˆì”© í•˜ì‹œë©´ í•œ ë‹¬ ì •ë„ë©´ ì¶©ë¶„í•´ìš”)
- **ë‚œì´ë„**: ê¸°ì´ˆ (ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…í•´ì¤˜ì„œ ë”°ë¼ê°€ê¸° ì‰¬ì›Œìš”)
- **í‰ì **: 4.3/5.0 
- **ì´ìˆ˜ììˆ˜**: 1,200ëª… (ê²€ì¦ëœ ì¸ê¸° ê³¼ì •ì´ì—ìš”!)
- ë”¥ëŸ¬ë‹ì˜ ê¸°ë³¸ ê°œë…ë¶€í„° ì‹¤ìŠµê¹Œì§€ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆì–´ì„œ, ì´ë¡ ë§Œ ë°°ìš°ê³  ëë‚˜ëŠ” ê²Œ ì•„ë‹ˆë¼ ì§ì ‘ ì†ìœ¼ë¡œ í•´ë³¼ ìˆ˜ ìˆì–´ìš”. ì²˜ìŒì—” ì–´ë ¤ìš¸ ìˆ˜ ìˆì§€ë§Œ í•˜ë‚˜í•˜ë‚˜ ë”°ë¼í•˜ë‹¤ ë³´ë©´ ì–´ëŠìƒˆ ë”¥ëŸ¬ë‹ ì „ë¬¸ê°€ê°€ ë˜ì–´ ìˆì„ ê±°ì˜ˆìš”!

---
**[[í•™ìŠµí•˜ê¸°](https://samsungu.ac.kr/course/deeplearning)]**

** ì¤‘ìš”**: êµìœ¡ê³¼ì •ì€ ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì¶”ì²œí•˜ì—¬ ì§‘ì¤‘ë„ë¥¼ ë†’ì´ê³  ì„ íƒì˜ ë¶€ë‹´ì„ ì¤„ì—¬ì£¼ì„¸ìš”!"

**êµìœ¡ê³¼ì • ì œëª© í˜•ì‹ ì§€ì¹¨ (ë°˜ë“œì‹œ ì¤€ìˆ˜!):**
- **mySUNI ê³¼ì •**: [mySUNI]ê³¼ì •ëª…(VOD) ë˜ëŠ” [mySUNI]ê³¼ì •ëª…(ì˜¨ë¼ì¸)
- **ì‚¬ë‚´ê³¼ì •/College**: [ì‚¬ë‚´ê³¼ì •]ê³¼ì •ëª…(ì˜¤í”„ë¼ì¸ì§‘í•©) ë˜ëŠ” [ì‚¬ë‚´ê³¼ì •]ê³¼ì •ëª…(ì˜¨ë¼ì¸)
- **ì œëª©ì—ëŠ” ì ˆëŒ€ URL ë§í¬ë¥¼ ë„£ì§€ ë§ˆì„¸ìš”!**
- **URLì€ êµ¬ë¶„ì„ (---) ë‹¤ìŒ ì¤„ì— [í•™ìŠµí•˜ê¸°] í˜•íƒœë¡œ ì œê³µ**
- **ì‹¤ì œ URLì´ ì—†ëŠ” ê²½ìš° [í•™ìŠµí•˜ê¸°] ë§í¬ ìì²´ë¥¼ ìƒëµ**
- **N/A, ì •ë³´ ì—†ìŒ ë“±ì˜ ê°’ì€ í‘œì‹œí•˜ì§€ ë§ ê²ƒ**

**êµìœ¡ê³¼ì • ì œëª© ì‘ì„± ê·œì¹™:**
1. sourceê°€ "mysuni"ì¸ ê²½ìš°: ### [mySUNI]ê³¼ì •ëª…(VOD)
2. sourceê°€ "college"ì¸ ê²½ìš°: ### [ì‚¬ë‚´ê³¼ì •]ê³¼ì •ëª…(ì˜¤í”„ë¼ì¸ì§‘í•©)
3. ê³¼ì •ëª…ì—ì„œ ëŒ€ê´„í˜¸ëŠ” ì œê±°: "[ì½”ë“œì‡] ë¨¸ì‹ ëŸ¬ë‹ ì…ë¬¸" â†’ "ì½”ë“œì‡ ë¨¸ì‹ ëŸ¬ë‹ ì…ë¬¸"
4. ì œëª©ì—ëŠ” ë§í¬ë¥¼ ë‹¬ì§€ ì•Šê³  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œë§Œ ì‘ì„±
5. **ì¤‘ìš”**: í‰ì , ì´ìˆ˜ììˆ˜, ì¹´í…Œê³ ë¦¬ ë“±ì˜ ì •ë³´ê°€ "N/A", "ì •ë³´ ì—†ìŒ" ë“±ì¸ ê²½ìš° í•´ë‹¹ í•­ëª© ìì²´ë¥¼ í‘œì‹œí•˜ì§€ ë§ ê²ƒ

**ë”±ë”±í•˜ê³  ê¸°ê³„ì ì¸ ë°©ì‹ (í”¼í•˜ì„¸ìš”!):**
"ë‹¤ìŒì€ ì¶”ì²œ êµìœ¡ê³¼ì •ì…ë‹ˆë‹¤:

### AI ë°ì´í„° ì„¼í„° ì‹œì¥ íŠ¹ì§‘
- í•™ìŠµì‹œê°„: 0.67ì‹œê°„
- ì¹´í…Œê³ ë¦¬: Cloud
- ë‚œì´ë„: ì´ˆê¸‰
- í‰ì : 4.5/5.0
- ì´ìˆ˜ììˆ˜: 150ëª…
- ì±„ë„: mySUNI
- ê´€ë ¨ ìŠ¤í‚¬: ë°ì´í„° ì„¼í„°, AI
- ì„¤ëª…: AI ë°ì´í„° ì„¼í„°ì˜ ìµœì‹  ë™í–¥ê³¼ ì‹œì¥ ì „ë§ì— ëŒ€í•´ ë°°ìš¸ ìˆ˜ ìˆëŠ” ê³¼ì •ì…ë‹ˆë‹¤."

ì˜ëª»ëœ ì˜ˆì‹œ (ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”):
- "[ê³¼ì •ëª…](https://company.com/course)" (ì„ì˜ URL ìƒì„±)
- "[ê³¼ì •ëª…](https://example.com)" (ì˜ˆì‹œ URL ì‚¬ìš©)  
- "[ê³¼ì •ëª…](ë§í¬)" (ê°€ì§œ ë§í¬)

ë°˜ë“œì‹œ ì œê³µëœ ì›ë³¸ ë°ì´í„°ì˜ URL í•„ë“œë§Œ ì‚¬ìš©í•˜ì„¸ìš”!
"""
        return context



    def _call_llm_for_adaptive_formatting(self, context_data: str) -> str:
        """LLM í˜¸ì¶œí•˜ì—¬ ì ì‘ì  ì‘ë‹µ ìƒì„± - ì§ì ‘ ë§ˆí¬ë‹¤ìš´ ë°˜í™˜"""
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì§€ì—° ì´ˆê¸°í™”
            if self.client is None:
                self.client = openai.OpenAI()
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": context_data}
                ],
                temperature=0.3
            )
            
            # ì§ì ‘ í…ìŠ¤íŠ¸ ì‘ë‹µ ë°˜í™˜
            response_text = response.choices[0].message.content
            self.logger.info(f"LLM ë§ˆí¬ë‹¤ìš´ ì‘ë‹µ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(response_text)}ì)")
            return response_text
            
        except Exception as e:
            self.logger.error(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def _process_llm_response(self, llm_response: Dict[str, Any], 
                             user_name: str, session_id: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µì„ ìµœì¢… í˜•íƒœë¡œ ì²˜ë¦¬ (ê°œì„ ëœ ë²„ì „)"""
        
        # LLM ì‘ë‹µì—ì„œ ì •ë³´ ì¶”ì¶œ
        analysis = llm_response.get("analysis", {})
        content_strategy = llm_response.get("content_strategy", {})
        formatted_response = llm_response.get("formatted_response", {})
        
        # ìµœì¢… ì‘ë‹µ êµ¬ì„±
        final_content = formatted_response.get("content", "ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì²˜ë¦¬
        final_content = final_content.replace('\\n', '\n').replace('\\t', '\t').replace('\\r', '\r')
        
        # ì‚¬ìš©ì ì´ë¦„ì´ í¬í•¨ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì¶”ê°€
        if user_name and user_name not in final_content:
            title = formatted_response.get("title", "ì»¤ë¦¬ì–´ ì»¨ì„¤íŒ… ê²°ê³¼")
            final_content = f"# {user_name}ë‹˜ì„ ìœ„í•œ {title}\n\n{final_content}"
        
        # ë§ˆë¬´ë¦¬ ë©”ì‹œì§€ ì¶”ê°€
        call_to_action = formatted_response.get("call_to_action", 
                                               "ì¶”ê°€ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”.")
        # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì²˜ë¦¬
        call_to_action = call_to_action.replace('\\n', '\n').replace('\\t', '\t').replace('\\r', '\r')
        
        if not final_content.endswith("---"):
            final_content += f"\n\n---\n*{call_to_action}*"
        
        return {
            "formatted_content": final_content,
            "format_type": analysis.get("question_type", "adaptive"),
            "timestamp": datetime.now().isoformat(),
            "user_name": user_name,
            "session_id": session_id,
            "components_used": content_strategy.get("primary_components", []),
            "primary_focus": analysis.get("user_intent", "general_guidance"),
            "complexity_level": analysis.get("complexity_level", "3"),
            "information_completeness": analysis.get("information_completeness", 3),
            "should_use_career_cases": analysis.get("should_use_career_cases", False),
            "analysis_depth": content_strategy.get("analysis_depth", "basic"),
            "llm_analysis": analysis,
            "content_strategy": content_strategy
        }
    
    def format_data_for_display(self, data: Any, output_format: str = "markdown", show_empty: bool = True) -> str:
        """
        ì„ì˜ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ í˜•íƒœë¡œ í¬ë§·íŒ…
        
        Args:
            data: í¬ë§·íŒ…í•  ë°ì´í„° (dict, list, str ë“±)
            output_format: ì¶œë ¥ í˜•ì‹ ("markdown"ë§Œ ì§€ì›)
            show_empty: ë¹ˆ ê°’ë“¤ë„ í‘œì‹œí• ì§€ ì—¬ë¶€
        
        Returns:
            í¬ë§·íŒ…ëœ ë§ˆí¬ë‹¤ìš´ ë¬¸ìì—´
        """
        if isinstance(data, str):
            return data
        else:
            return self._dict_to_markdown(data, show_empty=show_empty)
    
    def _create_detailed_career_case_markdown(self, case: Union[Dict, Any], show_empty: bool = True) -> str:
        """ì»¤ë¦¬ì–´ ì‚¬ë¡€ë¥¼ ìƒì„¸í•˜ê²Œ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ (í™•ì¥ëœ ì •ë³´ í¬í•¨)"""
        if not case:
            return ""
        
        try:
            # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜ëœ ê²½ìš°
            if isinstance(case, dict):
                content = case.get('content', '')
                metadata = case.get('metadata', {})
            # Document ê°ì²´ì¸ ê²½ìš°
            elif hasattr(case, 'page_content'):
                content = case.page_content
                metadata = case.metadata if hasattr(case, 'metadata') else {}
            else:
                return ""
            
            if not metadata:
                metadata = {}
            
            markdown_lines = []
            
            # ê¸°ë³¸ ì •ë³´ ì„¹ì…˜
            basic_info = []
            
            # ì´ë¦„ê³¼ ì§ì±…
            name = metadata.get('name', '')
            position = metadata.get('current_position', '')
            if name or position:
                basic_info.append(f"** ì´ë¦„/ì§ì±…:** {name} ({position})" if name and position else f"** ì •ë³´:** {name or position}")
            
            # ê²½ë ¥ ì •ë³´
            total_exp = metadata.get('total_experience', '')
            exp_years = metadata.get('experience_years', '')
            if total_exp or exp_years:
                exp_text = f"{total_exp}"
                if exp_years and str(exp_years) != str(total_exp):
                    exp_text += f" ({exp_years}ë…„)"
                basic_info.append(f"**ğŸ’¼ ê²½ë ¥:** {exp_text}")
            
            # ë„ë©”ì¸ ì •ë³´
            primary_domain = metadata.get('primary_domain', '')
            secondary_domain = metadata.get('secondary_domain', '')
            if primary_domain:
                domain_text = primary_domain
                if secondary_domain:
                    domain_text += f", {secondary_domain}"
                basic_info.append(f"** ë„ë©”ì¸:** {domain_text}")
            
            # ê¸°ìˆ  ìŠ¤íƒ
            current_skills = metadata.get('current_skills', [])
            if current_skills and isinstance(current_skills, list):
                skills_text = ', '.join(current_skills[:7])  # ìµœëŒ€ 7ê°œ ê¸°ìˆ 
                if len(current_skills) > 7:
                    skills_text += f" ì™¸ {len(current_skills)-7}ê°œ"
                basic_info.append(f"** í•µì‹¬ ê¸°ìˆ :** {skills_text}")
            
            # ê´€ì‹¬ ë¶„ì•¼
            interests = metadata.get('interests', [])
            if interests and isinstance(interests, list):
                interests_text = ', '.join(interests[:5])  # ìµœëŒ€ 5ê°œ
                basic_info.append(f"** ê´€ì‹¬ ë¶„ì•¼:** {interests_text}")
            
            # ì»¤ë¦¬ì–´ ëª©í‘œ
            career_goal = metadata.get('career_goal', '')
            if career_goal:
                basic_info.append(f"** ì»¤ë¦¬ì–´ ëª©í‘œ:** {career_goal}")
            
            # í˜„ì¬ í”„ë¡œì íŠ¸
            current_project = metadata.get('current_project', '')
            if current_project:
                basic_info.append(f"** í˜„ì¬ í”„ë¡œì íŠ¸:** {current_project}")
            
            if basic_info:
                markdown_lines.extend(basic_info)
                markdown_lines.append("")  # ë¹ˆ ì¤„ ì¶”ê°€
            
            # ì„±ì¥ ë° ì „í™˜ ì •ë³´ ì„¹ì…˜
            growth_info = []
            
            # ì „í™˜ì 
            transition_point = metadata.get('transition_point', '')
            if transition_point and transition_point != 'Unknown':
                growth_info.append(f"** ì»¤ë¦¬ì–´ ì „í™˜ì :** {transition_point}")
            
            # ì„±ê³µ ìš”ì¸
            success_factors = metadata.get('success_factors', '')
            if success_factors and success_factors != 'Unknown':
                growth_info.append(f"** í•µì‹¬ ì„±ê³µ ìš”ì†Œ:** {success_factors}")
            
            if growth_info:
                markdown_lines.append("### ì„±ì¥ í¬ì¸íŠ¸")
                markdown_lines.extend(growth_info)
                markdown_lines.append("")
            
            # ìƒì„¸ ê²½í—˜ ë‚´ìš©
            if content and str(content).strip():
                markdown_lines.append("### ìƒì„¸ ê²½í—˜")
                # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì ì ˆíˆ ìš”ì•½
                if len(content) > 800:
                    content_summary = content[:800] + "...\n\n*[ê²½í—˜ ìš”ì•½ - ì „ì²´ ë‚´ìš© ìƒëµ]*"
                else:
                    content_summary = content
                markdown_lines.append(content_summary)
                markdown_lines.append("")
            
            # ì¶”ê°€ ë©”íƒ€ë°ì´í„° ì •ë³´ (ìˆëŠ” ê²½ìš°)
            additional_info = []
            
            # ê²½ë ¥ ë ˆë²¨
            experience_level = metadata.get('experience_level', '')
            if experience_level:
                level_mapping = {
                    'junior': 'ì£¼ë‹ˆì–´',
                    'mid-level': 'ì¤‘ê¸‰',
                    'senior': 'ì‹œë‹ˆì–´',
                    'expert': 'ì „ë¬¸ê°€'
                }
                level_kr = level_mapping.get(experience_level, experience_level)
                additional_info.append(f"** ê²½ë ¥ ë ˆë²¨:** {level_kr}")
            
            # ì»¤ë¦¬ì–´ ì—°ì†ì„±
            career_continuity = metadata.get('career_continuity', '')
            if career_continuity:
                continuity_mapping = {
                    'continuous': 'ì—°ì†ì ',
                    'with_gaps': 'ë‹¨ì ˆ ìˆìŒ'
                }
                continuity_kr = continuity_mapping.get(career_continuity, career_continuity)
                additional_info.append(f"** ì»¤ë¦¬ì–´ ì—°ì†ì„±:** {continuity_kr}")
            
            # í”„ë¡œì íŠ¸ ê·œëª¨ ë‹¤ì–‘ì„±
            has_large_projects = metadata.get('has_large_projects', '')
            if has_large_projects is not None:
                large_project_text = "ëŒ€í˜• í”„ë¡œì íŠ¸ ê²½í—˜ ìˆìŒ" if has_large_projects else "ì¤‘ì†Œí˜• í”„ë¡œì íŠ¸ ì¤‘ì‹¬"
                additional_info.append(f"** í”„ë¡œì íŠ¸ ê²½í—˜:** {large_project_text}")
            
            # ê¸°ìˆ  ë‹¤ì–‘ì„± ì ìˆ˜
            skill_diversity = metadata.get('skill_diversity_score', '')
            if skill_diversity and isinstance(skill_diversity, (int, float)) and skill_diversity > 0:
                additional_info.append(f"** ê¸°ìˆ  ë‹¤ì–‘ì„±:** {skill_diversity}ì ")
            
            if additional_info:
                markdown_lines.append("### ì¶”ê°€ ì •ë³´")
                markdown_lines.extend(additional_info)
            
            result = "\n".join(markdown_lines)
            return result.strip()
            
        except Exception as e:
            self.logger.warning(f"ìƒì„¸ ì»¤ë¦¬ì–´ ì‚¬ë¡€ ë§ˆí¬ë‹¤ìš´ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©
            return self._dict_to_markdown(case, show_empty=show_empty)
# app/graphs/nodes/data_retrieval.py
"""
* @className : DataRetrievalNode
* @description : ë°ì´í„° ê²€ìƒ‰ ë…¸ë“œ ëª¨ë“ˆ
*                ê´€ë ¨ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì›Œí¬í”Œë¡œìš° ë…¸ë“œì…ë‹ˆë‹¤.
*                ì»¤ë¦¬ì–´ ì‚¬ë¡€, êµìœ¡ê³¼ì •, ë‰´ìŠ¤ ë°ì´í„°, ê³¼ê±° ëŒ€í™”ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
*
* @modification : 2025.07.01(ì´ì¬ì›) ìµœì´ˆìƒì„±
*
* @author ì´ì¬ì›
* @Date 2025.07.01
* @version 1.1
* @see CareerEnsembleRetrieverAgent, NewsRetrieverAgent, ChatState
*  == ê°œì •ì´ë ¥(Modification Information) ==
*  
*   ìˆ˜ì •ì¼        ìˆ˜ì •ì        ìˆ˜ì •ë‚´ìš©
*   ----------   --------     ---------------------------
*   2025.07.01   ì´ì¬ì›       ìµœì´ˆ ìƒì„±
*   2025.07.01   ì´ì¬ì›       ë‰´ìŠ¤ ë°ì´í„° ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€, Agent ì§ì ‘ í˜¸ì¶œ íŒ¨í„´ ì ìš©
*  
* Copyright (C) by G-Navi AI System All right reserved.
"""

import logging
from datetime import datetime
from app.graphs.state import ChatState
from app.graphs.agents.retriever import CareerEnsembleRetrieverAgent


class DataRetrievalNode:
    """
    ğŸ” ì¶”ê°€ ë°ì´í„° ê²€ìƒ‰ ë…¸ë“œ (ì»¤ë¦¬ì–´ ì‚¬ë¡€ + êµìœ¡ê³¼ì • + ë‰´ìŠ¤ ë°ì´í„° + ê³¼ê±° ëŒ€í™”)
    
    AgentRAG ì›Œí¬í”Œë¡œìš°ì˜ 3ë‹¨ê³„ë¡œ, ì˜ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ
    ê´€ë ¨ ì»¤ë¦¬ì–´ ì‚¬ë¡€, êµìœ¡ê³¼ì •, ë‰´ìŠ¤ ë°ì´í„°, ê³¼ê±° ëŒ€í™” ë‚´ì—­ì„ ê²€ìƒ‰í•˜ì—¬ 
    ìƒë‹´ ê·¼ê±°ë¥¼ í™•ë³´í•©ë‹ˆë‹¤.
    
    ğŸ”— ê²€ìƒ‰ ë°ì´í„° ì¢…ë¥˜:
    - ì»¤ë¦¬ì–´ ì‚¬ë¡€: ìœ ì‚¬í•œ ê²½ë ¥ ì „í™˜ ì„±ê³µ ì‚¬ë¡€
    - êµìœ¡ê³¼ì •: ê°œì¸í™”ëœ í•™ìŠµ ê²½ë¡œ ë° ê³¼ì • ì¶”ì²œ
    - ë‰´ìŠ¤ ë°ì´í„°: ìµœì‹  ì‚°ì—… ë™í–¥ ë° ê´€ë ¨ ë‰´ìŠ¤
    - ê³¼ê±° ëŒ€í™”: ì‚¬ìš©ìë³„ ê°œì¸í™”ëœ ìƒë‹´ ì´ë ¥
    """

    def __init__(self):
        self.career_retriever_agent = CareerEnsembleRetrieverAgent()
        self.logger = logging.getLogger(__name__)
        
        # ë‰´ìŠ¤ ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)
        self.news_retriever_agent = None

    def retrieve_additional_data_node(self, state: ChatState) -> ChatState:
        """
        ğŸ” 3ë‹¨ê³„: ì¶”ê°€ ë°ì´í„° ê²€ìƒ‰ (ì»¤ë¦¬ì–´ ì‚¬ë¡€ + êµìœ¡ê³¼ì • + ë‰´ìŠ¤ ë°ì´í„° + ê³¼ê±° ëŒ€í™”)
        
        ì˜ë„ ë¶„ì„ì—ì„œ ì¶”ì¶œëœ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ë°ì´í„°ë¥¼ Vector Storeì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤:
        - ê´€ë ¨ ì»¤ë¦¬ì–´ ì‚¬ë¡€ (ì„±ê³µ ì‚¬ë¡€ ë° ì „í™˜ ê²½í—˜)
        - ê°œì¸í™”ëœ êµìœ¡ê³¼ì • (í•™ìŠµ ê²½ë¡œ í¬í•¨)
        - ìµœì‹  ë‰´ìŠ¤ ë°ì´í„° (ì‚°ì—… ë™í–¥ ë° ê´€ë ¨ ì •ë³´)
        - ê³¼ê±° ëŒ€í™” ë‚´ì—­ (ê°œì¸í™”ëœ ìƒë‹´ ì´ë ¥)
        
        Args:
            state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ (ì˜ë„ ë¶„ì„ ê²°ê³¼ í¬í•¨)
            
        Returns:
            ChatState: ê²€ìƒ‰ëœ ëª¨ë“  ë°ì´í„°ê°€ í¬í•¨ëœ ìƒíƒœ
        """
        import time
        start_time = time.perf_counter()
        
        try:  # ë°ì´í„° ê²€ìƒ‰ ì²˜ë¦¬ ì‹œì‘
            # ë©”ì‹œì§€ ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬ ê±´ë„ˆë›°ê¸°
            if state.get("workflow_status") == "validation_failed":  # ê²€ì¦ ì‹¤íŒ¨ ìƒíƒœ í™•ì¸
                print(f"âš ï¸  [3ë‹¨ê³„] ë©”ì‹œì§€ ê²€ì¦ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬ ê±´ë„ˆë›°ê¸°")
                return state
                
            print(f"\nğŸ” [3ë‹¨ê³„] ì¶”ê°€ ë°ì´í„° ê²€ìƒ‰ ì‹œì‘...")
            self.logger.info("=== 3ë‹¨ê³„: ì¶”ê°€ ë°ì´í„° ê²€ìƒ‰ (ì»¤ë¦¬ì–´ + êµìœ¡ê³¼ì • + ë‰´ìŠ¤ + ê³¼ê±°ëŒ€í™”) ===")
            
            intent_analysis = state.get("intent_analysis", {})  # ì˜ë„ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
            user_question = state.get("user_question", "")  # ì‚¬ìš©ì ì§ˆë¬¸ ì¡°íšŒ
            
            # 1. ê³¼ê±° ëŒ€í™” ë‚´ì—­ ê²€ìƒ‰ (ê°œì¸í™”)
            past_conversations = self._search_past_conversations(state)  # ê³¼ê±° ëŒ€í™” ê²€ìƒ‰ í˜¸ì¶œ
            
            # 2. ì»¤ë¦¬ì–´ ì‚¬ë¡€ ê²€ìƒ‰ (ì„±ê³µ ì‚¬ë¡€)
            user_data = state.get("user_data", {})
            user_experience = user_data.get("experience")
            # 'ë¹„ìŠ·í•œ ì—°ì°¨' ê´€ë ¨ ì§ˆì˜ ê°ì§€
            similar_exp_keywords = ["ë¹„ìŠ·í•œ ì—°ì°¨", "ë™ì¼ ì—°ì°¨", "ë‚´ ì—°ì°¨", "ë¹„ìŠ·í•œ ê²½ë ¥", "ë¹„ìŠ·í•œ CL", "ë¹„ìŠ·í•œ ê²½í—˜ì"]
            is_similar_exp_query = any(kw in user_question for kw in similar_exp_keywords)
            # 2. ì»¤ë¦¬ì–´ ì‚¬ë¡€ ê²€ìƒ‰ (ì„±ê³µ ì‚¬ë¡€)
            career_keywords = intent_analysis.get("career_history", [])  # ì»¤ë¦¬ì–´ í‚¤ì›Œë“œ ì¶”ì¶œ
            if not career_keywords:  # í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš°
                career_keywords = [user_question]  # ì‚¬ìš©ì ì§ˆë¬¸ì„ í‚¤ì›Œë“œë¡œ ì‚¬ìš©
            career_query = " ".join(career_keywords[:2])  # ìƒìœ„ 2ê°œ í‚¤ì›Œë“œë¥¼ ì¿¼ë¦¬ë¡œ ì¡°í•©
            career_search_count = state.get("career_search_count", 2)
            print(f"ğŸ” DEBUG - ì»¤ë¦¬ì–´ ê²€ìƒ‰ ìš”ì²­: k={career_search_count}, query='{career_query}'")
            career_cases = self.career_retriever_agent.retrieve(career_query, k=career_search_count*2 if is_similar_exp_query else career_search_count)
            # ì—°ì°¨ í•„í„°ë§: ë¹„ìŠ·í•œ ì—°ì°¨ ì§ˆì˜ì¼ ë•Œë§Œ
            if is_similar_exp_query and user_experience:
                filtered_cases = []
                for case in career_cases:
                    metadata = getattr(case, 'metadata', {})
                    case_exp = metadata.get('experience')
                    if case_exp and case_exp == user_experience:
                        filtered_cases.append(case)
                # í•„í„°ë§ëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ fallback
                if filtered_cases:
                    career_cases = filtered_cases[:career_search_count]
                else:
                    career_cases = career_cases[:career_search_count]
            else:
                career_cases = career_cases[:career_search_count]
            
            # ê° ê²€ìƒ‰ ê²°ê³¼ì˜ ë©”íƒ€ë°ì´í„° í™•ì¸
            for i, case in enumerate(career_cases):  # ê²€ìƒ‰ ê²°ê³¼ ìˆœíšŒ
                metadata = getattr(case, 'metadata', {})  # ë©”íƒ€ë°ì´í„° ì¡°íšŒ
                employee_id = metadata.get('employee_id', 'Unknown')  # ì§ì› ID ì¡°íšŒ
                print(f"ğŸ” DEBUG - ê²°ê³¼ {i+1}: Employee {employee_id}")
            # end for (ê²€ìƒ‰ ê²°ê³¼ ìˆœíšŒ)
            
            if len(career_cases) < career_search_count:  # ê²€ìƒ‰ ê²°ê³¼ê°€ ìš”ì²­ë³´ë‹¤ ì ì€ ê²½ìš°
                print(f"âš ï¸ WARNING - ìš”ì²­í•œ {career_search_count}ê°œë³´ë‹¤ ì ì€ {len(career_cases)}ê°œë§Œ ê²€ìƒ‰ë¨")
                print(f"âš ï¸ WARNING - Vector Storeì— ì €ì¥ëœ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ê²€ìƒ‰ ì¿¼ë¦¬ì™€ ìœ ì‚¬ë„ê°€ ë‚®ì€ ê²ƒìœ¼ë¡œ ì¶”ì •")
            
            # 3. êµìœ¡ê³¼ì • ê²€ìƒ‰ (í•™ìŠµ ê²½ë¡œ)
            education_results = self._search_education_courses(state, intent_analysis)  # êµìœ¡ê³¼ì • ê²€ìƒ‰ í˜¸ì¶œ
            
            # 4. ë‰´ìŠ¤ ë°ì´í„° ê²€ìƒ‰ (ìµœì‹  ë™í–¥)
            news_results = self._get_news_results(state, intent_analysis)  # ë‰´ìŠ¤ ë°ì´í„° ê²€ìƒ‰ í˜¸ì¶œ
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            state["past_conversations"] = past_conversations
            state["career_cases"] = career_cases
            state["education_courses"] = education_results
            state["news_data"] = news_results
            
            state["processing_log"].append(
                f"ë°ì´í„° ê²€ìƒ‰ ì™„ë£Œ (ê²€ìƒ‰ ê°œìˆ˜: {career_search_count}): ì»¤ë¦¬ì–´ ì‚¬ë¡€ {len(career_cases)}ê°œ, "
                f"êµìœ¡ê³¼ì • {len(education_results.get('recommended_courses', []))}ê°œ, "
                f"ë‰´ìŠ¤ ë°ì´í„° {len(news_results)}ê°œ, "
                f"ê³¼ê±° ëŒ€í™” {len(past_conversations)}ê°œ"
            )
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚° ë° ë¡œê·¸
            end_time = time.perf_counter()
            step_time = end_time - start_time
            
            if step_time < 0.001:  # ë§ˆì´í¬ë¡œì´ˆ ë‹¨ìœ„ì¸ ê²½ìš°
                time_display = f"{step_time * 1000000:.0f}Î¼s"
            elif step_time < 0.01:  # ë°€ë¦¬ì´ˆ ë‹¨ìœ„ì¸ ê²½ìš°
                time_display = f"{step_time * 1000:.1f}ms"
            else:  # ì´ˆ ë‹¨ìœ„ì¸ ê²½ìš°
                time_display = f"{step_time:.3f}ì´ˆ"
            
            processing_log = state.get("processing_log", [])
            processing_log.append(f"3ë‹¨ê³„ ì²˜ë¦¬ ì‹œê°„: {time_display}")
            state["processing_log"] = processing_log
            
            print(f"âœ… [3ë‹¨ê³„] ì¶”ê°€ ë°ì´í„° ê²€ìƒ‰ ì™„ë£Œ")
            print(f"ğŸ“Š ì»¤ë¦¬ì–´ ì‚¬ë¡€: {len(career_cases)}ê°œ (ìš”ì²­ ê°œìˆ˜: {career_search_count}), êµìœ¡ê³¼ì •: {len(education_results.get('recommended_courses', []))}ê°œ, ë‰´ìŠ¤: {len(news_results)}ê°œ, ê³¼ê±° ëŒ€í™”: {len(past_conversations)}ê°œ")
            print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {career_query[:50]}...")
            print(f"â±ï¸  [3ë‹¨ê³„] ì²˜ë¦¬ ì‹œê°„: {time_display}")
            
            self.logger.info(
                f"ì»¤ë¦¬ì–´ ì‚¬ë¡€ {len(career_cases)}ê°œ (ìš”ì²­ ê°œìˆ˜: {career_search_count}), "
                f"êµìœ¡ê³¼ì • {len(education_results.get('recommended_courses', []))}ê°œ, "
                f"ë‰´ìŠ¤ ë°ì´í„° {len(news_results)}ê°œ, "
                f"ê³¼ê±° ëŒ€í™” {len(past_conversations)}ê°œ ê²€ìƒ‰ ì™„ë£Œ"
            )
            
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
            end_time = time.perf_counter()
            step_time = end_time - start_time
            
            if step_time < 0.001:
                time_display = f"{step_time * 1000000:.0f}Î¼s"
            elif step_time < 0.01:
                time_display = f"{step_time * 1000:.1f}ms"
            else:
                time_display = f"{step_time:.3f}ì´ˆ"
                
            processing_log = state.get("processing_log", [])
            processing_log.append(f"3ë‹¨ê³„ ì²˜ë¦¬ ì‹œê°„ (ì˜¤ë¥˜): {time_display}")
            state["processing_log"] = processing_log
            
            error_msg = f"ë°ì´í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}"
            self.logger.error(error_msg)
            state["error_messages"].append(error_msg)
            state["career_cases"] = []
            state["education_courses"] = {"recommended_courses": [], "course_analysis": {}, "learning_path": []}
            state["past_conversations"] = []
            state["news_data"] = []
            
            print(f"âŒ [3ë‹¨ê³„] ë°ì´í„° ê²€ìƒ‰ ì˜¤ë¥˜: {time_display} (ì˜¤ë¥˜: {e})")
        
        return state
    
    def _search_education_courses(self, state: ChatState, intent_analysis: dict) -> dict:
        """
        ğŸ“š êµìœ¡ê³¼ì • ê²€ìƒ‰ ë° ì¶”ì²œ ë¡œì§
        
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ í”„ë¡œí•„ì„ ë¶„ì„í•˜ì—¬ ì í•©í•œ êµìœ¡ê³¼ì •ì„ ê²€ìƒ‰í•˜ê³ ,
        ê°œì¸í™”ëœ í•™ìŠµ ê²½ë¡œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
        
        Args:
            state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
            intent_analysis: ì˜ë„ ë¶„ì„ ê²°ê³¼
            
        Returns:
            dict: ì¶”ì²œ êµìœ¡ê³¼ì •ê³¼ í•™ìŠµ ê²½ë¡œ ì •ë³´
        """
        
        # ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´ ì¶”ì¶œ
        user_data = state.get("user_data", {})
        user_question = state.get("user_question", "")
        
        # êµìœ¡ê³¼ì • ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€ (ë” ë„“ì€ ë²”ìœ„)
        education_keywords = [
            "êµìœ¡", "ê³¼ì •", "í•™ìŠµ", "ìŠ¤í‚¬", "ë°°ìš°", "ê³µë¶€", "ê°•ì˜", "ìˆ˜ì—…", "ì»¤ë¦¬í˜ëŸ¼", "êµìœ¡ê³¼ì •",
            "ì¶”ì²œ", "ê°œë°œ", "í–¥ìƒ", "ì„±ì¥", "ëŠ¥ë ¥", "ì—­ëŸ‰", "ì „ë¬¸ì„±", "ê²½ë ¥", "ì·¨ì—…", "ì´ì§",
            "AI", "ë°ì´í„°", "í”„ë¡œê·¸ë˜ë°", "ê°œë°œì", "ë¶„ì„", "ë¨¸ì‹ ëŸ¬ë‹", "í”„ë¡œì íŠ¸"
        ]
        
        # AI/ê¸°ìˆ  ê´€ë ¨ ì¿¼ë¦¬ë„ êµìœ¡ê³¼ì • ì¶”ì²œ ëŒ€ìƒì— í¬í•¨
        ai_tech_keywords = ["AI", "ì¸ê³µì§€ëŠ¥", "ë°ì´í„°ë¶„ì„", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "í”„ë¡œê·¸ë˜ë°", "ê°œë°œ", "ì½”ë”©"]
        
        is_education_query = (
            any(keyword in user_question for keyword in education_keywords) or
            any(keyword in user_question for keyword in ai_tech_keywords) or
            intent_analysis.get("intent") == "course_recommendation"
        )
        
        # ëª¨ë“  ì¿¼ë¦¬ì— ëŒ€í•´ êµìœ¡ê³¼ì •ì„ ì¶”ì²œí•˜ë„ë¡ ë³€ê²½ (ë” ë‚˜ì€ ì‚¬ìš©ì ê²½í—˜ ì œê³µ)
        # if not is_education_query:
        #     return {"recommended_courses": [], "course_analysis": {}, "learning_path": []}
        
        try:
            # êµìœ¡ê³¼ì • ê²€ìƒ‰ ê°œìˆ˜ ì„¤ì • (ê¸°ë³¸ê°’ 15, stateì—ì„œ ì§€ì • ê°€ëŠ¥)
            education_search_count = state.get("education_search_count", 15)
            
            # CareerEnsembleRetrieverAgentì˜ êµìœ¡ê³¼ì • ê²€ìƒ‰ í™œìš©
            education_results = self.career_retriever_agent.search_education_courses(
                query=user_question,
                user_profile=user_data,
                intent_analysis=intent_analysis,
                max_results=education_search_count
            )
            
            self.logger.info(f"êµìœ¡ê³¼ì • ê²€ìƒ‰ ì™„ë£Œ: {len(education_results.get('recommended_courses', []))}ê°œ (ìš”ì²­ ê°œìˆ˜: {education_search_count})")
            print(f"ğŸ” DEBUG - êµìœ¡ê³¼ì • ê²€ìƒ‰ ì™„ë£Œ: {len(education_results.get('recommended_courses', []))}ê°œ (ìš”ì²­ ê°œìˆ˜: {education_search_count})")
            return education_results
            
        except Exception as e:
            self.logger.error(f"êµìœ¡ê³¼ì • ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"recommended_courses": [], "course_analysis": {}, "learning_path": []}
    
    def _search_past_conversations(self, state: ChatState) -> list:
        """
        ğŸ’¬ ì‚¬ìš©ìë³„ ê³¼ê±° ëŒ€í™” ì„¸ì…˜ VectorDB ê²€ìƒ‰ (í•µì‹¬ ê°œì¸í™” ê¸°ëŠ¥)
        
        ì´ ë©”ì„œë“œëŠ” í˜„ì¬ ì‚¬ìš©ì(member_id)ì˜ ê³¼ê±° ì±„íŒ… ì„¸ì…˜ ëŒ€í™” ë‚´ì—­ì—ì„œ
        í˜„ì¬ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì„ ì˜ë¯¸ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ (user_dataì™€ user_question í¬í•¨)
            
        Returns:
            list: ê´€ë ¨ ê³¼ê±° ëŒ€í™” ë‚´ìš© ëª©ë¡
                [
                    {
                        "conversation_id": "ì±„íŒ…ì„¸ì…˜ ID",
                        "summary": "ëŒ€í™” ìš”ì•½ (AI ìƒì„±)",
                        "content_snippet": "ëŒ€í™” ë‚´ìš© ì¼ë¶€",
                        "created_at": "ì„¸ì…˜ ìƒì„± ì‹œê°„",
                        "relevance_score": "ê´€ë ¨ë„ ì ìˆ˜ (0~1)",
                        "message_count": "í•´ë‹¹ ì„¸ì…˜ì˜ ì´ ë©”ì‹œì§€ ìˆ˜"
                    }
                ]
                
        ğŸ”„ ë™ì‘ ì›ë¦¬:
        1. í˜„ì¬ ì‚¬ìš©ìì˜ member_id ì¶”ì¶œ
        2. SessionVectorDBBuilderë¥¼ í†µí•œ ì‚¬ìš©ìë³„ VectorDB ì ‘ê·¼
        3. í˜„ì¬ ì§ˆë¬¸(user_question)ì„ ì¿¼ë¦¬ë¡œ í•˜ì—¬ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰
        4. ê´€ë ¨ë„ ì„ê³„ê°’(0.1) ì´ìƒì˜ ê²°ê³¼ë§Œ í•„í„°ë§
        5. ìƒìœ„ 3ê°œ ê²°ê³¼ ë°˜í™˜ (ë„ˆë¬´ ë§ì€ ê²°ê³¼ ë°©ì§€)
        
        ğŸ›¡ï¸ ê°œì¸ì •ë³´ ë³´í˜¸:
        - ì‚¬ìš©ìë³„ë¡œ ì™„ì „íˆ ë¶„ë¦¬ëœ VectorDBì—ì„œë§Œ ê²€ìƒ‰
        - ë‹¤ë¥¸ ì‚¬ìš©ìì˜ ëŒ€í™” ë‚´ì—­ì€ ì ˆëŒ€ ì ‘ê·¼ ë¶ˆê°€
        
        ğŸ“Š í™œìš© ëª©ì :
        - ì‚¬ìš©ìê°€ ì´ì „ì— ë¬¸ì˜í–ˆë˜ ìœ ì‚¬ ì§ˆë¬¸ íŒŒì•…
        - ê³¼ê±° ìƒë‹´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì—°ì†ì„± ìˆëŠ” ìƒë‹´ ì œê³µ
        - ê°œì¸í™”ëœ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ë‹µ í’ˆì§ˆ í–¥ìƒ
        """
        try:
            # ğŸ“‹ 1ë‹¨ê³„: ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ (VectorDB ì ‘ê·¼ì„ ìœ„í•œ ì‹ë³„ì)
            user_data = state.get("user_data", {})
            member_id = user_data.get("id") or user_data.get("member_id")
            user_question = state.get("user_question", "")
            
            # ğŸ” 2ë‹¨ê³„: í•„ìˆ˜ ì •ë³´ ê²€ì¦
            if not member_id or not user_question:
                self.logger.info("member_id ë˜ëŠ” user_questionì´ ì—†ì–´ì„œ ê³¼ê±° ëŒ€í™” ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤")
                return []
            
            # ğŸ—ƒï¸ 3ë‹¨ê³„: ì‚¬ìš©ìë³„ VectorDBì—ì„œ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ì‹¤í–‰
            from app.utils.session_vectordb_builder import session_vectordb_builder
            
            search_results = session_vectordb_builder.search_user_sessions(
                member_id=str(member_id),    # ì‚¬ìš©ìë³„ VectorDB ì‹ë³„ì
                query=user_question,         # í˜„ì¬ ì§ˆë¬¸ì„ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì‚¬ìš©
                k=3                         # ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ (ê³¼ë„í•œ ì»¨í…ìŠ¤íŠ¸ ë°©ì§€)
            )
            
            # ğŸ“Š 4ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ ê°€ê³µ ë° í’ˆì§ˆ í•„í„°ë§
            past_conversations = []
            for result in search_results:
                metadata = result.get("metadata", {})
                content = result.get("content", "")
                relevance_score = result.get("relevance_score", 0)
                
                # âœ… 5ë‹¨ê³„: ê´€ë ¨ë„ ì„ê³„ê°’ í•„í„°ë§ (í’ˆì§ˆ ë³´ì¥)
                # ê´€ë ¨ë„ê°€ 0.1 ì´ìƒì¸ ê²ƒë§Œ í¬í•¨ (ë„ˆë¬´ ë‚®ìœ¼ë©´ ë…¸ì´ì¦ˆ, ë„ˆë¬´ ë†’ìœ¼ë©´ ê²°ê³¼ ë¶€ì¡±)
                if relevance_score > 0.1:
                    past_conversations.append({
                        "conversation_id": metadata.get("conversation_id"),
                        "summary": metadata.get("summary", ""),
                        "content_snippet": content[:200] + "..." if len(content) > 200 else content,
                        "created_at": metadata.get("created_at"),
                        "relevance_score": relevance_score,
                        "message_count": metadata.get("message_count", 0)
                    })
            
            self.logger.info(f"ê³¼ê±° ëŒ€í™” ê²€ìƒ‰ ì™„ë£Œ: {len(past_conversations)}ê°œ (member_id: {member_id})")
            return past_conversations
            
        except Exception as e:
            self.logger.error(f"ê³¼ê±° ëŒ€í™” ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def _get_news_results(self, state: ChatState, intent_analysis: dict) -> list:
        """
        ğŸ“° ë‰´ìŠ¤ ë°ì´í„° ê²€ìƒ‰ (NewsRetrieverAgent ì§ì ‘ í˜¸ì¶œ)
        
        ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì˜ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ NewsRetrieverAgentë¥¼ í†µí•´
        ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ìµœì‹  ì‚°ì—… ë™í–¥ ë° ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
        
        ğŸ” ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤:
        1. NewsRetrieverAgent ì§€ì—° ë¡œë”© (í•„ìš”ì‹œì—ë§Œ ì´ˆê¸°í™”)
        2. ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ì¶œ
        3. Agentë¥¼ í†µí•œ ì˜ë¯¸ ê¸°ë°˜ ë‰´ìŠ¤ ê²€ìƒ‰
        4. ìƒìœ„ 3ê°œ ê²°ê³¼ ë°˜í™˜
        
        Args:
            state (ChatState): í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ (user_question í¬í•¨)
            intent_analysis (dict): ì˜ë„ ë¶„ì„ ê²°ê³¼ (ê²€ìƒ‰ ìµœì í™”ìš©)
            
        Returns:
            list: ê²€ìƒ‰ëœ ë‰´ìŠ¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
                [
                    {
                        "id": "ë‰´ìŠ¤ ID",
                        "title": "ë‰´ìŠ¤ ì œëª©",
                        "content": "ë‰´ìŠ¤ ë‚´ìš©",
                        "source": "ë‰´ìŠ¤ ì¶œì²˜",
                        "published_date": "ë°œí–‰ì¼",
                        "category": "ì¹´í…Œê³ ë¦¬",
                        "domain": "ë„ë©”ì¸",
                        "relevance_score": "ê´€ë ¨ë„ ì ìˆ˜"
                    }
                ]
        """
        try:
            # ğŸ“° 1ë‹¨ê³„: ë‰´ìŠ¤ ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì§€ì—° ë¡œë”© (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
            if self.news_retriever_agent is None:
                try:
                    from app.graphs.agents.retriever import NewsRetrieverAgent
                    self.news_retriever_agent = NewsRetrieverAgent()
                except ImportError as e:
                    self.logger.warning(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì—ì´ì „íŠ¸ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                    return []
            
            # ğŸ” 2ë‹¨ê³„: ê²€ìƒ‰ ì¿¼ë¦¬ ì¤€ë¹„
            user_question = state.get("user_question", "")
            
            # ğŸ¯ 3ë‹¨ê³„: NewsRetrieverAgentë¥¼ í†µí•œ ë‰´ìŠ¤ ê²€ìƒ‰
            news_results = self.news_retriever_agent.search_relevant_news(
                query=user_question,
                intent_analysis=intent_analysis,
                n_results=2  # ìƒìœ„ 2ê°œ ë‰´ìŠ¤ë§Œ ì„ íƒ (ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ìµœì í™”)
            )
            
            self.logger.info(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(news_results)}ê°œ")
            return news_results
            
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []


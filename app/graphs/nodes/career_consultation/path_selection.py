# app/graphs/nodes/career_consultation/path_selection.py
"""
ì»¤ë¦¬ì–´ ê²½ë¡œ ì„ íƒ ì²˜ë¦¬ ë…¸ë“œ
ì‚¬ìš©ìê°€ ì„ íƒí•œ ê²½ë¡œì— ëŒ€í•œ ì‹¬í™” ë…¼ì˜ë¥¼ ì§„í–‰
AI ê¸°ë°˜ ê°œì¸ ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„± í¬í•¨
"""

import os
from typing import Dict, Any
from app.graphs.state import ChatState
from app.utils.html_logger import save_career_response_to_html


class PathSelectionNode:
    """
    ê²½ë¡œ ì„ íƒ ë° êµ¬ì²´í™” ë…¸ë“œ
    """
    
    def __init__(self, graph_builder):
        self.graph_builder = graph_builder
    
    async def _generate_path_selection_response(self, merged_user_data: dict, selected_path: dict) -> str:
        """ì„ íƒí•œ ê²½ë¡œì— ëŒ€í•œ AI ê¸°ë°˜ ê°„ê²°í•œ í™•ì¸ ë° ëª©í‘œ ì„¤ì • ì§ˆë¬¸ ìƒì„±"""
        try:
            from openai import AsyncOpenAI
            
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                return "ê²½ë¡œ ì„ íƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. êµ¬ì²´ì ì¸ ëª©í‘œë¥¼ ì„¤ì •í•´ë³´ê² ìŠµë‹ˆë‹¤."
            
            client = AsyncOpenAI(api_key=api_key)
            
            skills_str = ", ".join(merged_user_data.get('skills', ['ì •ë³´ ì—†ìŒ']))
            path_name = selected_path.get('name', 'ì„ íƒëœ ê²½ë¡œ')
            
            prompt = f"""
ë‹¹ì‹ ì€ G.Naviì˜ ì „ë¬¸ ì»¤ë¦¬ì–´ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. í˜„ì¬ ìƒë‹´ì´ ì§„í–‰ ì¤‘ì´ë©°, {merged_user_data.get('name', 'ê³ ê°')}ë‹˜ì´ "{path_name}" ê²½ë¡œë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤.

**ê³ ê° ì •ë³´:**
- ì´ë¦„: {merged_user_data.get('name', 'ê³ ê°')}
- ê²½ë ¥: {merged_user_data.get('experience', 'ì •ë³´ ì—†ìŒ')}
- ë³´ìœ  ê¸°ìˆ : {skills_str}
- ë„ë©”ì¸: {merged_user_data.get('domain', 'ì •ë³´ ì—†ìŒ')}
- ì„ íƒí•œ ê²½ë¡œ: {path_name}

**ìš”ì²­ì‚¬í•­:**
1. ê²½ë¡œ ì„ íƒì— ëŒ€í•œ ê°„ë‹¨í•œ í™•ì¸ ë° ê²©ë ¤
2. ë‹¤ìŒ ë‹¨ê³„ ë§ì¶¤í˜• ë¶„ì„ì„ ìœ„í•œ í•µì‹¬ ì§ˆë¬¸ 3ê°œ (ê° ì¹´í…Œê³ ë¦¬ë‹¹ 1ê°œì”©ë§Œ)

**ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”):**

## ê²½ë¡œ ì„ íƒ í™•ì¸

**{merged_user_data.get('name', 'ê³ ê°')}ë‹˜**ì´ ì„ íƒí•˜ì‹  **{path_name}** ê²½ë¡œëŠ” í›Œë¥­í•œ ì„ íƒì…ë‹ˆë‹¤! 
ë” êµ¬ì²´ì ì´ê³  ì‹¤ë¬´ì ì¸ ì•¡ì…˜ í”Œëœì„ ìˆ˜ë¦½í•˜ê¸° ìœ„í•´ 3ê°€ì§€ í•µì‹¬ ì§ˆë¬¸ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤

### ë§ì¶¤í˜• ì „ëµ ìˆ˜ë¦½ì„ ìœ„í•œ ì§ˆë¬¸

**ğŸ’¡ ì°¸ê³ ì‚¬í•­**
ì•„ë˜ ì§ˆë¬¸ë“¤ì— ë‹µë³€í•´ ì£¼ì‹œë©´ ë”ìš± ì •í™•í•œ ë§ì¶¤í˜• ì „ëµì„ ì œì•ˆë“œë¦´ ìˆ˜ ìˆì§€ë§Œ, **ë‹µë³€í•˜ì§€ ì•Šìœ¼ì…”ë„ ë©ë‹ˆë‹¤**. í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ê³ ê°ë‹˜ì˜ ì •ë³´(ê²½ë ¥, ê¸°ìˆ ìŠ¤íƒ, ë„ë©”ì¸)ì™€ ì‚¬ë‚´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œë„ ì¶©ë¶„íˆ ì‹¤ë¬´ì ì¸ ì„±ê³µ ì „ëµì„ ì œì•ˆë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤!


**1. ì„ íƒ ì´ìœ **
- ì´ ê²½ë¡œë¥¼ ì„ íƒí•˜ì‹  ê°€ì¥ ì¤‘ìš”í•œ ì´ìœ  í•œ ê°€ì§€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?

**2. êµ¬ì²´ì  ëª©í‘œ**  
- ì´ ê²½ë¡œë¥¼ í†µí•´ 1ë…„ í›„ ë‹¬ì„±í•˜ê³  ì‹¶ì€ êµ¬ì²´ì ì¸ ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?

**3. í˜„ì¬ ìƒí™©**
- í˜„ì¬ ì´ ëª©í‘œ ë‹¬ì„±ì— ê°€ì¥ í° ê±¸ë¦¼ëŒì´ë‚˜ ê³ ë¯¼ì€ ë¬´ì—‡ì¸ê°€ìš”?

---

**ë‹¤ìŒ ìŠ¤í…: ë§ì¶¤í˜• ì„±ì¥ ë¡œë“œë§µ**

ìœ„ ì§ˆë¬¸ë“¤ì— ëŒ€í•œ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ë”ìš± êµ¬ì²´ì ì´ê³  ì‹¤ë¬´ì ì¸ ì„±ì¥ ë¡œë“œë§µì„ í•¨ê»˜ ì„¤ê³„í•´ë³´ì‹œê² ì–´ìš”? ê°œì¸ ë§ì¶¤í˜• í•™ìŠµ ê³„íšê³¼ ì‹¤í–‰ ì „ëµì„ ì œì•ˆë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤!

**ì‘ì„± ì§€ì¹¨:**
- ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ (## ì œëª©, ### ì†Œì œëª©, **êµµì€ê¸€ì”¨**, - ë¦¬ìŠ¤íŠ¸ ë“±)
- ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ "## ê²½ë¡œ ì„ íƒ í™•ì¸" ì œëª©ìœ¼ë¡œ ì‹œì‘
- ìƒë‹´ì‚¬ì²˜ëŸ¼ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±
- 120-150ë‹¨ì–´ ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±
- ê° ì¹´í…Œê³ ë¦¬ë‹¹ ì •í™•íˆ 1ê°œì˜ ì§ˆë¬¸ë§Œ í¬í•¨
- **ì„ íƒ ì´ìœ **, **êµ¬ì²´ì  ëª©í‘œ**, **í˜„ì¬ ìƒí™©** ê°ê° 1ê°œì”© ì´ 3ê°œ ì§ˆë¬¸
- ë‹¤ìŒ ë‹¨ê³„(path_deepening)ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” í•µì‹¬ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ìˆ˜ì§‘ì— ì´ˆì 
"""
            
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000,
                temperature=0.4
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"ê²½ë¡œ ì„ íƒ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return "ê²½ë¡œ ì„ íƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì œ êµ¬ì²´ì ì¸ ëª©í‘œë¥¼ ì„¤ì •í•´ë³´ê² ìŠµë‹ˆë‹¤."
    
    async def process_path_selection_node(self, state: ChatState) -> Dict[str, Any]:
        """
        ì‚¬ìš©ìê°€ ì„ íƒí•œ ê²½ë¡œë¥¼ ì²˜ë¦¬í•˜ê³  ì‹¬í™” ì§ˆë¬¸ì„ ì§„í–‰í•œë‹¤.
        """
        print("ğŸ›¤ï¸ ê²½ë¡œ ì„ íƒ ì²˜ë¦¬ ì‹œì‘...")
        
        user_question = state.get("user_question", "").strip()
        career_paths = state.get("career_paths_suggested", [])
        
        # ì‚¬ìš©ì ì„ íƒ íŒŒì‹±
        selected_path = None
        user_question_upper = user_question.upper()
        
        # ë²ˆí˜¸ ê¸°ë°˜ ì„ íƒ ì²˜ë¦¬
        if "1ë²ˆ" in user_question or "1" in user_question or "ì²«" in user_question or "ONE" in user_question_upper:
            selected_path = career_paths[0] if len(career_paths) > 0 else None
        elif "2ë²ˆ" in user_question or "2" in user_question or "ë‘˜" in user_question or "TWO" in user_question_upper:
            selected_path = career_paths[1] if len(career_paths) > 1 else None
        else:
            # IDë‚˜ ì´ë¦„ ê¸°ë°˜ ì„ íƒ ì²˜ë¦¬
            for path in career_paths:
                if (path.get("id", "") in user_question_upper or 
                    path.get("name", "") in user_question):
                    selected_path = path
                    break
        
        # ê¸°ë³¸ê°’ ì²˜ë¦¬
        if not selected_path:
            selected_path = career_paths[0] if career_paths else {"name": "ê¸°ë³¸ ê²½ë¡œ", "id": "default_path"}
        
        # selected_pathì— path_name ì¶”ê°€
        if selected_path and "path_name" not in selected_path:
            selected_path["path_name"] = selected_path.get("name", "ì„ íƒëœ ê²½ë¡œ")
        
        user_data = self.graph_builder.get_user_info_from_session(state)
        collected_info = state.get("collected_user_info", {})
        merged_user_data = {**user_data, **collected_info}
        
        # AI ê¸°ë°˜ ê²½ë¡œ ì„ íƒ í™•ì¸ ë° ëª©í‘œ ì„¤ì • ì§ˆë¬¸ ìƒì„±
        ai_response = await self._generate_path_selection_response(merged_user_data, selected_path)
        
        # ì‘ë‹µ êµ¬ì„±
        deepening_response = {
            "message": ai_response,
            "selected_path": selected_path
        }
        
        # path_selectionì—ì„œ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ path_deepeningì—ì„œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì €ì¥
        path_selection_info = {
            "user_input_for_deepening": user_question  # ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ë¶„ì„í•  ì‚¬ìš©ì ì‘ë‹µ (ìœ ì¼í•˜ê²Œ ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” ì •ë³´)
        }
        
        # HTML ë¡œê·¸ ì €ì¥
        save_career_response_to_html("path_selection", deepening_response, state.get("session_id", "unknown"))
        
        # path_selectionì—ì„œ state_traceì— ì¶”ê°€
        import time
        updated_state_trace = state.get("state_trace", []) + [f"path_selection_completed_{int(time.time())}"]
        
        return {
            **state,
            "consultation_stage": "deepening",
            "selected_career_path": selected_path,
            "path_selection_info": path_selection_info,  # path_deepeningì—ì„œ í™œìš©í•  ì •ë³´
            "path_name": selected_path.get("path_name") or selected_path.get("name", "ì„ íƒëœ ê²½ë¡œ"),  # learning_roadmapì—ì„œ ì‚¬ìš©
            "formatted_response": deepening_response,
            "final_response": deepening_response,
            "awaiting_user_input": True,
            "next_expected_input": "goals_and_reasons",
            "state_trace": updated_state_trace,  # ì¶”ì  ì •ë³´ ì—…ë°ì´íŠ¸
            "processing_log": state.get("processing_log", []) + [f"ê²½ë¡œ ì„ íƒ ì™„ë£Œ: {selected_path.get('name', '')} (ë²ˆí˜¸: {selected_path.get('number', 'N/A')})"]
        }

# app/graphs/nodes/career_consultation/path_deepening.py
"""
ì„ íƒí•œ ê²½ë¡œì— ëŒ€í•œ ì‹¬í™” ë…¼ì˜ ë…¸ë“œ
ì‚¬ìš©ìì˜ ëª©í‘œì™€ ì´ìœ ë¥¼ ë¶„ì„í•˜ì—¬**ğŸ” í˜„ì¬ ìƒí™© ë¶„ì„ (Gap Analysis)**
- **ë³´ìœ  ì—­ëŸ‰**: {', '.join(user_data.get('skills', [])[:3])} ë“±
- **ê²½ë ¥ ìˆ˜ì¤€**: {user_data.get('experience', 'N/A')}ë…„ì°¨
- **ë¶€ì¡± ì—­ëŸ‰**: [ì‘ë‹µ ê¸°ë°˜ ë¶„ì„ í•„ìš”]
- **ì„±ì¥ ê°€ëŠ¥ì„±**: ë†’ìŒ (ê¸°ì¡´ ê²½í—˜ í™œìš© ê°€ëŠ¥)

{("**ğŸ¤– AI ë§ì¶¤í˜• ì „ëµ ë¶„ì„**" + chr(10) + ai_strategy + chr(10)) if ai_strategy else ""}

**ğŸ—ºï¸ ì²´ê³„ì  ì‹¤í–‰ ë¡œë“œë§µ** ìˆ˜ë¦½
AI ê¸°ë°˜ ê°œì¸ ë§ì¶¤í˜• ì „ëµ ë¶„ì„ í¬í•¨
"""

import os
from typing import Dict, Any
from app.graphs.state import ChatState
from app.utils.html_logger import save_career_response_to_html


class PathDeepeningNode:
    """
    ê²½ë¡œ ì‹¬í™” ë…¼ì˜ ë…¸ë“œ
    """
    
    def __init__(self, graph_builder):
        self.graph_builder = graph_builder
        # ê¸°ì¡´ ë°ì´í„° ê²€ìƒ‰ ë…¸ë“œ ì¬í™œìš©
        self.data_retrieval_node = graph_builder.data_retrieval_node
    
    async def _generate_personalized_strategy(self, user_data: dict, selected_path: dict, user_goals: str) -> str:
        """AI ê¸°ë°˜ ê°œì¸ ë§ì¶¤í˜• ì‹¤í–‰ ì „ëµ ìƒì„±"""
        try:
            from openai import AsyncOpenAI
            
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                return ""
            
            client = AsyncOpenAI(api_key=api_key)
            
            skills_str = ", ".join(user_data.get('skills', ['í˜„ì¬ ìŠ¤í‚¬']))
            path_name = selected_path.get('name', 'ì„ íƒëœ ê²½ë¡œ')
            
            prompt = f"""
ë‹¤ìŒ ì§ì¥ì¸ì„ ìœ„í•œ ë§ì¶¤í˜• ì»¤ë¦¬ì–´ ì „ëµì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”:

- ê²½ë ¥: {user_data.get('experience', 'ì •ë³´ ì—†ìŒ')}
- í˜„ì¬ ìŠ¤í‚¬: {skills_str}
- ëª©í‘œ ê²½ë¡œ: {path_name}
- ëª©í‘œ ë° ë™ê¸°: {user_goals[:300]}
- ë„ë©”ì¸: {user_data.get('domain', 'ì „ë¬¸ ë¶„ì•¼')}

ë‹¤ìŒì„ í¬í•¨í•˜ì—¬ 200-250ë‹¨ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. í˜„ì¬ ìƒí™©ì—ì„œ ì´ ê²½ë¡œë¡œ ê°€ê¸° ìœ„í•œ êµ¬ì²´ì  ê°­ ë¶„ì„
2. 3-6ê°œì›” ë‚´ ë‹¬ì„± ê°€ëŠ¥í•œ í˜„ì‹¤ì  ì²« ë‹¨ê³„
3. ê°€ì¥ ì¤‘ìš”í•œ ìŠ¤í‚¬ ê°œë°œ ìš°ì„ ìˆœìœ„ 3ê°€ì§€
4. ì˜ˆìƒë˜ëŠ” ì–´ë ¤ì›€ê³¼ í•´ê²° ë°©ì•ˆ

ì‹¤ë¬´ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
            
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=3000,
                temperature=0.6
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"ê°œì¸í™” ì „ëµ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return ""
    
    async def process_deepening_node(self, state: ChatState) -> Dict[str, Any]:
        """
        ì‚¬ìš©ìì˜ ëª©í‘œì™€ ì´ìœ ë¥¼ ë¶„ì„í•˜ì—¬ ì‹¤í–‰ ì „ëµì„ ì œì‹œí•œë‹¤.
        """
        print("ğŸ¯ ê²½ë¡œ ì‹¬í™” ë…¼ì˜ ì‹œì‘...")
        
        user_response = state.get("user_question", "")
        selected_path = state.get("selected_career_path", {})
        user_data = self.graph_builder.get_user_info_from_session(state)
        
        # ê¸°ì¡´ ë°ì´í„° ê²€ìƒ‰ ë…¸ë“œë¡œ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘
        state = self.data_retrieval_node.retrieve_additional_data_node(state)
        
        # AI ê¸°ë°˜ ê°œì¸ ë§ì¶¤í˜• ì „ëµ ìƒì„±
        ai_strategy = await self._generate_personalized_strategy(
            user_data, selected_path, user_response
        )
        
        # ì‚¬ìš©ì ì‘ë‹µ ì»¨í…ìŠ¤íŠ¸ ì €ì¥
        consultation_context = {
            "user_goals": user_response,
            "selected_path": selected_path,
            "analysis_timestamp": "2025-07-02"
        }
        
        # ì „ë¬¸ì ì¸ ì‹¤í–‰ ì „ëµ ë° ë¶„ì„ ìƒì„±
        strategy_response = {
            "message": f"""ğŸ¯ **ì „ë¬¸ì  ì»¤ë¦¬ì–´ ë¶„ì„ ë° ì‹¤í–‰ ì „ëµ**

{user_data.get('name', 'ê³ ê°')}ë‹˜ì˜ ëª©í‘œì™€ í˜„ì¬ ìƒí™©ì„ ì¢…í•© ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, **{selected_path.get('name', 'ì„ íƒí•˜ì‹  ê²½ë¡œ')}** ë‹¬ì„±ì„ ìœ„í•œ ì²´ê³„ì ì¸ ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤.

**ï¿½ í˜„ì¬ ìƒí™© ë¶„ì„ (Gap Analysis)**
- **ë³´ìœ  ì—­ëŸ‰**: {', '.join(user_data.get('skills', [])[:3])} ë“±
- **ê²½ë ¥ ìˆ˜ì¤€**: {user_data.get('experience', 'N/A')}ë…„ì°¨
- **ë¶€ì¡± ì—­ëŸ‰**: [ì‘ë‹µ ê¸°ë°˜ ë¶„ì„ í•„ìš”]
- **ì„±ì¥ ê°€ëŠ¥ì„±**: ë†’ìŒ (ê¸°ì¡´ ê²½í—˜ í™œìš© ê°€ëŠ¥)

**ğŸ—ºï¸ ì²´ê³„ì  ì‹¤í–‰ ë¡œë“œë§µ**

**Phase 1: ê¸°ë°˜ êµ¬ì¶• (1-3ê°œì›”)**
- **ì—­ëŸ‰ ì§„ë‹¨**: í˜„ì¬ ìˆ˜ì¤€ ê°ê´€ì  í‰ê°€
- **Quick Win í”„ë¡œì íŠ¸**: ê´€ë ¨ ì—…ë¬´ì—ì„œ ì‘ì€ ì„±ê³¼ ì°½ì¶œ
- **ë„¤íŠ¸ì›Œí¬ êµ¬ì¶•**: í•´ë‹¹ ë¶„ì•¼ ì‚¬ë‚´ ì „ë¬¸ê°€ 1-2ëª…ê³¼ ê´€ê³„ í˜•ì„±
- **í•™ìŠµ í™˜ê²½ êµ¬ì¶•**: í•„ìš” ë„êµ¬/ë¦¬ì†ŒìŠ¤ í™•ë³´

**Phase 2: ì—­ëŸ‰ ê°•í™” (3-9ê°œì›”)**
- **í•µì‹¬ ìŠ¤í‚¬ ê°œë°œ**: {selected_path.get('focus', 'ê´€ë ¨ ë¶„ì•¼')} ì „ë¬¸ì„± ê°•í™”
- **ì‹¤ë¬´ ì ìš©**: í˜„ì¬ ì—…ë¬´ì— ìƒˆë¡œìš´ ë°©ë²•ë¡  ì ìš©
- **ë©˜í† ë§ ì‹œì‘**: ì„ ë°° ì „ë¬¸ê°€ì™€ ì •ê¸° ë©˜í† ë§ ì„¸ì…˜
- **ì™¸ë¶€ í™œë™**: ê´€ë ¨ ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬ ë° ë„¤íŠ¸ì›Œí‚¹

**Phase 3: ì„±ê³¼ ì°½ì¶œ (9-18ê°œì›”)**
- **í”„ë¡œì íŠ¸ ë¦¬ë“œ**: ê´€ë ¨ ë¶„ì•¼ í”„ë¡œì íŠ¸ ì£¼ë„
- **ì§€ì‹ ê³µìœ **: ì‚¬ë‚´ ì„¸ë¯¸ë‚˜/êµìœ¡ ì§„í–‰
- **ì„±ê³¼ ì¸¡ì •**: ì •ëŸ‰ì  ì„±ê³¼ ì§€í‘œ ìˆ˜ì§‘
- **ê²½ë ¥ ì¤€ë¹„**: ëª©í‘œ í¬ì§€ì…˜ ì§€ì› ì¤€ë¹„

**ğŸ¯ í•µì‹¬ ì„±ê³µ ìš”ì¸ (Critical Success Factors)**
1. **ì§€ì†ì  í•™ìŠµ**: ì£¼ 5-10ì‹œê°„ íˆ¬ì
2. **ì‹¤ë¬´ ì ìš©**: ë°°ìš´ ë‚´ìš© ì¦‰ì‹œ ì—…ë¬´ ì ìš©
3. **ë„¤íŠ¸ì›Œí‚¹**: ì›” 1-2íšŒ ì „ë¬¸ê°€ ë„¤íŠ¸ì›Œí‚¹
4. **ì„±ê³¼ ê¸°ë¡**: ëª¨ë“  ì„±ê³¼ ë¬¸ì„œí™” ë° ì •ëŸ‰í™”

**âš ï¸ ì£¼ì˜ì‚¬í•­ ë° ë¦¬ìŠ¤í¬ ê´€ë¦¬**
- **ì‹œê°„ ê´€ë¦¬**: í˜„ì¬ ì—…ë¬´ í’ˆì§ˆ ìœ ì§€í•˜ë©° ì„±ì¥
- **ë²ˆì•„ì›ƒ ë°©ì§€**: ë‹¨ê³„ì  ëª©í‘œ ì„¤ì •ìœ¼ë¡œ ì§€ì†ê°€ëŠ¥ì„± í™•ë³´
- **ì¡°ì§ ë‚´ ì •ì¹˜**: ìƒì‚¬ ë° ë™ë£Œì™€ì˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ê°•í™”

**ğŸ“ˆ ì„±ê³µ ì§€í‘œ (KPI)**
- 3ê°œì›”: ê´€ë ¨ ì—…ë¬´ ì°¸ì—¬ìœ¨ 30% ì¦ê°€
- 6ê°œì›”: í•´ë‹¹ ë¶„ì•¼ ì‚¬ë‚´ ì „ë¬¸ê°€ ì¸ì •
- 12ê°œì›”: ê´€ë ¨ í”„ë¡œì íŠ¸ ì„±ê³¼ ì°½ì¶œ
- 18ê°œì›”: ëª©í‘œ í¬ì§€ì…˜ ì§€ì› ìê²© íšë“

**ë‹¤ìŒ ë‹¨ê³„ë¡œ ë§ì¶¤í˜• í•™ìŠµ ê³„íšì„ ìˆ˜ë¦½í•´ë“œë¦´ê¹Œìš”?**
êµ¬ì²´ì ì¸ êµìœ¡ê³¼ì •, ë„ì„œ, í”„ë¡œì íŠ¸ ë“±ì„ í¬í•¨í•œ ìƒì„¸ í•™ìŠµ ë¡œë“œë§µì´ í•„ìš”í•˜ì‹œë©´ "ë„¤, í•™ìŠµ ê³„íšë„ ë°›ê³  ì‹¶ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.""",
            "action_plan": {
                "phase1": "ê¸°ë°˜ êµ¬ì¶• (1-3ê°œì›”)",
                "phase2": "ì—­ëŸ‰ ê°•í™” (3-9ê°œì›”)", 
                "phase3": "ì„±ê³¼ ì°½ì¶œ (9-18ê°œì›”)",
                "success_factors": ["ì§€ì†ì  í•™ìŠµ", "ì‹¤ë¬´ ì ìš©", "ë„¤íŠ¸ì›Œí‚¹", "ì„±ê³¼ ê¸°ë¡"]
            }
        }
        
        # HTML ë¡œê·¸ ì €ì¥
        save_career_response_to_html("path_deepening", strategy_response, state.get("session_id", "unknown"))
        
        return {
            **state,
            "consultation_stage": "learning_decision",
            "consultation_context": consultation_context,
            "formatted_response": strategy_response,
            "final_response": strategy_response,  # final_response ì¶”ê°€
            "awaiting_user_input": True,
            "next_expected_input": "learning_roadmap_decision",
            "processing_log": state.get("processing_log", []) + ["ì‹¤í–‰ ì „ëµ ìˆ˜ë¦½ ì™„ë£Œ"]
        }

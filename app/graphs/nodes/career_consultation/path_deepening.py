# app/graphs/nodes/career_consultation/path_deepening.py
"""
ì„ íƒí•œ ê²½ë¡œì— ëŒ€í•œ ì‹¬í™” ë…¼ì˜ ë…¸ë“œ
ì‚¬ìš©ìì˜ ëª©í‘œì™€ ì´ìœ ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ë‚´ ë°ì´í„° ê¸°ë°˜ ì•¡ì…˜ í”Œëœ ìˆ˜ë¦½
AI ê¸°ë°˜ ê°œì¸ ë§ì¶¤í˜• ì „ëµ ë¶„ì„ í¬í•¨
"""

import os
from typing import Dict, Any
from app.graphs.state import ChatState
from app.utils.html_logger import save_career_response_to_html


class PathDeepeningNode:
    """
    ê²½ë¡œ ì‹¬í™” ë…¼ì˜ ë…¸ë“œ
    """
    
    def __init__(self, graph_builder):
        self.graph_builder = graph_builder
        # ê¸°ì¡´ ë°ì´í„° ê²€ìƒ‰ ë…¸ë“œ ì¬í™œìš©
        self.data_retrieval_node = graph_builder.data_retrieval_node
    
    async def _generate_ai_action_plan(self, merged_user_data: dict, selected_path: dict, user_goals: str, retrieved_data: dict) -> str:
        """AI ê¸°ë°˜ ì‚¬ë‚´ ë°ì´í„°ë¥¼ í™œìš©í•œ ì•¡ì…˜ í”Œëœ ë° ë©˜í†  ì¶”ì²œ ìƒì„±"""
        try:
            from openai import AsyncOpenAI
            
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                return "AI ë¶„ì„ ê¸°ëŠ¥ì´ í˜„ì¬ ì´ìš© ë¶ˆê°€í•©ë‹ˆë‹¤."
            
            client = AsyncOpenAI(api_key=api_key)
            
            skills_str = ", ".join(merged_user_data.get('skills', ['ì •ë³´ ì—†ìŒ']))
            path_name = selected_path.get('name', 'ì„ íƒëœ ê²½ë¡œ')
            
            # ë””ë²„ê¹…: AI ë©”ì„œë“œì— ì „ë‹¬ëœ ë°ì´í„° í™•ì¸
            print(f"ğŸ” DEBUG - path_deepening AI ë©”ì„œë“œì— ì „ë‹¬ëœ merged_user_data: {merged_user_data}")
            print(f"ğŸ” DEBUG - path_deepening user_goals: {user_goals}")
            
            # retrieved_dataì—ì„œ ì‚¬ë‚´ ê²½ë ¥ ë°ì´í„° ì¶”ì¶œ
            career_data = retrieved_data.get('career_data', [])
            
            # ë””ë²„ê¹…: career_data í™•ì¸
            print(f"ğŸ” DEBUG - path_deepeningì—ì„œ ì‚¬ìš©í•  career_data ê°œìˆ˜: {len(career_data)}")
            print(f"ğŸ” DEBUG - career_data ìƒ˜í”Œ: {career_data[:2] if career_data else 'None'}")
            print(f"ğŸ” DEBUG - retrieved_dataì˜ í‚¤ë“¤: {list(retrieved_data.keys())}")
            print(f"ğŸ” DEBUG - career_dataê°€ existing_career_dataì—ì„œ ì™”ëŠ”ì§€ í™•ì¸")
            
            career_context = ""
            if career_data:
                print(f"âœ… SUCCESS - {len(career_data)}ê°œì˜ ì‚¬ë‚´ êµ¬ì„±ì› ë°ì´í„° í™œìš© ê°€ëŠ¥")
                # ì‚¬ë‚´ êµ¬ì„±ì› ë°ì´í„°ë¥¼ ìµëª…í™”í•˜ì—¬ í™œìš©
                career_profiles = []
                for i, profile in enumerate(career_data[:10]):  # ìµœëŒ€ 10ê°œë§Œ ìƒì„¸ ë¶„ì„
                    # ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ ìµëª…í™” ì²˜ë¦¬
                    anonymous_id = f'êµ¬ì„±ì›{chr(65+i)}'  # êµ¬ì„±ì›A, êµ¬ì„±ì›B, ...
                    experience = profile.get('experience', 'ì •ë³´ì—†ìŒ')
                    skills = profile.get('skills', [])
                    domain = profile.get('domain', 'ì •ë³´ì—†ìŒ')
                    career_path = profile.get('career_path', 'ì •ë³´ì—†ìŒ')
                    
                    profile_info = f"- {anonymous_id}: {experience}, ê¸°ìˆ : {', '.join(skills[:3])}, ë„ë©”ì¸: {domain}, ê²½ë¡œ: {career_path}"
                    career_profiles.append(profile_info)
                    
                    # ê° êµ¬ì„±ì› ë°ì´í„° ë””ë²„ê¹…
                    print(f"ğŸ” DEBUG - {anonymous_id}: experience={experience}, skills={skills[:3]}, domain={domain}")
                
                career_context = f"""
**ì‚¬ë‚´ êµ¬ì„±ì› ì„±ê³µ ì‚¬ë¡€ ({len(career_data)}ëª… ë¶„ì„, ìµëª…í™” ì²˜ë¦¬):**
{chr(10).join(career_profiles)}

**ë°ì´í„° ë¶„ì„ ê²°ê³¼:**
- ì´ {len(career_data)}ëª…ì˜ ì‚¬ë‚´ êµ¬ì„±ì› ë°ì´í„° ë¶„ì„ (ê°œì¸ì •ë³´ ìµëª…í™”)
- career_positioning ë‹¨ê³„ì—ì„œ ê²€ìƒ‰ëœ ë°ì´í„° í™œìš©
- ìœ ì‚¬ ê²½ë¡œ ì„±ê³µ ì‚¬ë¡€ ë° ì„±ì¥ íŒ¨í„´ íŒŒì•… ê°€ëŠ¥
"""
                print(f"ğŸ” DEBUG - ìƒì„±ëœ career_context ê¸¸ì´: {len(career_context)}")
                print(f"ğŸ” DEBUG - career_context ë¯¸ë¦¬ë³´ê¸°: {career_context[:200]}...")
            else:
                career_context = "ì‚¬ë‚´ êµ¬ì„±ì› ë°ì´í„°: í˜„ì¬ ë¶„ì„ ê°€ëŠ¥í•œ ë°ì´í„° ì—†ìŒ"
                print("âŒ WARNING - career_dataê°€ ë¹„ì–´ìˆì–´ ê¸°ë³¸ ë©”ì‹œì§€ ì‚¬ìš©")
                print("ğŸ” DEBUG - existing_career_data â†’ retrieved_data â†’ career_data ì „ë‹¬ ê³¼ì •ì—ì„œ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥ì„±")
            
            prompt = f"""
ë‹¹ì‹ ì€ G.Naviì˜ ì „ë¬¸ ì»¤ë¦¬ì–´ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. í˜„ì¬ ìƒë‹´ì´ ì§„í–‰ ì¤‘ì´ë©°, ì‚¬ë‚´ êµ¬ì„±ì› ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ë¬´ì ì¸ ì•¡ì…˜ í”Œëœì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.

**ê³ ê° ì •ë³´:**
- ì´ë¦„: {merged_user_data.get('name', 'ê³ ê°')}
- ê²½ë ¥: {merged_user_data.get('experience', 'ì •ë³´ ì—†ìŒ')}
- ë³´ìœ  ê¸°ìˆ : {skills_str}
- ë„ë©”ì¸: {merged_user_data.get('domain', 'ì •ë³´ ì—†ìŒ')}
- ì„ íƒí•œ ê²½ë¡œ: {path_name}
- ëª©í‘œ ë° ë™ê¸°: {user_goals[:200]}

**ì‚¬ë‚´ ë°ì´í„°:**
{career_context}

**ìš”ì²­ì‚¬í•­:**
1. ì‚¬ë‚´ ê²½ë ¥ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¥ê¸° ì•¡ì…˜ í”Œëœ ìˆ˜ë¦½
2. **ì‚¬ë‚´ êµ¬ì„±ì› ë²¤ì¹˜ë§ˆí‚¹**: ìœ„ì˜ ìµëª…í™”ëœ ì‚¬ë‚´ ë°ì´í„°ì—ì„œ {path_name} ê²½ë¡œì™€ ìœ ì‚¬í•œ êµ¬ì„±ì›ë“¤ì˜ ì„±ì¥ ì‚¬ë¡€ë¥¼ ë¶„ì„í•˜ê³  ë²¤ì¹˜ë§ˆí‚¹ 
   - ë°˜ë“œì‹œ ìœ„ì— ì œì‹œëœ êµ¬ì„±ì›A, êµ¬ì„±ì›B ë“±ì˜ ì‹¤ì œ ë°ì´í„°ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë¶„ì„
   - ê° êµ¬ì„±ì›ì˜ ê²½í—˜, ê¸°ìˆ , ë„ë©”ì¸, ê²½ë¡œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„±ì¥ íŒ¨í„´ ë„ì¶œ
   - ì„ íƒí•œ ê²½ë¡œì™€ ê°€ì¥ ìœ ì‚¬í•œ êµ¬ì„±ì›ë“¤ì„ ì‹ë³„í•˜ê³  ê·¸ë“¤ì˜ ì„±ê³µ ìš”ì¸ ë¶„ì„
3. ë°ì´í„° ê¸°ë°˜ ë©˜í† /ë¡¤ëª¨ë¸ ì¶”ì²œ (ìµëª…í™”ëœ í”„ë¡œí•„ì„ í™œìš©í•œ íŠ¹ì„± ê¸°ë°˜ ì¶”ì²œ)
4. ë„¤íŠ¸ì›Œí‚¹ ê¸°íšŒ ì œì•ˆ (ì‚¬ë‚´ ì»¤ë®¤ë‹ˆí‹°, ìŠ¤í„°ë”” ê·¸ë£¹ ë“±)
5. í•™ìŠµ ë¡œë“œë§µ ì„¤ê³„ í•„ìš”ì„±ì— ëŒ€í•œ ìœ ë„ ë©˜íŠ¸

**ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”):**

## ë§ì¶¤í˜• ì•¡ì…˜ í”Œëœ

{merged_user_data.get('name', 'ê³ ê°')}ë‹˜ì´ ì„¤ì •í•˜ì‹  ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšì„ ì œì•ˆë“œë¦½ë‹ˆë‹¤.

### 1. ì‚¬ë‚´ ì„±ê³µ ì‚¬ë¡€ ë²¤ì¹˜ë§ˆí‚¹

**ìœ ì‚¬ ì„±ì¥ ê²½ë¡œ ë¶„ì„:**
- ë°˜ë“œì‹œ ìœ„ì— ì œì‹œëœ ì‹¤ì œ ì‚¬ë‚´ êµ¬ì„±ì› ë°ì´í„°(êµ¬ì„±ì›A, êµ¬ì„±ì›B ë“±)ë¥¼ í™œìš©í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„
- {path_name} ê²½ë¡œì™€ ê°€ì¥ ìœ ì‚¬í•œ êµ¬ì„±ì›ë“¤ì„ ì‹ë³„í•˜ê³ , ê·¸ë“¤ì˜ ê²½í—˜, ê¸°ìˆ , ë„ë©”ì¸ì„ ë°”íƒ•ìœ¼ë¡œ ì„±ì¥ íŒ¨í„´ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ
- ì˜ˆ: "êµ¬ì„±ì›AëŠ” 3ë…„ì°¨ ê°œë°œìì—ì„œ {{}}, êµ¬ì„±ì›BëŠ” {{}} ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ {{}} ê²½ë¡œë¡œ ì„±ì¥" í˜•íƒœë¡œ ì‹¤ì œ ë°ì´í„° í™œìš©

### 2. ì¶”ì²œ ë©˜í† /ë¡¤ëª¨ë¸

- ìœ„ì— ì œì‹œëœ ì‹¤ì œ êµ¬ì„±ì› ë°ì´í„°ì—ì„œ ê°€ì¥ ì í•©í•œ ë©˜í†  ìœ í˜•ì„ êµ¬ì²´ì ìœ¼ë¡œ ì¶”ì²œ (ì˜ˆ: "êµ¬ì„±ì›Cì™€ ê°™ì€ {{}} ë°°ê²½ì˜ ë©˜í† ")

### 3. SKAX ì‚¬ë‚´ ë„¤íŠ¸ì›Œí‚¹ ê¸°íšŒ

**ì „ë¬¸ ì»¤ë®¤ë‹ˆí‹°:**
- **AI/Tech Innovation Lab**: ë§¤ì£¼ ëª©ìš”ì¼ 17:00-18:00, íŒêµ ë³¸ì‚¬ 15ì¸µ Innovation Hub
- **ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ìŠ¤í„°ë””**: ê²©ì£¼ í™”ìš”ì¼ 19:00-21:00, ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ ë³‘í–‰
- **í´ë¼ìš°ë“œ ì•„í‚¤í…ì²˜ í¬ëŸ¼**: ë§¤ì›” ì²«ì§¸ì£¼ ê¸ˆìš”ì¼ 14:00-16:00, ë³¸ì‚¬ ì»¨í¼ëŸ°ìŠ¤ë£¸

**ì„±ì¥ ë„¤íŠ¸ì›Œí¬:**
- **SKX ë©˜í† ë§ í”„ë¡œê·¸ë¨**: ë¶„ê¸°ë³„ ë§¤ì¹­, HRíŒ€ ì£¼ê´€ (ë‚´ë¶€ ì‹ ì²­ ì‹œìŠ¤í…œ í™œìš©)
- **Cross-Function í˜‘ì—… TF**: ë‹¤ì–‘í•œ ë¶€ì„œ ê°„ í”„ë¡œì íŠ¸ ì°¸ì—¬ ê¸°íšŒ
- **ë¦¬ë”ì‹­ ì›Œí¬ìƒµ**: ë§¤ì›” ë§ˆì§€ë§‰ì£¼ í† ìš”ì¼ 09:00-16:00, ì—°ìˆ˜ì›

**ì‹¤ë¬´ ë„¤íŠ¸ì›Œí‚¹:**
- **ì ì‹¬ì‹œê°„ Tech Talk**: ë§¤ì£¼ ìˆ˜ìš”ì¼ 12:30-13:30, ì¹´í˜í…Œë¦¬ì•„ ì„¸ë¯¸ë‚˜ì‹¤
- **ì‚¬ë‚´ í•´ì»¤í†¤**: ë¶„ê¸°ë³„ ê°œìµœ (íŒ€ ë¹Œë”© ë° ì•„ì´ë””ì–´ ê³µìœ )
- **ì—…ë¬´ ì—­ëŸ‰ ê°•í™” ëª¨ì„**: íŒ€ ë¦¬ë“œê¸‰ ì´ìƒ ëŒ€ìƒ ì›”ê°„ ëª¨ì„

### 4. ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš

- [ìœ„ì˜ ë²¤ì¹˜ë§ˆí‚¹ ê²°ê³¼ì™€ ì‚¬ë‚´ ë„¤íŠ¸ì›Œí‚¹ ê¸°íšŒë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ 3-6ê°œì›” ë‹¨ê³„ë³„ ê³„íš]

ë‹¤ìŒ ë‹¨ê³„ë¡œ **SKAX ì‚¬ë‚´ êµìœ¡ê³¼ì •ì„ ì¶”ì²œ**í•´ë“œë¦´ê¹Œìš”?

**ì‘ì„± ì§€ì¹¨:**
- ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ (## ì œëª©, ### ì†Œì œëª©, **êµµì€ê¸€ì”¨**, - ë¦¬ìŠ¤íŠ¸ ë“±)
- ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ "## ë§ì¶¤í˜• ì•¡ì…˜ í”Œëœ" ì œëª©ìœ¼ë¡œ ì‹œì‘
- ìƒë‹´ì‚¬ì²˜ëŸ¼ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±
- 250-300ë‹¨ì–´ ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ ìœ„ì£¼
- ì‚¬ë‚´ ë°ì´í„°ë¥¼ ì ê·¹ í™œìš©í•œ ë§ì¶¤í˜• ì¶”ì²œ (ë‹¨, ê°œì¸ì •ë³´ëŠ” ìµëª…í™”í•˜ì—¬ í™œìš©)
- **ì‚¬ë‚´ ì„±ê³µ ì‚¬ë¡€ ë²¤ì¹˜ë§ˆí‚¹ì„ í•„ìˆ˜ë¡œ í¬í•¨**: ì œì‹œëœ ì‹¤ì œ êµ¬ì„±ì› ë°ì´í„°ë¥¼ ë°˜ë“œì‹œ í™œìš©í•˜ì—¬ êµ¬ì²´ì ì¸ ë¶„ì„ ì œê³µ
- ë§ˆì§€ë§‰ì— í•™ìŠµ ë¡œë“œë§µ ì„¤ê³„ ì œì•ˆì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
"""
            
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000,
                temperature=0.6
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"AI ì•¡ì…˜ í”Œëœ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return "ì•¡ì…˜ í”Œëœì„ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    async def process_deepening_node(self, state: ChatState) -> Dict[str, Any]:
        """
        ì‚¬ìš©ìì˜ ëª©í‘œì™€ ì´ìœ ë¥¼ ë¶„ì„í•˜ì—¬ ì‹¤í–‰ ì „ëµì„ ì œì‹œí•œë‹¤.
        """
        print("ğŸ¯ ê²½ë¡œ ì‹¬í™” ë…¼ì˜ ì‹œì‘...")
        
        user_response = state.get("user_question", "")
        selected_path = state.get("selected_career_path", {})
        user_data = self.graph_builder.get_user_info_from_session(state)
        collected_info = state.get("collected_user_info", {})
        merged_user_data = {**user_data, **collected_info}
        
        # ë””ë²„ê¹…: ë°ì´í„° í™•ì¸
        print(f"ğŸ” DEBUG - path_deepening user_data from session: {user_data}")
        print(f"ğŸ” DEBUG - path_deepening collected_info: {collected_info}")
        print(f"ğŸ” DEBUG - path_deepening merged_user_data: {merged_user_data}")
        
        # ê¸°ì¡´ ë°ì´í„° ê²€ìƒ‰ ë…¸ë“œë¡œ ì‚¬ë‚´ ê²½ë ¥ ë°ì´í„° ìˆ˜ì§‘
        # career_positioningì—ì„œ ì´ë¯¸ ê²€ìƒ‰í•œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒˆë¡œ ê²€ìƒ‰
        existing_career_data = state.get("retrieved_career_data", [])
        print(f"ğŸ” DEBUG - stateì—ì„œ ê°€ì ¸ì˜¨ existing_career_data: {len(existing_career_data)}ê°œ")
        print(f"ğŸ” DEBUG - existing_career_data ìƒ˜í”Œ: {existing_career_data[:1] if existing_career_data else 'None'}")
        
        if existing_career_data:
            print(f"ğŸ” DEBUG - career_positioningì—ì„œ ì €ì¥ëœ ì‚¬ë‚´ êµ¬ì„±ì› ë°ì´í„° ì¬ì‚¬ìš©: {len(existing_career_data)}ê°œ")
            retrieved_data = {"career_data": existing_career_data}
            print(f"ğŸ” DEBUG - retrieved_data êµ¬ì„± ì™„ë£Œ: career_data í‚¤ì— {len(retrieved_data['career_data'])}ê°œ ë°ì´í„° ì €ì¥")
        else:
            print("ğŸ” DEBUG - ìƒˆë¡œìš´ ì‚¬ë‚´ êµ¬ì„±ì› ë°ì´í„° ê²€ìƒ‰ ì‹¤í–‰")
            state = self.data_retrieval_node.retrieve_additional_data_node(state)
            retrieved_data = state.get("retrieved_data", {})
            print(f"ğŸ” DEBUG - ìƒˆë¡œ ê²€ìƒ‰ëœ retrieved_data: {list(retrieved_data.keys()) if retrieved_data else 'None'}")
        
        print(f"ğŸ” DEBUG - AI í˜¸ì¶œ ì „ retrieved_data í™•ì¸: career_data={len(retrieved_data.get('career_data', []))}ê°œ")
        
        # AI ê¸°ë°˜ ì‚¬ë‚´ ë°ì´í„° í™œìš© ì•¡ì…˜ í”Œëœ ìƒì„±
        ai_response = await self._generate_ai_action_plan(
            merged_user_data, selected_path, user_response, retrieved_data
        )
        
        # ì‚¬ìš©ì ì‘ë‹µ ì»¨í…ìŠ¤íŠ¸ ì €ì¥
        consultation_context = {
            "user_goals": user_response,
            "selected_path": selected_path,
            "analysis_timestamp": "2025-07-02"
        }
        
        # ì‘ë‹µ êµ¬ì„±
        strategy_response = {
            "message": ai_response,
            "action_plan": {
                "context": consultation_context,
                "data_sources": ["career_data", "networking_opportunities"]
            }
        }
        
        # HTML ë¡œê·¸ ì €ì¥
        save_career_response_to_html("path_deepening", strategy_response, state.get("session_id", "unknown"))
        
        return {
            **state,
            "consultation_stage": "learning_decision",
            "consultation_context": consultation_context,
            "formatted_response": strategy_response,
            "final_response": strategy_response,
            "awaiting_user_input": True,
            "next_expected_input": "learning_roadmap_decision",
            "processing_log": state.get("processing_log", []) + ["ì‹¤í–‰ ì „ëµ ìˆ˜ë¦½ ì™„ë£Œ"]
        }

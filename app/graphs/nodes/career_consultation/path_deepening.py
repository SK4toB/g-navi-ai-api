# app/graphs/nodes/career_consultation/path_deepening.py
"""
ì„ íƒí•œ ê²½ë¡œì— ëŒ€í•œ ì‹¬í™” ë…¼ì˜ ë…¸ë“œ
ì‚¬ìš©ìì˜ ëª©í‘œì™€ ì´ìœ ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ë‚´ ë°ì´í„° ê¸°ë°˜ ì•¡ì…˜ í”Œëœ ìˆ˜ë¦½
AI ê¸°ë°˜ ê°œì¸ ë§ì¶¤í˜• ì „ëµ ë¶„ì„ í¬í•¨
"""

import os
from typing import Dict, Any
from app.graphs.state import ChatState
from app.utils.html_logger import save_career_response_to_html


class PathDeepeningNode:
    """
    ê²½ë¡œ ì‹¬í™” ë…¼ì˜ ë…¸ë“œ
    """
    
    def __init__(self, graph_builder):
        self.graph_builder = graph_builder
        # ê¸°ì¡´ ë°ì´í„° ê²€ìƒ‰ ë…¸ë“œ ì¬í™œìš©
        self.data_retrieval_node = graph_builder.data_retrieval_node
    
    async def _generate_ai_action_plan(self, merged_user_data: dict, selected_path: dict, user_goals: str, retrieved_data: dict, path_selection_context: dict = None) -> str:
        """AI ê¸°ë°˜ ì‚¬ë‚´ ë°ì´í„°ë¥¼ í™œìš©í•œ ì•¡ì…˜ í”Œëœ ë° ë©˜í†  ì¶”ì²œ ìƒì„±"""
        try:
            from openai import AsyncOpenAI
            
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                return "AI ë¶„ì„ ê¸°ëŠ¥ì´ í˜„ì¬ ì´ìš© ë¶ˆê°€í•©ë‹ˆë‹¤."
            
            client = AsyncOpenAI(api_key=api_key)
            
            # íšŒì‚¬ ë¹„ì „ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            company_vision_context = ""
            try:
                # retriever ëª¨ë“ˆì—ì„œ ì§ì ‘ íšŒì‚¬ ë¹„ì „ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
                from app.graphs.agents.retriever import CareerEnsembleRetrieverAgent
                temp_retriever = CareerEnsembleRetrieverAgent()
                company_vision_context = temp_retriever.get_company_vision_context()
                print(f"ğŸ” DEBUG - path_deepeningì—ì„œ íšŒì‚¬ ë¹„ì „ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ: {len(company_vision_context)}ì")
            except Exception as e:
                print(f"âŒ WARNING - path_deepeningì—ì„œ íšŒì‚¬ ë¹„ì „ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                company_vision_context = ""
            
            path_name = selected_path.get('name', 'ì„ íƒëœ ê²½ë¡œ')
            
            # ë””ë²„ê¹…: AI ë©”ì„œë“œì— ì „ë‹¬ëœ ë°ì´í„° í™•ì¸
            print(f"ğŸ” DEBUG - path_deepening AI ë©”ì„œë“œì— ì „ë‹¬ëœ merged_user_data: {merged_user_data}")
            print(f"ğŸ” DEBUG - ìƒë‹´ ëŒ€ìƒì ì •ë³´: ì´ë¦„={merged_user_data.get('name', 'None')}, ê²½ë ¥={merged_user_data.get('experience', 'None')}, ìŠ¤í‚¬={merged_user_data.get('skills', 'None')}, ë„ë©”ì¸={merged_user_data.get('domain', 'None')}")
            print(f"ğŸ” DEBUG - path_deepening user_goals: {user_goals}")
            print(f"ğŸ” DEBUG - path_selection_context: {path_selection_context}")
            
            # retrieved_dataì—ì„œ ì‚¬ë‚´ ê²½ë ¥ ë°ì´í„° ì¶”ì¶œ
            career_data = retrieved_data.get('career_data', [])
            
            # ë””ë²„ê¹…: career_data í™•ì¸
            print(f"ğŸ” DEBUG - path_deepeningì—ì„œ ì‚¬ìš©í•  career_data ê°œìˆ˜: {len(career_data)}")
            print(f"ğŸ” DEBUG - career_data ìƒ˜í”Œ: {career_data[:2] if career_data else 'None'}")
            print(f"ğŸ” DEBUG - retrieved_dataì˜ í‚¤ë“¤: {list(retrieved_data.keys())}")
            print(f"ğŸ” DEBUG - career_dataê°€ existing_career_dataì—ì„œ ì™”ëŠ”ì§€ í™•ì¸")
            
            career_context = ""
            if career_data:
                print(f"âœ… SUCCESS - {len(career_data)}ê°œì˜ ì‚¬ë‚´ êµ¬ì„±ì› ë°ì´í„° í™œìš© ê°€ëŠ¥")
                # ë°ì´í„° êµ¬ì¡°ì— ìƒê´€ì—†ì´ ê°„ë‹¨íˆ ì²˜ë¦¬
                career_profiles = []
                for i, profile in enumerate(career_data[:10]):  # ìµœëŒ€ 10ê°œë§Œ ìƒì„¸ ë¶„ì„
                    # ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ ìµëª…í™” ì²˜ë¦¬
                    anonymous_id = f'êµ¬ì„±ì›{chr(65+i)}'  # êµ¬ì„±ì›A, êµ¬ì„±ì›B, ...
                    
                    # ì‹¤ì œ ë°ì´í„° êµ¬ì¡° í™•ì¸ (ë””ë²„ê¹…ìš©)
                    print(f"ğŸ” DEBUG - {anonymous_id} ë°ì´í„° êµ¬ì¡°: {type(profile)}")
                    if isinstance(profile, dict):
                        profile_keys = list(profile.keys())
                        print(f"ğŸ” DEBUG - {anonymous_id} í‚¤ë“¤: {profile_keys[:5]}...")  # ì²˜ìŒ 5ê°œ í‚¤ë§Œ ì¶œë ¥
                    
                    # êµ¬ì¡°ì— ìƒê´€ì—†ì´ ê¸°ë³¸ ì •ë³´ë§Œ ìƒì„±
                    profile_info = f"- {anonymous_id}: ì‚¬ë‚´ êµ¬ì„±ì› ë°ì´í„° í™•ì¸ë¨"
                    career_profiles.append(profile_info)
                
                career_context = f"""
**ì‚¬ë‚´ êµ¬ì„±ì› ì„±ê³µ ì‚¬ë¡€ ({len(career_data)}ëª… ë¶„ì„, ìµëª…í™” ì²˜ë¦¬):**
{chr(10).join(career_profiles)}

**ë°ì´í„° ë¶„ì„ ê²°ê³¼:**
- ì´ {len(career_data)}ëª…ì˜ ì‚¬ë‚´ êµ¬ì„±ì› ë°ì´í„° ë¶„ì„ (ê°œì¸ì •ë³´ ìµëª…í™”)
- career_positioning ë‹¨ê³„ì—ì„œ ê²€ìƒ‰ëœ ì‹¤ì œ ë°ì´í„° í™œìš©
- ìœ ì‚¬ ê²½ë¡œ ì„±ê³µ ì‚¬ë¡€ ë° ì„±ì¥ íŒ¨í„´ íŒŒì•… ê°€ëŠ¥
"""
                print(f"ğŸ” DEBUG - ìƒì„±ëœ career_context ê¸¸ì´: {len(career_context)}")
                print(f"ğŸ” DEBUG - career_context ë¯¸ë¦¬ë³´ê¸°: {career_context[:200]}...")
            else:
                career_context = "ì‚¬ë‚´ êµ¬ì„±ì› ë°ì´í„°: í˜„ì¬ ë¶„ì„ ê°€ëŠ¥í•œ ë°ì´í„° ì—†ìŒ"
                print("âŒ WARNING - career_dataê°€ ë¹„ì–´ìˆì–´ ê¸°ë³¸ ë©”ì‹œì§€ ì‚¬ìš©")
                print("ğŸ” DEBUG - existing_career_data â†’ retrieved_data â†’ career_data ì „ë‹¬ ê³¼ì •ì—ì„œ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥ì„±")
            
            # path_selection_context ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
            selection_context_str = ""
            if path_selection_context:
                selection_context_str = f"""
**ê²½ë¡œ ì„ íƒ ì»¨í…ìŠ¤íŠ¸:**
- ì„ íƒí•œ ê²½ë¡œ: {path_selection_context.get('selected_path_name', 'ì •ë³´ ì—†ìŒ')}
- ì„ íƒ ì´ìœ : {path_selection_context.get('path_selection_reason', 'ì •ë³´ ì—†ìŒ')}
- í˜„ì¬ ëª©í‘œ/ë™ê¸°: {path_selection_context.get('current_goals', 'ì •ë³´ ì—†ìŒ')[:150]}"""
            
            prompt = f"""
ë‹¹ì‹ ì€ SKAXì˜ ì‹œë‹ˆì–´ ì»¤ë¦¬ì–´ ë©˜í† ì…ë‹ˆë‹¤. ë™ë£Œ êµ¬ì„±ì›ì¸ {merged_user_data.get('name', 'ê³ ê°')}ë‹˜ì˜ ì»¤ë¦¬ì–´ ì„±ì¥ì„ ìœ„í•œ ì‹¤ë¬´ì ì¸ ì¡°ì–¸ê³¼ êµ¬ì²´ì ì¸ ì•¡ì…˜ í”Œëœì„ ì œê³µí•´ì£¼ì„¸ìš”.

{company_vision_context}

**ìƒë‹´ ëŒ€ìƒì ì •ë³´:**
- ì´ë¦„: {merged_user_data.get('name', 'ê³ ê°')}ë‹˜
- í˜„ì¬ ê²½ë ¥: {merged_user_data.get('experience', 'ì •ë³´ ì—†ìŒ')}
- ë³´ìœ  ìŠ¤í‚¬: {merged_user_data.get('skills', 'ì •ë³´ ì—†ìŒ')}
- ë‹´ë‹¹ ë„ë©”ì¸: {merged_user_data.get('domain', 'ì •ë³´ ì—†ìŒ')}
- í¬ë§ ì„±ì¥ ë°©í–¥: {path_name}
- ê³ ë¯¼ê³¼ ëª©í‘œ: {user_goals[:200]}

{selection_context_str}

**ì‚¬ë‚´ ë™ë£Œë“¤ì˜ ì„±ì¥ ì‚¬ë¡€:**
{career_context}

**ë©˜í† ë§ ê°€ì´ë“œë¼ì¸:**
1. **ì‹¤ì œ ë™ë£Œ ì‚¬ë¡€ ê¸°ë°˜ ì¡°ì–¸**: ìœ„ì— ì–¸ê¸‰ëœ ì‚¬ë‚´ êµ¬ì„±ì›ë“¤ì˜ ì‹¤ì œ ì„±ì¥ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì¸ ì„±ì¥ ê²½ë¡œ ì œì‹œ
2. **SKAX ë‚´ë¶€ ë¦¬ì†ŒìŠ¤ í™œìš©**: ì‚¬ë‚´ì—ì„œ ì‹¤ì œë¡œ í™œìš© ê°€ëŠ¥í•œ ë©˜í† ë§, ìŠ¤í„°ë””, í”„ë¡œì íŠ¸ ê¸°íšŒ ì•ˆë‚´
3. **íšŒì‚¬ ë¹„ì „ ì—°ê³„**: íšŒì‚¬ì˜ ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œ ë° ì „ëµ ë°©í–¥ê³¼ ê°œì¸ ì„±ì¥ì„ ì—°ê²°í•œ ì¡°ì–¸ ì œê³µ
4. **ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš**: ë‹¤ìŒ 3-6ê°œì›” ë‚´ ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì•¡ì…˜ ì•„ì´í…œ ì œê³µ
5. **ì‚¬ë‚´ ë„¤íŠ¸ì›Œí‚¹**: ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì‚¬ë‚´ ì»¤ë®¤ë‹ˆí‹°ë‚˜ íŒ€ ì†Œê°œ

**ë©˜í† ë§ ì‘ë‹µ í˜•ì‹:**

## {merged_user_data.get('name', 'ê³ ê°')}ë‹˜ì„ ìœ„í•œ ì„±ì¥ ë¡œë“œë§µ

ì•ˆë…•í•˜ì„¸ìš”! {merged_user_data.get('name', 'ê³ ê°')}ë‹˜ì˜ **{path_name}** ë°©í–¥ ì„±ì¥ì„ í•¨ê»˜ ê³„íší•´ë³´ê² ìŠµë‹ˆë‹¤.

### ì‚¬ë‚´ ì„ ë°°ë“¤ì˜ ì„±ê³µ ì‚¬ë¡€

**{path_name} ë¡œë“œë§µ ê´€ë ¨ ë™ë£Œë“¤ì˜ ì‹¤ì œ ì„±ì¥ ìŠ¤í† ë¦¬:**

**ë°ì´í„° ê¸°ë°˜ ì„±ì¥ ì‚¬ë¡€ ë¶„ì„:**
{f"- **{merged_user_data.get('name', 'ê³ ê°')}ë‹˜**ê³¼ ìœ ì‚¬í•œ ë°°ê²½ì„ ê°€ì§„ ì‚¬ë‚´ ì„ ë°° {len(career_data)}ëª…ì˜ ì‹¤ì œ ë°ì´í„°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤" if career_data else "- ìœ ì‚¬í•œ ê²½í—˜ì„ ê°€ì§„ ë™ë£Œë“¤ì˜ ì‹¤ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•´ë³´ë©´"}
- êµ¬ì„±ì›A: [ì‹¤ì œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ êµ¬ì²´ì ì¸ ì„±ì¥ ìŠ¤í† ë¦¬ì™€ í˜„ì¬ ê²½ë¡œ ì„ íƒ ë°°ê²½]
- êµ¬ì„±ì›B: [ë‹¤ë¥¸ ê´€ì ì˜ ì„±ì¥ ê²½í—˜ê³¼ **{merged_user_data.get('name', 'ê³ ê°')}ë‹˜**ê³¼ì˜ ê³µí†µì ]
- êµ¬ì„±ì›C: [ìœ ì‚¬í•œ ê¸°ìˆ  ìŠ¤íƒ/ë„ë©”ì¸ì—ì„œ ì„±ê³µí•œ ì‚¬ë¡€ì™€ í•µì‹¬ ì „ëµ]

**{merged_user_data.get('name', 'ê³ ê°')}ë‹˜ê³¼ì˜ ë°ì´í„° ì¼ì¹˜ì :**
- **ê²½ë ¥ ìˆ˜ì¤€**: [ê³ ê°ì˜ í˜„ì¬ ê²½ë ¥ê³¼ ì¼ì¹˜í•˜ëŠ” ì„ ë°°ë“¤ì˜ ë‹¹ì‹œ ìƒí™©]
- **ê¸°ìˆ  ìŠ¤íƒ**: [ê³ ê°ì˜ ë³´ìœ  ê¸°ìˆ ê³¼ ìœ ì‚¬í•œ ì„ ë°°ë“¤ì˜ ì‹œì‘ì ]
- **ë„ë©”ì¸ ê²½í—˜**: [ê³ ê°ì˜ ë„ë©”ì¸ê³¼ ê²¹ì¹˜ëŠ” ì„ ë°°ë“¤ì˜ ì„±ì¥ ë°°ê²½]
- **ì„±ì¥ ë™ê¸°**: [ê³ ê°ì˜ ëª©í‘œì™€ ì¼ì¹˜í•˜ëŠ” ì„ ë°°ë“¤ì˜ ë‹¹ì‹œ ëª©í‘œ]

**ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„±ì¥ íŒ¨í„´:**
- **í•µì‹¬ ì„±ê³µ ìš”ì¸**: [ì‹¤ì œ ë°ì´í„°ì—ì„œ ë°œê²¬ë˜ëŠ” ê³µí†µì ì¸ ì„±ì¥ ì „ëµ]
- **ë‹¨ê³„ë³„ ì„±ì¥ ê³¼ì •**: [ë°ì´í„°ë¡œ ê²€ì¦ëœ 1ë…„ì°¨â†’3ë…„ì°¨â†’5ë…„ì°¨ ì„±ì¥ ê²½ë¡œ]
- **ì„±ê³µ ì§€í‘œ**: [ì„ ë°°ë“¤ì´ ì‹¤ì œë¡œ ë‹¬ì„±í•œ êµ¬ì²´ì ì¸ ì„±ê³¼ ì§€í‘œ]

**{merged_user_data.get('name', 'ê³ ê°')}ë‹˜ì„ ìœ„í•œ ë§ì¶¤í˜• ë²¤ì¹˜ë§ˆí‚¹:**
- [ê³ ê°ì˜ í˜„ì¬ ë°ì´í„°ì™€ ê°€ì¥ ì¼ì¹˜í•˜ëŠ” ì„ ë°° ì‚¬ë¡€ ê¸°ë°˜ êµ¬ì²´ì ì¸ ì„±ì¥ ë°©í–¥]
- [ë°ì´í„° ë¶„ì„ ê²°ê³¼ ë„ì¶œëœ **{merged_user_data.get('name', 'ê³ ê°')}ë‹˜**ë§Œì˜ ìµœì  ì„±ì¥ ì „ëµ]

*ğŸŒŸ ì´ ì¶”ì²œ ë°©í–¥ì„±ì€ ê°œì¸ì˜ ê²½í—˜ ë°ì´í„°ì™€ í•¨ê»˜ SKAXì˜ ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œ ë° ë¹„ì „ ë°©í–¥ì„±ì„ ì¢…í•© ë¶„ì„í•˜ì—¬ ì œì‹œë©ë‹ˆë‹¤.*

### ì¶”ì²œ ë©˜í† /ì„ ë°°

**ì‹¤ì œ êµ¬ì„±ì› ë°ì´í„° ê¸°ë°˜ ë©˜í†  ì¶”ì²œ:**

**ë©˜í†  A (ì¶”ì²œë„: â˜…â˜…â˜…â˜…â˜…)**
- **ë°°ê²½**: [**{merged_user_data.get('name', 'ê³ ê°')}ë‹˜**ê³¼ ìœ ì‚¬í•œ ê²½ë ¥/ê¸°ìˆ  ìŠ¤íƒì„ ê°€ì§„ ì„ ë°°ì˜ êµ¬ì²´ì  í”„ë¡œí•„]
- **ì„±ì¥ ê²½í—˜**: [í•´ë‹¹ ë©˜í† ê°€ ì‹¤ì œë¡œ ê²ªì€ **{path_name}** ê´€ë ¨ ì„±ì¥ ê³¼ì •ê³¼ ì„±ê³¼]
- **ì¶”ì²œ ì´ìœ **: [**{merged_user_data.get('name', 'ê³ ê°')}ë‹˜**ì˜ í˜„ì¬ ìƒí™©ê³¼ ëª©í‘œì— ì™œ ì´ ë©˜í† ê°€ ìµœì ì¸ì§€ êµ¬ì²´ì  ì„¤ëª…]
- **ë©˜í† ë§ ê°€ëŠ¥ ì˜ì—­**: [ì‹¤ì œ ë„ì›€ë°›ì„ ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ë¶„ì•¼ë“¤]

**ë©˜í†  B (ì¶”ì²œë„: â˜…â˜…â˜…â˜…â˜†)**  
- **ë°°ê²½**: [ë‹¤ë¥¸ ê´€ì ì—ì„œ **{path_name}** ê²½ë¡œë¥¼ ì„±ê³µì ìœ¼ë¡œ ê±¸ì–´ì˜¨ ì„ ë°°ì˜ í”„ë¡œí•„]
- **ì„±ì¥ ê²½í—˜**: [í•´ë‹¹ ë©˜í† ì˜ ë…íŠ¹í•œ ì„±ì¥ ìŠ¤í† ë¦¬ì™€ í•µì‹¬ ì¸ì‚¬ì´íŠ¸]
- **ì¶”ì²œ ì´ìœ **: [**{merged_user_data.get('name', 'ê³ ê°')}ë‹˜**ì´ ë†“ì¹  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì„ ë³´ì™„í•´ì¤„ ìˆ˜ ìˆëŠ” ì´ìœ ]
- **ë©˜í† ë§ ê°€ëŠ¥ ì˜ì—­**: [ì´ ë©˜í† ë§Œì˜ íŠ¹ë³„í•œ ì¡°ì–¸ ê°€ëŠ¥ ë¶„ì•¼]

**ë©˜í† ë§ ì‹ ì²­ ë° ì—°ê²° ë°©ë²•:**
- **ì‚¬ë‚´ ë©˜í† ë§ í”„ë¡œê·¸ë¨**: HRíŒ€ ê³µì‹ ì±„ë„ í†µí•´ ì‹ ì²­ (ì›” 1íšŒ ë§¤ì¹­)
- **ë¹„ê³µì‹ ë©˜í† ë§**: ì‚¬ë‚´ ë©”ì‹ ì €ë‚˜ ì´ë©”ì¼ì„ í†µí•œ ê°œë³„ ì»¨íƒ
- **ê·¸ë£¹ ë©˜í† ë§**: ìœ ì‚¬í•œ ëª©í‘œë¥¼ ê°€ì§„ ë™ë£Œë“¤ê³¼ í•¨ê»˜í•˜ëŠ” ê·¸ë£¹ ì„¸ì…˜ ì°¸ì—¬

---(ì´ ëŒ€ì‹œë¶€ë¶„ ë¬´ì¡°ê±´ í¬í•¨)

**ë‹¤ìŒ ìŠ¤í…: ì²´ê³„ì ì¸ í•™ìŠµ ë¡œë“œë§µ ì„¤ê³„**

ìœ„ì—ì„œ ì œì‹œí•œ ì„±ì¥ ì „ëµê³¼ ë©˜í† ë§ ê³„íšì„ ë°”íƒ•ìœ¼ë¡œ, ë”ìš± êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í•™ìŠµ ë¡œë“œë§µì„ í•¨ê»˜ ì„¤ê³„í•´ë³´ì‹œê² ì–´ìš”?
í•™ìŠµ ë¡œë“œë§µì„ ì›í•˜ì‹œë©´ "ë„¤, í•™ìŠµ ë¡œë“œë§µì„ ì„¤ê³„í•´ì£¼ì„¸ìš”"ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”!

---

**ì‘ì„± ì›ì¹™:**
- ë™ë£Œì—ê²Œ ì¡°ì–¸í•˜ëŠ” ë”°ëœ»í•˜ê³  ì‹¤ë¬´ì ì¸ í†¤
- ì‹¤ì œ ì‚¬ë‚´ì—ì„œ í™œìš© ê°€ëŠ¥í•œ ë¦¬ì†ŒìŠ¤ì™€ ê¸°íšŒ ì¤‘ì‹¬
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ê¸°/ì¤‘ê¸° ê³„íš
- ê°œì¸ì •ë³´ëŠ” ìµëª…í™”í•˜ë˜ ì‹¤ì œ ì‚¬ë¡€ì˜ ì§„ì •ì„± ìœ ì§€
- íšŒì‚¬ ë¹„ì „ ì •ë³´ê°€ ì œê³µëœ ê²½ìš°, í•´ë‹¹ ê°€ì¹˜ì™€ ì „ëµ ë°©í–¥ì— ë¶€í•©í•˜ëŠ” ë©˜í† ë§ê³¼ ì•¡ì…˜ í”Œëœ ì œê³µ
- 200-250ë‹¨ì–´ë¡œ ê°„ê²°í•˜ë©´ì„œë„ ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±
"""
            
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000,
                temperature=0.6
            )
            
            ai_content = response.choices[0].message.content.strip()
            
            return ai_content
            
        except Exception as e:
            print(f"AI ì•¡ì…˜ í”Œëœ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return "ì•¡ì…˜ í”Œëœì„ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    async def process_deepening_node(self, state: ChatState) -> Dict[str, Any]:
        """
        ì‚¬ìš©ìì˜ ëª©í‘œì™€ ì´ìœ ë¥¼ ë¶„ì„í•˜ì—¬ ì‹¤í–‰ ì „ëµì„ ì œì‹œí•œë‹¤.
        """
        print("ğŸ¯ ê²½ë¡œ ì‹¬í™” ë…¼ì˜ ì‹œì‘...")
        
        # State ì „ë‹¬ íŠ¸ë ˆì´ì‹± í™•ì¸ (ë””ë²„ê¹…)
        print(f"ğŸ” DEBUG - path_deepeningì—ì„œ ë°›ì€ state íŠ¸ë ˆì´ì‹±:")
        print(f"ğŸ” DEBUG - state_trace: {state.get('state_trace', 'None')}")
        print(f"ğŸ” DEBUG - career_positioning_timestamp: {state.get('career_positioning_timestamp', 'None')}")
        print(f"ğŸ” DEBUG - consultation_stage: {state.get('consultation_stage', 'None')}")
        print(f"ğŸ” DEBUG - awaiting_user_input: {state.get('awaiting_user_input', 'None')}")
        
        user_response = state.get("user_question", "")
        selected_path = state.get("selected_career_path", {})
        user_data = self.graph_builder.get_user_info_from_session(state)
        collected_info = state.get("collected_user_info", {})
        merged_user_data = {**user_data, **collected_info}
        
        # path_selection ë‹¨ê³„ì—ì„œì˜ ì‚¬ìš©ì ì„ íƒ ì •ë³´ ì¶”ì¶œ
        path_selection_info = state.get("path_selection_info", {})
        path_selection_context = {
            "selected_path_name": selected_path.get("name", "ì„ íƒëœ ê²½ë¡œ"),
            "selected_path_id": selected_path.get("id", ""),
            "path_selection_reason": "",  # ì‚¬ìš©ìê°€ í•´ë‹¹ ê²½ë¡œë¥¼ ì„ íƒí•œ ì´ìœ  ì¶”ì¶œ
            "current_goals": user_response,  # í˜„ì¬ ë‹¨ê³„ì—ì„œì˜ ëª©í‘œ/ë™ê¸°
            "previous_user_input": path_selection_info.get("user_input_for_deepening", "")  # path_selectionì—ì„œì˜ ì‚¬ìš©ì ì…ë ¥
        }
        
        # ì‚¬ìš©ì ì‘ë‹µì—ì„œ ê²½ë¡œ ì„ íƒ ì´ìœ  ì¶”ì¶œ (í‚¤ì›Œë“œ ê¸°ë°˜)
        selection_keywords = {
            "ê´€ì‹¬": "í•´ë‹¹ ë¶„ì•¼ì— ê´€ì‹¬",
            "ê²½í—˜": "ê´€ë ¨ ê²½í—˜ ë³´ìœ ",
            "ì„±ì¥": "ì„±ì¥ ê°€ëŠ¥ì„±",
            "ê¸°íšŒ": "ê¸°íšŒ í™•ëŒ€",
            "ì „ë¬¸ì„±": "ì „ë¬¸ì„± ê°œë°œ",
            "ë„ì „": "ìƒˆë¡œìš´ ë„ì „",
            "ì ì„±": "ì ì„±ì— ë§ìŒ",
            "ë¹„ì „": "ë¹„ì „ ì¼ì¹˜",
            "ì‹œì¥": "ì‹œì¥ ì „ë§",
            "ë¯¸ë˜": "ë¯¸ë˜ ê°€ëŠ¥ì„±"
        }
        
        # í˜„ì¬ ì‘ë‹µê³¼ ì´ì „ ì‘ë‹µ ëª¨ë‘ì—ì„œ ì´ìœ  ì¶”ì¶œ
        combined_response = f"{user_response} {path_selection_context['previous_user_input']}"
        
        for keyword, description in selection_keywords.items():
            if keyword in combined_response:
                path_selection_context["path_selection_reason"] += f"{description}, "
        
        # ì´ìœ ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ì „ì²´ ì‘ë‹µì„ ì´ìœ ë¡œ í™œìš©
        if not path_selection_context["path_selection_reason"]:
            path_selection_context["path_selection_reason"] = user_response[:100] + "..." if len(user_response) > 100 else user_response
        else:
            path_selection_context["path_selection_reason"] = path_selection_context["path_selection_reason"].rstrip(", ")
        
        # ë””ë²„ê¹…: ë°ì´í„° í™•ì¸
        print(f"ğŸ” DEBUG - path_deepening user_data from session: {user_data}")
        print(f"ğŸ” DEBUG - path_deepening collected_info: {collected_info}")
        print(f"ğŸ” DEBUG - path_deepening merged_user_data: {merged_user_data}")
        print(f"ğŸ” DEBUG - path_selection_context: {path_selection_context}")
        
        # career_positioningì—ì„œ ê²€ìƒ‰ëœ ì‚¬ë‚´ ê²½ë ¥ ë°ì´í„° í™œìš©
        # path_selectionê³¼ path_deepening ì‚¬ì´ì—ëŠ” ë°ì´í„° ì†ì‹¤ì´ ì—†ì–´ì•¼ í•¨
        
        # ë¨¼ì € stateì˜ ëª¨ë“  career ê´€ë ¨ í‚¤ë“¤ì„ í™•ì¸
        career_related_keys = [key for key in state.keys() if 'career' in key.lower()]
        print(f"ğŸ” DEBUG - stateì˜ career ê´€ë ¨ í‚¤ë“¤: {career_related_keys}")
        
        # ì „ì²´ state í‚¤ í™•ì¸ (ë””ë²„ê¹…ìš©)
        all_state_keys = list(state.keys())
        print(f"ğŸ” DEBUG - ì „ì²´ state í‚¤ ê°œìˆ˜: {len(all_state_keys)}")
        print(f"ğŸ” DEBUG - ëª¨ë“  state í‚¤ë“¤: {all_state_keys}")
        
        # retrieved_career_data í™•ì¸
        existing_career_data = state.get("retrieved_career_data", [])
        print(f"ğŸ” DEBUG - stateì—ì„œ ê°€ì ¸ì˜¨ retrieved_career_data: {len(existing_career_data)}ê°œ")
        print(f"ğŸ” DEBUG - retrieved_career_data íƒ€ì…: {type(existing_career_data)}")
        
        if existing_career_data:
            print(f"ğŸ” DEBUG - ì²« ë²ˆì§¸ ë°ì´í„° ìƒ˜í”Œ: {existing_career_data[0] if existing_career_data else 'None'}")
            print(f"ğŸ” DEBUG - ëª¨ë“  employee_id: {[item.get('employee_id', 'N/A') for item in existing_career_data[:5]]}")
            
            # ë°ì´í„° êµ¬ì¡° ê²€ì¦
            if isinstance(existing_career_data[0], dict):
                sample_keys = list(existing_career_data[0].keys())
                print(f"ğŸ” DEBUG - ë°ì´í„° êµ¬ì¡° ê²€ì¦ OK - ìƒ˜í”Œ í‚¤ë“¤: {sample_keys}")
            else:
                print(f"âŒ WARNING - ë°ì´í„° êµ¬ì¡° ì´ìƒ: ì²« ë²ˆì§¸ í•­ëª©ì´ dictê°€ ì•„ë‹˜ - {type(existing_career_data[0])}")
        else:
            print("âŒ WARNING - retrieved_career_dataê°€ ë¹„ì–´ìˆìŒ!")
        
        if existing_career_data and len(existing_career_data) > 0:
            print(f"âœ… SUCCESS - career_positioningì—ì„œ ì €ì¥ëœ ì‚¬ë‚´ êµ¬ì„±ì› ë°ì´í„° ì¬ì‚¬ìš©: {len(existing_career_data)}ê°œ")
            retrieved_data = {"career_data": existing_career_data}
            print(f"ğŸ” DEBUG - retrieved_data êµ¬ì„± ì™„ë£Œ: career_data í‚¤ì— {len(retrieved_data['career_data'])}ê°œ ë°ì´í„° ì €ì¥")
        else:
            print("âŒ WARNING - retrieved_career_dataê°€ ë¹„ì–´ìˆê±°ë‚˜ ì—†ìŒ. ë¹ˆ ë°ì´í„°ë¡œ ì²˜ë¦¬")
            retrieved_data = {"career_data": []}
        
        print(f"ğŸ” DEBUG - AI í˜¸ì¶œ ì „ ìµœì¢… retrieved_data í™•ì¸: career_data={len(retrieved_data.get('career_data', []))}ê°œ")
        
        # AI ê¸°ë°˜ ì‚¬ë‚´ ë°ì´í„° í™œìš© ì•¡ì…˜ í”Œëœ ìƒì„± (path_selection ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
        ai_response = await self._generate_ai_action_plan(
            merged_user_data, selected_path, user_response, retrieved_data, path_selection_context
        )
        
        # ì‚¬ìš©ì ì‘ë‹µ ì»¨í…ìŠ¤íŠ¸ ì €ì¥ (path_selection ì •ë³´ í¬í•¨)
        consultation_context = {
            "user_goals": user_response,
            "selected_path": selected_path,
            "path_selection_context": path_selection_context,
            "analysis_timestamp": "2025-07-02"
        }
        
        # ì‘ë‹µ êµ¬ì„±
        strategy_response = {
            "message": ai_response,
            "action_plan": {
                "context": consultation_context,
                "data_sources": ["career_data", "networking_opportunities"]
            }
        }
        
        # HTML ë¡œê·¸ ì €ì¥
        save_career_response_to_html("path_deepening", strategy_response, state.get("session_id", "unknown"))
        
        return {
            **state,
            "consultation_stage": "learning_decision",
            "consultation_context": consultation_context,
            "formatted_response": strategy_response,
            "final_response": strategy_response,
            "awaiting_user_input": True,
            "next_expected_input": "learning_roadmap_decision",
            "processing_log": state.get("processing_log", []) + ["ì‹¤í–‰ ì „ëµ ìˆ˜ë¦½ ì™„ë£Œ"]
        }

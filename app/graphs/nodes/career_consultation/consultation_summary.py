# app/graphs/nodes/career_consultation/consultation_summary.py
"""
ìƒë‹´ ìš”ì•½ ë° ë™ê¸°ë¶€ì—¬ ë§ˆë¬´ë¦¬ ë…¸ë“œ
AI ê¸°ë°˜ ê°œì¸í™”ëœ ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ ìƒì„±
"""

import os
from typing import Dict, Any
from app.graphs.state import ChatState
from app.utils.html_logger import save_career_response_to_html


class ConsultationSummaryNode:
    """
    ìƒë‹´ ìš”ì•½ ë° ë§ˆë¬´ë¦¬ ë…¸ë“œ
    """
    
    def __init__(self, graph_builder):
        self.graph_builder = graph_builder
    
    async def _generate_consultation_summary(self, merged_user_data: dict, selected_path: dict, consultation_context: dict, processing_log: list) -> str:
        """AI ê¸°ë°˜ ìƒë‹´ ìš”ì•½ ë° ê²©ë ¤ ë©”ì‹œì§€ ìƒì„±"""
        try:
            from openai import AsyncOpenAI
            
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                return f"""## ìƒë‹´ ìš”ì•½

{merged_user_data.get('name', 'ê³ ê°')}ë‹˜ì˜ ì»¤ë¦¬ì–´ ìƒë‹´ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

**ì„ íƒëœ ê²½ë¡œ**: {selected_path.get('name', 'ëª©í‘œ ê²½ë¡œ')}
**ëª©í‘œ**: {consultation_context.get('user_goals', 'ì„¤ì •ëœ ëª©í‘œ')[:200]}

ì²´ê³„ì ì¸ ê³„íšì„ ë°”íƒ•ìœ¼ë¡œ ê¾¸ì¤€íˆ ì‹¤í–‰í•´ë‚˜ê°€ì‹œë©´ ë°˜ë“œì‹œ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‘ì›í•©ë‹ˆë‹¤!"""
            
            client = AsyncOpenAI(api_key=api_key)
            
            skills_str = ", ".join(merged_user_data.get('skills', ['ì •ë³´ ì—†ìŒ']))
            path_name = selected_path.get('name', 'ì„ íƒëœ ê²½ë¡œ')
            user_goals = consultation_context.get('user_goals', 'ì»¤ë¦¬ì–´ ì„±ì¥ ëª©í‘œ')
            
            # ë””ë²„ê¹…: AI ë©”ì„œë“œì— ì „ë‹¬ëœ ë°ì´í„° í™•ì¸
            print(f"ğŸ” DEBUG - consultation_summary AI ë©”ì„œë“œì— ì „ë‹¬ëœ ë°ì´í„°")
            print(f"   - name: {merged_user_data.get('name')}")
            print(f"   - path_name: {path_name}")
            print(f"   - user_goals: {user_goals[:100]}...")
            print(f"   - processing_log: {processing_log}")
            
            prompt = f"""
ë‹¹ì‹ ì€ G.Naviì˜ ì „ë¬¸ ì»¤ë¦¬ì–´ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. {merged_user_data.get('name', 'ê³ ê°')}ë‹˜ê³¼ì˜ ìƒë‹´ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. 

**ìƒë‹´ ë‚´ìš© ìš”ì•½:**
- ì´ë¦„: {merged_user_data.get('name', 'ê³ ê°')}
- ê²½ë ¥: {merged_user_data.get('experience', 'ì •ë³´ ì—†ìŒ')}
- ë³´ìœ  ê¸°ìˆ : {skills_str}
- ë„ë©”ì¸: {merged_user_data.get('domain', 'ì •ë³´ ì—†ìŒ')}
- ì„ íƒí•œ ê²½ë¡œ: {path_name}
- ì„¤ì •í•œ ëª©í‘œ: {user_goals}

**ìƒë‹´ ì§„í–‰ ê³¼ì •:**
{', '.join(processing_log)}

**ìš”ì²­ì‚¬í•­:**
1. ìƒë‹´ ë‚´ìš©ì˜ í•µì‹¬ ìš”ì•½ (ì„ íƒí•œ ê²½ë¡œ, ì£¼ìš” ê²°ì •ì‚¬í•­, í–¥í›„ ê³„íš)
2. ê°œì¸ ë§ì¶¤í˜• ê²©ë ¤ ë©”ì‹œì§€

**ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”):**

## ìƒë‹´ ìš”ì•½ ì™„ë£Œ

### ğŸ“‹ ìƒë‹´ í•µì‹¬ ë‚´ìš©

**ì„ íƒëœ ê²½ë¡œ**: {path_name}
**í•µì‹¬ ê²°ì •ì‚¬í•­**: [ìƒë‹´ì„ í†µí•´ ê²°ì •ëœ ì£¼ìš” ë‚´ìš©ë“¤]
**í–¥í›„ ê³„íš**: [ë‹¤ìŒ ë‹¨ê³„ ì•¡ì…˜ í”Œëœ ìš”ì•½]

### ğŸ’ª ë§ˆë¬´ë¦¬ ê²©ë ¤ ë©”ì‹œì§€

[{merged_user_data.get('name', 'ê³ ê°')}ë‹˜ì—ê²Œ ë³´ë‚´ëŠ” ê°œì¸ ë§ì¶¤í˜• ê²©ë ¤ì™€ ì‘ì› ë©”ì‹œì§€]

**ì‘ì„± ì§€ì¹¨:**
- ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì‚¬ìš© (## ì œëª©, ### ì†Œì œëª©, **êµµì€ê¸€ì”¨** ë“±)
- ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ "## ìƒë‹´ ìš”ì•½ ì™„ë£Œ"ë¡œ ì‹œì‘
- ì „ì²´ 150-200ë‹¨ì–´ ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±
- ìƒë‹´ì˜ í•µì‹¬ ë‚´ìš©ì„ ì •í™•íˆ ìš”ì•½
- ë”°ëœ»í•˜ê³  ì „ë¬¸ì ì¸ ê²©ë ¤ ë©”ì‹œì§€ë¡œ ë§ˆë¬´ë¦¬
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš© ìœ„ì£¼
"""
            
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=600,
                temperature=0.5
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"AI ìƒë‹´ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return f"""## ìƒë‹´ ìš”ì•½

**{merged_user_data.get('name', 'ê³ ê°')}ë‹˜**ì˜ ì»¤ë¦¬ì–´ ìƒë‹´ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

**ì„ íƒëœ ê²½ë¡œ**: {selected_path.get('name', 'ëª©í‘œ ê²½ë¡œ')}
**ëª©í‘œ**: {consultation_context.get('user_goals', 'ì„¤ì •ëœ ëª©í‘œ')[:200]}

ì²´ê³„ì ì¸ ê³„íšì„ ë°”íƒ•ìœ¼ë¡œ ê¾¸ì¤€íˆ ì‹¤í–‰í•´ë‚˜ê°€ì‹œë©´ ë°˜ë“œì‹œ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‘ì›í•©ë‹ˆë‹¤!"""
    
    async def create_consultation_summary_node(self, state: ChatState) -> Dict[str, Any]:
        """
        ìƒë‹´ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ê²©ë ¤ ë©”ì‹œì§€ë¡œ ë§ˆë¬´ë¦¬í•œë‹¤.
        """
        print("ğŸ“ ìƒë‹´ ìš”ì•½ ë° ë§ˆë¬´ë¦¬...")
        
        selected_path = state.get("selected_career_path", {})
        consultation_context = state.get("consultation_context", {})
        user_data = self.graph_builder.get_user_info_from_session(state)
        collected_info = state.get("collected_user_info", {})
        merged_user_data = {**user_data, **collected_info}
        processing_log = state.get("processing_log", [])
        
        # ë””ë²„ê¹…: ë°ì´í„° í™•ì¸
        print(f"ğŸ” DEBUG - consultation_summary user_data from session: {user_data}")
        print(f"ğŸ” DEBUG - consultation_summary collected_info: {collected_info}")
        print(f"ğŸ” DEBUG - consultation_summary merged_user_data: {merged_user_data}")
        
        # AI ê¸°ë°˜ ìƒë‹´ ìš”ì•½ ìƒì„±
        summary_message = await self._generate_consultation_summary(
            merged_user_data, selected_path, consultation_context, processing_log
        )
        
        # ê°„ê²°í•œ ìš”ì•½ ì‘ë‹µ êµ¬ì„±
        summary_response = {
            "message": summary_message,
            "summary": {
                "consultation_type": "career_consultation",
                "selected_path": selected_path.get('name', 'ì„ íƒëœ ê²½ë¡œ'),
                "user_goals": consultation_context.get('user_goals', 'ì„¤ì •ëœ ëª©í‘œ'),
                "completed_stages": processing_log
            }
        }
    
        # HTML ë¡œê·¸ ì €ì¥
        save_career_response_to_html("consultation_summary", summary_response, state.get("session_id", "unknown"))
    
        return {
            **state,
            "consultation_stage": "completed",
            "formatted_response": summary_response,
            "final_response": summary_response,
            "awaiting_user_input": False,
            "processing_log": processing_log + ["ì»¤ë¦¬ì–´ ìƒë‹´ ì™„ë£Œ"]
        }

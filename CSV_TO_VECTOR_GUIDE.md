# CSV ë°ì´í„° â†’ ë²¡í„° ì„ë² ë”© ê°€ì´ë“œ

ë¡¤ëª¨ë¸ CSV ë°ì´í„°ë¥¼ ChromaDB ë²¡í„° ìŠ¤í† ì–´ë¡œ ë³€í™˜í•˜ëŠ” í”„ë¡œì„¸ìŠ¤

**ì‘ì„±ì:** ì–‘ìŠ¹ìš°
**ì‘ì„±ì¼:** 2025.07.01

---

## ğŸ“‹ ê°œìš”

G-Navi ì‹œìŠ¤í…œì€ ë¡¤ëª¨ë¸(ì„ ë°° ì§ì›)ì˜ ì»¤ë¦¬ì–´ ë°ì´í„°ë¥¼ ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•˜ì—¬,
ì‚¬ìš©ì ì§ˆë¬¸ì— ìœ ì‚¬í•œ ì‚¬ë¡€ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

**ì…ë ¥:** CSV íŒŒì¼ (ì»¤ë¦¬ì–´ ì‚¬ë¡€, êµìœ¡ê³¼ì •)
**ì¶œë ¥:** ChromaDB ë²¡í„° ìŠ¤í† ì–´ + JSON ë¬¸ì„œ

---

## ğŸ—‚ï¸ í•„ìš”í•œ CSV íŒŒì¼

### **1. ì»¤ë¦¬ì–´ ë°ì´í„°**

| íŒŒì¼ëª… | ê²½ë¡œ | ì„¤ëª… |
|--------|------|------|
| `career_history_v2.csv` | `app/data/csv/` | ë¡¤ëª¨ë¸ ì»¤ë¦¬ì–´ ì‚¬ë¡€ |
| `skill_set.csv` | `app/data/csv/` | ì§ë¬´-ìŠ¤í‚¬ ë§¤í•‘ |

**career_history_v2.csv êµ¬ì¡°:**
```csv
ê³ ìœ ë²ˆí˜¸,ì´ë¦„,ì—°ë„,ì—°ì°¨,íšŒì‚¬,ì§ë¬´,í”„ë¡œì íŠ¸,ì£¼ìš”ì—…ë¬´,ì—­í• ,ìŠ¤í‚¬
P001,í™ê¸¸ë™,2020,1,SKí•˜ì´ë‹‰ìŠ¤,SWê°œë°œ,ëª¨ë°”ì¼ì•±,APIê°œë°œ,ê°œë°œì,Java/Spring
P001,í™ê¸¸ë™,2021,2,SKí•˜ì´ë‹‰ìŠ¤,SWê°œë°œ,ì›¹ì„œë¹„ìŠ¤,í”„ë¡ íŠ¸ì—”ë“œ,ê°œë°œì,React/TypeScript
P002,ê¹€ì² ìˆ˜,2019,1,SKí…”ë ˆì½¤,ë°ì´í„°ë¶„ì„,ì¶”ì²œì‹œìŠ¤í…œ,ëª¨ë¸ë§,ë°ì´í„°ê³¼í•™ì,Python/ML
...
```

**íŠ¹ì§•:**
- ê³ ìœ ë²ˆí˜¸ë¡œ ê°œì¸ ì‹ë³„
- ì—°ë„/ì—°ì°¨ë¡œ ì‹œê°„ìˆœ ì •ë ¬
- í”„ë¡œì íŠ¸/ì£¼ìš”ì—…ë¬´ë¡œ ê²½ë ¥ ìƒì„¸í™”

---

### **2. êµìœ¡ê³¼ì • ë°ì´í„°**

| íŒŒì¼ëª… | ê²½ë¡œ | ì„¤ëª… |
|--------|------|------|
| `college.csv` | `app/data/csv/` | SKê·¸ë£¹ College êµìœ¡ê³¼ì • |
| `mysuni.csv` | `app/data/csv/` | mySUNI ì˜¨ë¼ì¸ êµìœ¡ê³¼ì • |

**college.csv êµ¬ì¡°:**
```csv
êµìœ¡ê³¼ì •ëª…,í•™ë¶€,í‘œì¤€ê³¼ì •,êµìœ¡ìœ í˜•,í•™ìŠµì‹œê°„,íŠ¹í™” ì§ë¬´ ë° Skill set,URL
AI ê¸°ì´ˆê³¼ì •,SK Univ,í•„ìˆ˜,ì˜¨ë¼ì¸,40,AI/ML/Python,https://...
ë°ì´í„°ë¶„ì„ ì‹¤ë¬´,ë°ì´í„°,ì„ íƒ,ì§‘í•©,16,ë°ì´í„°ë¶„ì„/SQL/Python,https://...
```

---

## ğŸ”§ ë°ì´í„° ì²˜ë¦¬ ì½”ë“œ

### **1. Career Data Processor**

**íŒŒì¼:** `app/utils/career_data_processor.py`

```python
from app.utils.career_data_processor import VectorDBGroupingFixer

# 1. í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
processor = VectorDBGroupingFixer(
    csv_path="app/data/csv/career_history_v2.csv",
    skillset_csv_path="app/data/csv/skill_set.csv",
    persist_directory="app/storage/vector_stores/career_data",
    cache_directory="app/storage/cache/embedding_cache",
    docs_json_path="app/storage/docs/career_history.json"
)

# 2. CSV â†’ ë²¡í„° ë³€í™˜ ì‹¤í–‰
processor.fix_and_rebuild_vectordb()
```

**ë‚´ë¶€ í”„ë¡œì„¸ìŠ¤:**

```python
# Step 1: CSV ë¡œë“œ ë° ê·¸ë£¹í•‘
employee_groups = processor.load_and_group_career_data()
# â†’ Dict[ê³ ìœ ë²ˆí˜¸, DataFrame]
# â†’ ì—°ë„/ì—°ì°¨ ìˆœ ì •ë ¬

# Step 2: ê°œì¸ë³„ ë¬¸ì„œ ìƒì„±
documents = processor.create_documents_from_groups(employee_groups)
# â†’ List[Document]
# â†’ ê° ê°œì¸ì˜ ì»¤ë¦¬ì–´ íƒ€ì„ë¼ì¸ì„ í•˜ë‚˜ì˜ ë¬¸ì„œë¡œ

# Step 3: ìŠ¤í‚¬ì…‹ ë§¤í•‘ ì ìš©
processor._load_skillset_mapping()
# â†’ skill_set.csv ë¡œë“œ
# â†’ ì§ë¬´ ì½”ë“œ â†’ ìŠ¤í‚¬ëª… ë³€í™˜

# Step 4: í…ìŠ¤íŠ¸ ì²­í‚¹
chunked_docs = processor.split_documents(documents)
# â†’ RecursiveCharacterTextSplitter
# â†’ chunk_size=1500, overlap=150

# Step 5: ì„ë² ë”© ìƒì„± (ìºì‹± ì ìš©)
embeddings = processor.cached_embeddings
# â†’ OpenAI text-embedding-3-small (1536 dim)
# â†’ LocalFileStore ìºì‹±ìœ¼ë¡œ API ë¹„ìš© ì ˆê°

# Step 6: ChromaDB ì €ì¥
vectorstore = Chroma.from_documents(
    documents=chunked_docs,
    embedding=embeddings,
    persist_directory="app/storage/vector_stores/career_data"
)

# Step 7: JSON ë¬¸ì„œ ì €ì¥
processor.save_documents_as_json(documents)
# â†’ app/storage/docs/career_history.json
```

**ìƒì„± ê²°ê³¼:**

```
app/storage/
â”œâ”€â”€ vector_stores/
â”‚   â””â”€â”€ career_data/
â”‚       â”œâ”€â”€ chroma.sqlite3           # ChromaDB ë©”íƒ€ë°ì´í„°
â”‚       â””â”€â”€ {uuid}/                  # ë²¡í„° ë°ì´í„°
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ career_history.json          # ì›ë³¸ ë¬¸ì„œ (ê²€ìƒ‰ ê²°ê³¼ ì°¸ì¡°ìš©)
â””â”€â”€ cache/
    â””â”€â”€ embedding_cache/             # ì„ë² ë”© ìºì‹±
        â””â”€â”€ {hash}.bin               # ìºì‹œëœ ë²¡í„°
```

---

### **2. Education Data Processor**

**íŒŒì¼:** `app/utils/education_data_processor.py`

```python
from app.utils.education_data_processor import EducationDataProcessor

# 1. í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
processor = EducationDataProcessor()

# 2. ì „ì²´ êµìœ¡ê³¼ì • ì²˜ë¦¬
processor.process_all_education_data()
```

**ë‚´ë¶€ í”„ë¡œì„¸ìŠ¤:**

```python
# Step 1: ìŠ¤í‚¬ ë°ì´í„° ë¡œë“œ
skill_data = processor._load_skill_data()
# â†’ skill_set.csv

# Step 2: College ë°ì´í„° ì²˜ë¦¬
college_courses = processor._process_college_data(skill_data)
# â†’ college.csv íŒŒì‹±
# â†’ ìŠ¤í‚¬ ë§¤í•‘ ì ìš©

# Step 3: mySUNI ë°ì´í„° ì²˜ë¦¬
mysuni_courses = processor._process_mysuni_data(skill_data)
# â†’ mysuni.csv íŒŒì‹±

# Step 4: ìŠ¤í‚¬-êµìœ¡ê³¼ì • ë§¤í•‘ ìƒì„±
skill_mapping = processor._create_skill_education_mapping(
    college_courses, mysuni_courses
)
# â†’ {ìŠ¤í‚¬ì½”ë“œ: [ê³¼ì •ID1, ê³¼ì •ID2, ...]}

# Step 5: ì¤‘ë³µ ì œê±° ì¸ë±ìŠ¤ ìƒì„±
deduplication_index = processor._create_deduplication_index(
    college_courses, mysuni_courses
)
# â†’ ë™ì¼/ìœ ì‚¬ ê³¼ì • ê·¸ë£¹í™”

# Step 6: VectorDBìš© ë¬¸ì„œ ìƒì„±
all_documents = processor._create_vector_documents(
    college_courses, mysuni_courses
)
# â†’ ê³¼ì •ëª… + ì„¤ëª… + ìŠ¤í‚¬ â†’ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸

# Step 7: ChromaDB ì €ì¥
processor._build_vector_database(all_documents)
# â†’ Chroma.from_documents()

# Step 8: JSON ì €ì¥
processor._save_processed_data(...)
# â†’ education_courses.json
# â†’ skill_education_mapping.json
# â†’ course_deduplication_index.json
```

**ìƒì„± ê²°ê³¼:**

```
app/storage/
â”œâ”€â”€ vector_stores/
â”‚   â””â”€â”€ education_courses/
â”‚       â”œâ”€â”€ chroma.sqlite3
â”‚       â””â”€â”€ {uuid}/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ education_courses.json       # í†µí•© êµìœ¡ê³¼ì •
â”‚   â”œâ”€â”€ college_courses_detailed.json  # College ìƒì„¸
â”‚   â”œâ”€â”€ mysuni_courses_detailed.json   # mySUNI ìƒì„¸
â”‚   â”œâ”€â”€ skill_education_mapping.json   # ìŠ¤í‚¬-ê³¼ì • ë§¤í•‘
â”‚   â””â”€â”€ course_deduplication_index.json  # ì¤‘ë³µ ì œê±°
â””â”€â”€ cache/
    â””â”€â”€ education_embedding_cache/
```

---

##  ì‹¤í–‰ ë°©ë²•

### **ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰**

```bash
# 1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™
cd /Users/swyang/Desktop/GSë„¤ì˜¤í…/project/g-navi-ai-api

# 2. ê°€ìƒí™˜ê²½ í™œì„±í™” (ì„ íƒ)
source venv/bin/activate

# 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export OPENAI_API_KEY=sk-proj-...

# 4. ì»¤ë¦¬ì–´ ë°ì´í„° ì„ë² ë”©
python3 -m app.utils.career_data_processor

# 5. êµìœ¡ê³¼ì • ë°ì´í„° ì„ë² ë”©
python3 -m app.utils.education_data_processor
```

**ì˜ˆìƒ ì¶œë ¥:**

```
=== ì»¤ë¦¬ì–´ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘ ===
ìŠ¤í‚¬ì…‹ ë§¤í•‘ ì™„ë£Œ: 189ê°œ
ê²½ë ¥ ë°ì´í„° ë¡œë“œ: 1,234í–‰
ê°œì¸ë³„ ê·¸ë£¹í•‘ ì™„ë£Œ: 156ëª…
ë¬¸ì„œ ìƒì„± ì™„ë£Œ: 156ê°œ
ì²­í‚¹ ì™„ë£Œ: 312ê°œ (í‰ê·  2.0ê°œ/ì¸)
ì„ë² ë”© ìƒì„± ì¤‘... (ìºì‹œ íˆíŠ¸ìœ¨: 45%)
ChromaDB ì €ì¥ ì™„ë£Œ
JSON ë¬¸ì„œ ì €ì¥ ì™„ë£Œ
=== ì²˜ë¦¬ ì™„ë£Œ: 156ëª…, 312ê°œ ì²­í¬ ===
```

---

### **K8s í™˜ê²½ì—ì„œ ì‹¤í–‰ (Pod)**

**íŒŒì¼:** `app/utils/upload_career_to_pod_chroma.py`

```bash
# Kubernetes Jobìœ¼ë¡œ ì‹¤í–‰
kubectl apply -f k8s/chromadb-init-job.yaml

# Job ë¡œê·¸ í™•ì¸
kubectl logs -f job/chromadb-init-data -n sk-team-04
```

**ì½”ë“œ:**

```python
# app/utils/upload_career_to_pod_chroma.py
from app.utils.career_data_processor import VectorDBGroupingFixer
import os

def upload_to_pod_chroma():
    """K8s Pod ChromaDBì— ì—…ë¡œë“œ"""

    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ChromaDB ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    chroma_host = os.getenv("CHROMA_HOST", "chromadb-1")
    chroma_port = int(os.getenv("CHROMA_PORT", 8000))

    # HTTP Clientë¡œ ChromaDB ì—°ê²°
    import chromadb
    client = chromadb.HttpClient(
        host=chroma_host,
        port=chroma_port,
        settings=Settings(
            chroma_client_auth_provider="chromadb.auth.basic_authn.BasicAuthClientProvider",
            chroma_client_auth_credentials=os.getenv("CHROMA_AUTH_CREDENTIALS")
        )
    )

    # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
    collection = client.get_or_create_collection(
        name="gnavi4_career_prod",
        metadata={"hnsw:space": "cosine"}
    )

    # ë°ì´í„° ì²˜ë¦¬
    processor = VectorDBGroupingFixer()
    documents = processor.create_documents()

    # ì„ë² ë”© ìƒì„± ë° ì—…ë¡œë“œ
    for doc in documents:
        embedding = processor.cached_embeddings.embed_query(doc.page_content)
        collection.add(
            ids=[doc.metadata["id"]],
            embeddings=[embedding],
            documents=[doc.page_content],
            metadatas=[doc.metadata]
        )

if __name__ == "__main__":
    upload_to_pod_chroma()
```

---

##  ê²€ì¦ ë°©ë²•

### **1. ë²¡í„° ìŠ¤í† ì–´ í™•ì¸**

```python
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

# VectorDB ë¡œë“œ
vectorstore = Chroma(
    persist_directory="app/storage/vector_stores/career_data",
    embedding_function=OpenAIEmbeddings(model="text-embedding-3-small")
)

# ë¬¸ì„œ ê°œìˆ˜ í™•ì¸
collection = vectorstore._collection
print(f"ì´ ë¬¸ì„œ ìˆ˜: {collection.count()}")

# ìƒ˜í”Œ ê²€ìƒ‰
results = vectorstore.similarity_search("AI ê°œë°œì", k=3)
for doc in results:
    print(f"- {doc.metadata.get('ì´ë¦„')}: {doc.page_content[:100]}...")
```

**ì˜ˆìƒ ì¶œë ¥:**

```
ì´ ë¬¸ì„œ ìˆ˜: 312
- í™ê¸¸ë™: === ê²½ë ¥ 1ë…„ì°¨ (2020ë…„) ===
  íšŒì‚¬: SKí•˜ì´ë‹‰ìŠ¤
  ì§ë¬´: SWê°œë°œ
  í”„ë¡œì íŠ¸: ëª¨ë°”ì¼ì•± ê°œë°œ
  ì£¼ìš”ì—…ë¬´: API ì„œë²„ ê°œë°œ, DB ì„¤ê³„...
- ê¹€ì² ìˆ˜: === ê²½ë ¥ 2ë…„ì°¨ (2021ë…„) ===
  ...
```

---

### **2. JSON ë¬¸ì„œ í™•ì¸**

```bash
# ì»¤ë¦¬ì–´ ë¬¸ì„œ í™•ì¸
cat app/storage/docs/career_history.json | jq '.[0]'

# êµìœ¡ê³¼ì • ë¬¸ì„œ í™•ì¸
cat app/storage/docs/education_courses.json | jq '.[0]'

# ìŠ¤í‚¬ ë§¤í•‘ í™•ì¸
cat app/storage/docs/skill_education_mapping.json | jq '.AI'
```

**ì˜ˆìƒ ì¶œë ¥:**

```json
{
  "id": "P001",
  "ì´ë¦„": "í™ê¸¸ë™",
  "ì „ì²´ê²½ë ¥": "2ë…„",
  "ì£¼ìš”ì§ë¬´": ["SWê°œë°œ"],
  "ì£¼ìš”ìŠ¤í‚¬": ["Java", "Spring", "React"],
  "íƒ€ì„ë¼ì¸": [
    {
      "ì—°ì°¨": 1,
      "íšŒì‚¬": "SKí•˜ì´ë‹‰ìŠ¤",
      "í”„ë¡œì íŠ¸": "ëª¨ë°”ì¼ì•± ê°œë°œ"
    }
  ]
}
```

---

## ğŸ’¡ í•µì‹¬ ì„¤ê³„ í¬ì¸íŠ¸

### **1. ê°œì¸ë³„ ê·¸ë£¹í•‘**

```python
# - ì˜ëª»ëœ ë°©ë²•: ê° í–‰ì„ ê°œë³„ ë¬¸ì„œë¡œ
for row in csv_rows:
    doc = Document(page_content=row)  # ë¬¸ë§¥ ì—†ìŒ

#  ì˜¬ë°”ë¥¸ ë°©ë²•: ê°œì¸ë³„ í†µí•© ë¬¸ì„œ
for person_id, person_data in grouped.items():
    timeline = create_timeline(person_data)  # ì‹œê°„ìˆœ ì •ë ¬
    doc = Document(
        page_content=timeline,  # ì „ì²´ ì»¤ë¦¬ì–´ ìŠ¤í† ë¦¬
        metadata={"id": person_id, ...}
    )
```

**ì™œ?**
- ë²¡í„° ê²€ìƒ‰ì€ ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ì°¾ìŒ
- ê°œë³„ í–‰ë³´ë‹¤ ì „ì²´ ì»¤ë¦¬ì–´ ìŠ¤í† ë¦¬ê°€ ë” ìœ ìš©
- ì˜ˆ: "ëª¨ë°”ì¼ ê°œë°œì—ì„œ ë°±ì—”ë“œë¡œ ì „í™˜í•œ ì‚¬ëŒ" ê²€ìƒ‰ ê°€ëŠ¥

---

### **2. ì„ë² ë”© ìºì‹±**

```python
# ìºì‹± ì ìš© ì „
embeddings = OpenAIEmbeddings()
# ë§¤ë²ˆ API í˜¸ì¶œ â†’ ë¹„ìš© $$$

# ìºì‹± ì ìš© í›„
from langchain.embeddings import CacheBackedEmbeddings
from langchain.storage import LocalFileStore

cached_embeddings = CacheBackedEmbeddings.from_bytes_store(
    OpenAIEmbeddings(),
    LocalFileStore("cache/"),
    namespace="career"
)
# ê°™ì€ í…ìŠ¤íŠ¸ëŠ” ìºì‹œì—ì„œ ë¡œë“œ â†’ ë¹„ìš© ì ˆê°
```

**íš¨ê³¼:**
- API í˜¸ì¶œ: 1,000ê±´ â†’ 200ê±´ (80% ì ˆê°)
- ë¹„ìš©: $10 â†’ $2
- ì†ë„: 10ë¶„ â†’ 2ë¶„

---

### **3. ë©”íƒ€ë°ì´í„° í™œìš©**

```python
Document(
    page_content="...",  # ì„ë² ë”©ë  í…ìŠ¤íŠ¸
    metadata={
        "id": "P001",
        "ì´ë¦„": "í™ê¸¸ë™",
        "ì—°ì°¨ë²”ìœ„": "1-3ë…„ì°¨",
        "ì£¼ìš”ì§ë¬´": ["SWê°œë°œ"],
        "ì£¼ìš”ìŠ¤í‚¬": ["Java", "Spring"],
        "source_file": "career_history_v2.csv"
    }
)
```

**í™œìš©:**
```python
# í•„í„°ë§ ê²€ìƒ‰
results = vectorstore.similarity_search(
    "ë°±ì—”ë“œ ê°œë°œ",
    k=5,
    filter={"ì£¼ìš”ì§ë¬´": {"$in": ["SWê°œë°œ", "ë°±ì—”ë“œ"]}}
)
```

---

##  ë©´ì ‘ ì‹œ ê°•ì¡° í¬ì¸íŠ¸

**"CSV ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ë²¡í„°í™”í–ˆë‚˜ìš”?"**

```
1. ë°ì´í„° ì „ì²˜ë¦¬
   - ê°œì¸ë³„ ê·¸ë£¹í•‘ (ê³ ìœ ë²ˆí˜¸ ê¸°ì¤€)
   - ì‹œê°„ìˆœ ì •ë ¬ (ì—°ë„/ì—°ì°¨)
   - ìŠ¤í‚¬ì…‹ ë§¤í•‘ ì ìš©

2. ë¬¸ì„œ ìƒì„±
   - ê°œì¸ë³„ í†µí•© ë¬¸ì„œ (ì»¤ë¦¬ì–´ íƒ€ì„ë¼ì¸)
   - RecursiveCharacterTextSplitter (1500ì)
   - ë©”íƒ€ë°ì´í„° í’ë¶€í™”

3. ì„ë² ë”© ìµœì í™”
   - OpenAI text-embedding-3-small (1536 dim)
   - CacheBackedEmbeddings (80% ë¹„ìš© ì ˆê°)
   - LocalFileStore ìºì‹±

4. ChromaDB ì €ì¥
   - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰
   - ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì§€ì›
   - JSON ë°±ì—… (ê²€ìƒ‰ ê²°ê³¼ ì°¸ì¡°ìš©)
```

---

**"ì™œ ê°œì¸ë³„ë¡œ ê·¸ë£¹í•‘í–ˆë‚˜ìš”?"**

```
ë²¡í„° ê²€ìƒ‰ì˜ íŠ¹ì„± ë•Œë¬¸ì…ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´:
- ì§ˆë¬¸: "ëª¨ë°”ì¼ ê°œë°œì—ì„œ ë°±ì—”ë“œë¡œ ì „í™˜í•œ ì„ ë°° ì‚¬ë¡€"
- ê° í–‰ ê°œë³„ ê²€ìƒ‰: ëª¨ë°”ì¼ OR ë°±ì—”ë“œ (ë¬¸ë§¥ ì—†ìŒ)
- ê°œì¸ë³„ í†µí•©: ëª¨ë°”ì¼ â†’ ë°±ì—”ë“œ ì „í™˜ ìŠ¤í† ë¦¬ (ë¬¸ë§¥ æœ‰)

â†’ ê°œì¸ë³„ í†µí•© ë¬¸ì„œê°€ ì˜ë¯¸ì ìœ¼ë¡œ ë” ìœ ì‚¬í•¨
```

---

**ì‘ì„±ì:** ì–‘ìŠ¹ìš°
**ìµœì¢… ìˆ˜ì •ì¼:** 2025.07.01
